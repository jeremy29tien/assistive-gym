demos: (480, 200, 43)
demo_rewards: (480,)
maximum traj length 200
maximum traj length 200
num train_obs 52326
num train_labels 52326
num val_obs 1128
num val_labels 1128
ModuleList(
  (0): Linear(in_features=43, out_features=128, bias=True)
  (1): Linear(in_features=128, out_features=64, bias=True)
  (2): Linear(in_features=64, out_features=1, bias=False)
)
Training reward model from scratch...
Total number of parameters: 13952
Number of trainable paramters: 13952
device: cuda:2
end of epoch 0: val_loss 0.0651904976927546, val_acc 0.9716312056737588
trigger times: 0
saving model weights...
end of epoch 1: val_loss 0.05431471145838202, val_acc 0.9796099290780141
trigger times: 0
saving model weights...
end of epoch 2: val_loss 0.03937758593988126, val_acc 0.9867021276595744
trigger times: 0
saving model weights...
end of epoch 3: val_loss 0.03777865660571171, val_acc 0.9858156028368794
trigger times: 0
saving model weights...
end of epoch 4: val_loss 0.035163278720958195, val_acc 0.9884751773049646
trigger times: 0
saving model weights...
end of epoch 5: val_loss 0.03483798033650865, val_acc 0.9884751773049646
trigger times: 0
saving model weights...
end of epoch 6: val_loss 0.03425993762697022, val_acc 0.9875886524822695
trigger times: 0
saving model weights...
end of epoch 7: val_loss 0.030230197111620033, val_acc 0.9884751773049646
trigger times: 0
saving model weights...
end of epoch 8: val_loss 0.03826498523553791, val_acc 0.9858156028368794
trigger times: 1
end of epoch 9: val_loss 0.03070728318049736, val_acc 0.9893617021276596
trigger times: 2
end of epoch 10: val_loss 0.031028862639335023, val_acc 0.9902482269503546
trigger times: 3
end of epoch 11: val_loss 0.03322027305928193, val_acc 0.9893617021276596
trigger times: 4
end of epoch 12: val_loss 0.03239091115078325, val_acc 0.9902482269503546
trigger times: 5
end of epoch 13: val_loss 0.03171768010608682, val_acc 0.9902482269503546
trigger times: 6
end of epoch 14: val_loss 0.04114839862069786, val_acc 0.9875886524822695
trigger times: 7
end of epoch 15: val_loss 0.035540293956549, val_acc 0.9902482269503546
trigger times: 8
end of epoch 16: val_loss 0.032984774181251335, val_acc 0.9893617021276596
trigger times: 9
end of epoch 17: val_loss 0.03223641992304446, val_acc 0.9902482269503546
trigger times: 10
Early stopping.
0 -38.97125355154276 -114.3478791814026
1 -30.803668098524213 -113.0527592060181
2 -38.845048097893596 -103.2050097258442
3 -31.827529033645988 -101.76388982232147
4 -31.09318088926375 -82.95243894933974
5 -29.825555991381407 -80.41220948132849
6 -13.298319559544325 -62.91270007904664
7 -19.651382498443127 -55.45183907670275
8 -11.643311271443963 -26.226286028753027
9 -8.266610510647297 -25.030892790643723
10 -4.725115433335304 -10.941586969641467
11 0.9833204904571176 -2.6693152362626984
12 -0.6975751258432865 -0.6169503682874974
13 -0.4836240904405713 7.085127736448486
14 9.784241653047502 30.085890959085077
15 11.6081434013322 33.309940907344725
16 11.91864989604801 34.53183125686171
17 14.252753582783043 38.74386523093347
18 14.54659379646182 39.160251163178806
19 15.185769808012992 51.18130221875085
20 21.589004940353334 59.162585389085
21 23.736735818441957 69.21057916674489
22 25.920925562269986 80.2319629802139
23 33.18355214968324 91.31020541502424
24 35.06384892389178 91.60291397111007
25 34.88341947179288 95.31009344169037
26 48.48109013680369 128.73676510885525
27 46.350638921838254 131.48967691990322
28 47.974438041914254 133.33968592253453
29 57.19515011832118 153.3157491396614
30 55.08324469439685 154.0081635777143
31 65.80877157440409 177.594294762342
32 68.28046436980367 190.1449010777256
33 80.09634786099195 214.6263040548001
34 76.98478982783854 214.7728217494139
35 80.45342337153852 218.5468376965032
36 84.65794430952519 234.15916506458083
37 91.88195736624766 252.17029359403926
38 97.98224914213642 266.3586992205008
39 109.05519495811313 305.27906870114026
40 117.1163844615221 324.0197976082746
41 120.62911708164029 333.0407029156643
42 122.6468569803983 338.4771724289715
43 129.75987570453435 361.84626739841684
44 141.68762311711907 390.7517184882046
45 145.44709364976734 400.0413426933392
46 146.98361293785274 403.13796958654353
47 155.26457529515028 423.1355871564197
train accuracy: 0.99545159194282
validation accuracy: 0.9902482269503546
