demos: (480, 200, 43)
demo_rewards: (480,)
maximum traj length 200
maximum traj length 200
num train_obs 7140
num train_labels 7140
num val_obs 1128
num val_labels 1128
ModuleList(
  (0): Linear(in_features=43, out_features=128, bias=True)
  (1): Linear(in_features=128, out_features=64, bias=True)
  (2): Linear(in_features=64, out_features=1, bias=False)
)
Training reward model from scratch...
Total number of parameters: 13952
Number of trainable paramters: 13952
device: cuda:2
end of epoch 0: val_loss 0.20555335270554778, val_acc 0.900709219858156
trigger times: 0
saving model weights...
end of epoch 1: val_loss 0.16633712204922382, val_acc 0.9237588652482269
trigger times: 0
saving model weights...
end of epoch 2: val_loss 0.16287791202031388, val_acc 0.9299645390070922
trigger times: 0
saving model weights...
end of epoch 3: val_loss 0.13933846173215392, val_acc 0.9406028368794326
trigger times: 0
saving model weights...
end of epoch 4: val_loss 0.13398097167436837, val_acc 0.9468085106382979
trigger times: 0
saving model weights...
end of epoch 5: val_loss 0.12830720829369924, val_acc 0.9450354609929078
trigger times: 0
saving model weights...
end of epoch 6: val_loss 0.11584557586968604, val_acc 0.9521276595744681
trigger times: 0
saving model weights...
end of epoch 7: val_loss 0.11086796667853009, val_acc 0.9539007092198581
trigger times: 0
saving model weights...
end of epoch 8: val_loss 0.09793815396925507, val_acc 0.9627659574468085
trigger times: 0
saving model weights...
end of epoch 9: val_loss 0.10918501193499082, val_acc 0.9547872340425532
trigger times: 1
end of epoch 10: val_loss 0.09696714071846474, val_acc 0.9609929078014184
trigger times: 0
saving model weights...
end of epoch 11: val_loss 0.09990615924356791, val_acc 0.9583333333333334
trigger times: 1
end of epoch 12: val_loss 0.08792152370109085, val_acc 0.9689716312056738
trigger times: 0
saving model weights...
end of epoch 13: val_loss 0.08638131476280674, val_acc 0.9689716312056738
trigger times: 0
saving model weights...
end of epoch 14: val_loss 0.0885798696122986, val_acc 0.9663120567375887
trigger times: 1
end of epoch 15: val_loss 0.09108512191484741, val_acc 0.9645390070921985
trigger times: 2
end of epoch 16: val_loss 0.08162963207754576, val_acc 0.9663120567375887
trigger times: 0
saving model weights...
end of epoch 17: val_loss 0.07812862768495196, val_acc 0.9725177304964538
trigger times: 0
saving model weights...
end of epoch 18: val_loss 0.07386789849817071, val_acc 0.9725177304964538
trigger times: 0
saving model weights...
end of epoch 19: val_loss 0.07416375431712435, val_acc 0.9716312056737588
trigger times: 1
end of epoch 20: val_loss 0.09505326417566418, val_acc 0.9618794326241135
trigger times: 2
end of epoch 21: val_loss 0.08310437586619919, val_acc 0.9663120567375887
trigger times: 3
end of epoch 22: val_loss 0.06912514101162338, val_acc 0.9725177304964538
trigger times: 0
saving model weights...
end of epoch 23: val_loss 0.06483479226788152, val_acc 0.973404255319149
trigger times: 0
saving model weights...
end of epoch 24: val_loss 0.06660128839415043, val_acc 0.974290780141844
trigger times: 1
end of epoch 25: val_loss 0.08366780527697758, val_acc 0.9663120567375887
trigger times: 2
end of epoch 26: val_loss 0.07341231261699974, val_acc 0.9716312056737588
trigger times: 3
end of epoch 27: val_loss 0.07124918743298596, val_acc 0.9716312056737588
trigger times: 4
end of epoch 28: val_loss 0.05896987399996501, val_acc 0.975177304964539
trigger times: 0
saving model weights...
end of epoch 29: val_loss 0.06117877920199097, val_acc 0.9769503546099291
trigger times: 1
end of epoch 30: val_loss 0.07600559654318295, val_acc 0.975177304964539
trigger times: 2
end of epoch 31: val_loss 0.06022226508062681, val_acc 0.9796099290780141
trigger times: 3
end of epoch 32: val_loss 0.07330480909809013, val_acc 0.973404255319149
trigger times: 4
end of epoch 33: val_loss 0.06802357244035044, val_acc 0.973404255319149
trigger times: 5
end of epoch 34: val_loss 0.0661968664506885, val_acc 0.973404255319149
trigger times: 6
end of epoch 35: val_loss 0.06613190157813585, val_acc 0.9787234042553191
trigger times: 7
end of epoch 36: val_loss 0.061347270678378335, val_acc 0.974290780141844
trigger times: 8
end of epoch 37: val_loss 0.06064556314795479, val_acc 0.9804964539007093
trigger times: 9
end of epoch 38: val_loss 0.0616293949363762, val_acc 0.9813829787234043
trigger times: 10
Early stopping.
0 -44.80656339973211 -101.76388982232147
1 -39.81670358031988 -86.65072964683067
2 -42.77377185970545 -85.66259925248552
3 -44.54870668053627 -77.01090975292257
4 -36.51208824664354 -72.73934795341557
5 -36.31306982040405 -57.644804265451405
6 -31.951197165995836 -56.34472211229872
7 -32.12779739871621 -50.660824574682984
8 -27.357805859297514 -36.33152782603484
9 -23.435717973858118 -24.584813233651065
10 -29.87910893186927 -22.94737629424818
11 -23.262915056198835 -11.5973519031622
12 -23.218267619609833 -6.937724378212109
13 -21.310774073004723 -4.946601920236691
14 -26.793459640815854 3.430982471853314
15 -22.4077404178679 8.519563505539821
16 -19.237066254019737 14.588410588465225
17 -21.464095167815685 17.83838203486445
18 -16.18901227042079 32.39268529257516
19 -16.03130615875125 33.309940907344725
20 -13.268779192119837 36.391810699359475
21 -15.247453931719065 52.76057747481694
22 -8.852525053545833 54.94621558067348
23 -10.900133233517408 70.81952421033375
24 -6.3043858632445335 83.1813616168006
25 -4.32721465267241 101.9061505897436
26 2.1514315009117126 108.6266552798086
27 0.42169588431715965 115.76264727059684
28 2.345274979248643 125.83945216304483
29 0.9587903283536434 127.60055662815962
30 6.677509400993586 164.63948553528294
31 9.800599984824657 170.2769258573369
32 8.705812491476536 173.36443629284494
33 9.994420349597931 176.89141765627136
34 20.100569250062108 230.23584072637587
35 18.565761037170887 234.582534233438
36 20.92186565324664 237.23945479951806
37 22.09565120562911 246.62206176082205
38 24.332404911518097 250.73781616547046
39 33.650096978992224 301.6965823877335
40 35.18861918896437 306.78447028794534
41 38.10262298025191 328.26073799893464
42 35.292963253334165 333.0407029156643
43 38.90628778375685 338.4771724289715
44 39.117637664079666 343.3928836976398
45 44.07995958998799 364.1736706930025
46 52.31713276542723 423.1355871564197
47 57.72561912611127 434.80815706930116
train accuracy: 0.9946778711484594
validation accuracy: 0.9813829787234043
