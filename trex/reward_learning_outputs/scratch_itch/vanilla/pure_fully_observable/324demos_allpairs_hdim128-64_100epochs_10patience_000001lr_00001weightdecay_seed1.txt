demos: (480, 200, 19)
demo_rewards: (480,)
sorted_train_rewards: [-1.68281407e+02 -1.45727567e+02 -1.39123043e+02 -1.33973547e+02
 -1.25906495e+02 -1.23737226e+02 -1.18441257e+02 -1.15454518e+02
 -1.15278652e+02 -1.14763156e+02 -1.14085096e+02 -1.12885489e+02
 -1.11179560e+02 -1.10579609e+02 -1.10248073e+02 -1.06969949e+02
 -1.06298076e+02 -1.06264986e+02 -1.05880618e+02 -1.01565908e+02
 -1.00495946e+02 -1.00348353e+02 -9.79572956e+01 -9.72448577e+01
 -9.72257679e+01 -9.60581398e+01 -9.47527923e+01 -9.42721572e+01
 -9.39936009e+01 -9.08470847e+01 -8.99058909e+01 -8.98050349e+01
 -8.92193126e+01 -8.88554189e+01 -8.71119989e+01 -8.58361739e+01
 -8.42859587e+01 -8.40914856e+01 -8.33560899e+01 -8.14466377e+01
 -8.10067480e+01 -7.89340632e+01 -7.86319117e+01 -7.84173816e+01
 -7.80515779e+01 -7.63592934e+01 -7.50296954e+01 -7.48307224e+01
 -7.41288702e+01 -7.35268215e+01 -7.30055356e+01 -7.26136252e+01
 -7.23199016e+01 -7.10097190e+01 -7.02497554e+01 -6.98788242e+01
 -6.90105689e+01 -6.88032812e+01 -6.82574483e+01 -6.81709241e+01
 -6.78589144e+01 -6.77543594e+01 -6.77033281e+01 -6.58589998e+01
 -6.53374190e+01 -6.50060709e+01 -6.49762184e+01 -6.43151789e+01
 -6.32463365e+01 -6.31014303e+01 -5.92349209e+01 -5.78572803e+01
 -5.76610527e+01 -5.71589430e+01 -5.63099047e+01 -5.50587300e+01
 -5.45877794e+01 -5.38140519e+01 -5.23998422e+01 -5.20708438e+01
 -5.03190683e+01 -4.94482556e+01 -4.87197115e+01 -4.55497329e+01
 -4.52135310e+01 -4.44901949e+01 -4.39133519e+01 -4.35323363e+01
 -4.26845918e+01 -4.13106519e+01 -3.93647734e+01 -3.84347912e+01
 -3.72825558e+01 -3.65728483e+01 -3.64541601e+01 -3.63795012e+01
 -3.56366006e+01 -3.51896507e+01 -3.49277470e+01 -3.44876502e+01
 -3.36956904e+01 -2.95933148e+01 -2.77930868e+01 -2.71949370e+01
 -2.63456513e+01 -2.26604777e+01 -2.17769506e+01 -2.17096738e+01
 -2.11615803e+01 -2.01425951e+01 -2.00548875e+01 -1.87912468e+01
 -1.74207898e+01 -1.68901975e+01 -1.61143764e+01 -1.44711839e+01
 -1.39267768e+01 -1.12508710e+01 -7.28306957e+00 -6.03798033e+00
 -4.48405644e+00 -1.63608121e+00 -1.43319012e+00 -1.25215708e+00
  2.69474090e-01  5.32120974e-01  8.48755488e-01  9.71479122e-01
  3.13137341e+00  4.09388103e+00  4.23223568e+00  6.23806049e+00
  8.10954932e+00  8.62917691e+00  1.29952266e+01  1.34336148e+01
  1.51800256e+01  1.58979399e+01  1.65923688e+01  1.89453788e+01
  1.94910199e+01  1.94916920e+01  1.96225348e+01  2.05305881e+01
  2.15104917e+01  2.41170029e+01  2.43710703e+01  2.58660332e+01
  2.60724768e+01  2.74672520e+01  2.75751580e+01  2.85285750e+01
  3.05892332e+01  3.27442577e+01  3.37899159e+01  3.41611587e+01
  3.42153602e+01  3.48663961e+01  3.72456187e+01  3.99267393e+01
  3.99602846e+01  4.23875378e+01  4.39159825e+01  4.42327291e+01
  4.48500197e+01  4.83776686e+01  4.88736658e+01  5.51223952e+01
  5.53688861e+01  5.56692378e+01  5.59202636e+01  5.78923918e+01
  5.86309323e+01  5.93436812e+01  6.02906417e+01  6.47458201e+01
  6.49603340e+01  6.51680641e+01  6.68749790e+01  6.76039372e+01
  6.78694515e+01  6.85395993e+01  6.85552576e+01  7.00722782e+01
  7.10566011e+01  7.18958063e+01  7.42631002e+01  7.64437617e+01
  7.80250544e+01  8.00743291e+01  8.04122550e+01  8.18901469e+01
  8.32565101e+01  8.33459185e+01  8.73487076e+01  8.87279953e+01
  9.04900629e+01  9.13388441e+01  9.30086833e+01  9.30344412e+01
  9.73584524e+01  9.78474792e+01  9.87173322e+01  9.92848455e+01
  1.02399087e+02  1.03162159e+02  1.03450957e+02  1.03768508e+02
  1.04406383e+02  1.05720971e+02  1.07092483e+02  1.07710068e+02
  1.11625387e+02  1.11924895e+02  1.13547690e+02  1.14761007e+02
  1.16179984e+02  1.16837433e+02  1.21326132e+02  1.33048584e+02
  1.33573303e+02  1.36511921e+02  1.37758285e+02  1.39131419e+02
  1.41638120e+02  1.41844812e+02  1.42424512e+02  1.43496609e+02
  1.43510881e+02  1.46199060e+02  1.46556236e+02  1.48382236e+02
  1.48407567e+02  1.48912536e+02  1.49165606e+02  1.50802776e+02
  1.51584630e+02  1.57633889e+02  1.58938144e+02  1.58956502e+02
  1.63267115e+02  1.64188964e+02  1.64960890e+02  1.66294281e+02
  1.68205106e+02  1.68399273e+02  1.70621405e+02  1.71268575e+02
  1.71509314e+02  1.72966312e+02  1.74644664e+02  1.74710408e+02
  1.79019423e+02  1.81095791e+02  1.82868270e+02  1.82965600e+02
  1.89562752e+02  1.89574834e+02  1.89672310e+02  1.91027077e+02
  1.94950274e+02  1.99518927e+02  2.01784542e+02  2.04149936e+02
  2.06118964e+02  2.08133270e+02  2.09047338e+02  2.09294404e+02
  2.09568207e+02  2.10601509e+02  2.13399135e+02  2.15422119e+02
  2.21445846e+02  2.22947849e+02  2.24805184e+02  2.25145886e+02
  2.26628167e+02  2.28189327e+02  2.28893032e+02  2.35044073e+02
  2.36284670e+02  2.36684500e+02  2.37351876e+02  2.37904515e+02
  2.39673843e+02  2.40087383e+02  2.40746217e+02  2.42298224e+02
  2.44455371e+02  2.45745089e+02  2.47396543e+02  2.47424733e+02
  2.49133124e+02  2.50199516e+02  2.50956709e+02  2.51005724e+02
  2.52138755e+02  2.56224103e+02  2.56233725e+02  2.57266362e+02
  2.58179264e+02  2.60083093e+02  2.60765499e+02  2.62492064e+02
  2.63648761e+02  2.65056624e+02  2.66105443e+02  2.66165893e+02
  2.66927189e+02  2.73760950e+02  2.75046082e+02  2.76765168e+02
  2.77043285e+02  2.78210634e+02  2.78449570e+02  2.78926353e+02
  2.82206256e+02  2.82325028e+02  2.84101176e+02  2.86464187e+02
  2.86772706e+02  2.86931290e+02  2.87806515e+02  2.88479049e+02
  2.88826115e+02  2.89886738e+02  2.90002505e+02  2.90633014e+02
  2.90673531e+02  2.91437334e+02  2.91755546e+02  2.92387265e+02
  2.93628281e+02  2.94666653e+02  2.94932601e+02  2.96188315e+02
  2.96502288e+02  2.96822454e+02  2.97975474e+02  2.98212430e+02
  3.00668612e+02  3.01696582e+02  3.01876822e+02  3.02112561e+02
  3.03572646e+02  3.04409455e+02  3.04449763e+02  3.06384175e+02
  3.06727103e+02  3.07812719e+02  3.08096964e+02  3.10210664e+02
  3.11984654e+02  3.12755351e+02  3.14574421e+02  3.17598550e+02
  3.17861441e+02  3.19020009e+02  3.20899374e+02  3.21383177e+02
  3.23073902e+02  3.23170946e+02  3.23359694e+02  3.23678838e+02
  3.26023906e+02  3.26326863e+02  3.27089227e+02  3.27093677e+02
  3.29794865e+02  3.30083446e+02  3.31713138e+02  3.34824512e+02
  3.34942982e+02  3.36264366e+02  3.38064250e+02  3.41586114e+02
  3.42427604e+02  3.43392884e+02  3.45169167e+02  3.45467793e+02
  3.50754649e+02  3.51098770e+02  3.52589335e+02  3.52938639e+02
  3.53122732e+02  3.57327858e+02  3.57432774e+02  3.60230626e+02
  3.60404347e+02  3.60494199e+02  3.63639297e+02  3.65528706e+02
  3.66902709e+02  3.67026251e+02  3.67221496e+02  3.68309635e+02
  3.68871842e+02  3.70497366e+02  3.70665008e+02  3.71474657e+02
  3.72391756e+02  3.73902990e+02  3.74044271e+02  3.75975458e+02
  3.76103509e+02  3.78576962e+02  3.79102861e+02  3.81301733e+02
  3.83305336e+02  3.84246014e+02  3.89847138e+02  3.89945653e+02
  3.94941529e+02  3.96037631e+02  4.06941403e+02  4.07718412e+02
  4.13881992e+02  4.14385640e+02  4.14433011e+02  4.15231967e+02
  4.18896984e+02  4.19530524e+02  4.20454152e+02  4.20949962e+02
  4.29050163e+02  4.31102150e+02  4.34196834e+02  4.34808157e+02
  4.44554017e+02  4.45936030e+02  4.67300177e+02  4.73149208e+02]
sorted_val_rewards: [-103.15213887  -87.66500552  -84.84678494  -81.8475632   -81.40890617
  -80.85477622  -80.48391381  -80.25156009  -33.34809777  -20.41800932
  -20.1312764   -15.36293844   -1.89633986   -0.57284213    4.38318042
    6.83923461    6.84166284   27.01133577   33.68434584   35.05308872
   50.52841486   56.63572585   57.7674455    69.90236244   81.30023532
   92.20740196   92.26562045  101.50661113  125.53777532  157.73723206
  158.45436886  169.19923675  185.35424212  204.55988076  205.26719392
  214.62630405  233.63745377  266.35869922  284.93230584  291.329522
  320.09463125  324.01979761  333.04070292  361.8462674   390.75171849
  400.04134269  403.13796959  423.13558716]
maximum traj length 200
maximum traj length 200
num train_obs 52326
num train_labels 52326
num val_obs 1128
num val_labels 1128
ModuleList(
  (0): Linear(in_features=19, out_features=128, bias=True)
  (1): Linear(in_features=128, out_features=64, bias=True)
  (2): Linear(in_features=64, out_features=1, bias=False)
)
Training reward model from scratch...
Total number of parameters: 10880
Number of trainable paramters: 10880
device: cuda:1
end of epoch 0: val_loss 0.19559689475805647, val_acc 0.9175531914893617
trigger times: 0
saving model weights...
end of epoch 1: val_loss 0.20353989676452308, val_acc 0.9175531914893617
trigger times: 1
end of epoch 2: val_loss 0.20849437069975327, val_acc 0.9166666666666666
trigger times: 2
end of epoch 3: val_loss 0.2101036764999019, val_acc 0.9193262411347518
trigger times: 3
end of epoch 4: val_loss 0.21548395220289965, val_acc 0.9175531914893617
trigger times: 4
end of epoch 5: val_loss 0.22666641528664933, val_acc 0.9184397163120568
trigger times: 5
end of epoch 6: val_loss 0.22355051884528437, val_acc 0.9202127659574468
trigger times: 6
end of epoch 7: val_loss 0.23634233801972482, val_acc 0.9131205673758865
trigger times: 7
end of epoch 8: val_loss 0.24597125268510836, val_acc 0.9148936170212766
trigger times: 8
end of epoch 9: val_loss 0.23728740684355798, val_acc 0.9157801418439716
trigger times: 9
end of epoch 10: val_loss 0.23984643313290055, val_acc 0.9193262411347518
trigger times: 10
Early stopping.
0 -30.934511817991734 -103.1521388660611
1 -30.04072070121765 -87.66500551980913
2 -25.62351336237043 -84.84678494475872
3 -26.711684965062886 -81.84756319767409
4 -23.519888215698302 -81.40890616600856
5 -29.122672164812684 -80.85477622402837
6 -28.627882913686335 -80.48391381073206
7 -27.89356193691492 -80.25156008912637
8 -16.373525140807033 -33.34809776864483
9 -17.05258203332778 -20.418009315237114
10 -16.94781652931124 -20.131276401477507
11 -15.146576997824013 -15.362938437720853
12 -16.679137996863574 -1.8963398599782397
13 -16.9038123274222 -0.5728421252635456
14 -13.37957839667797 4.383180415256293
15 -12.576086055953056 6.8392346078963
16 -16.671362121473067 6.841662837067183
17 -14.29126717778854 27.01133577467053
18 -11.043194084893912 33.68434584390655
19 -14.287159845465794 35.05308871945419
20 -11.376835726201534 50.52841485696464
21 -9.863515922334045 56.635725849291575
22 -12.203385428059846 57.76744549995627
23 -10.195036183227785 69.90236244353298
24 -11.336519721255172 81.30023532085879
25 -6.970563450478949 92.20740196031777
26 -10.315892004175112 92.26562045392546
27 -9.517851568991318 101.50661112827956
28 -12.71710492996499 125.53777532052302
29 -9.165507340338081 157.73723206248386
30 -7.7861447697505355 158.4543688649787
31 -7.794704674859531 169.19923674906562
32 -5.954628939507529 185.35424212127486
33 -9.804123563109897 204.5598807600962
34 -4.988438282161951 205.26719391532652
35 2.939910903805867 214.6263040548001
36 -6.511437235865742 233.63745376530167
37 -1.8627629624679685 266.3586992205008
38 0.9922535964287817 284.9323058364518
39 -5.886638954281807 291.32952200448
40 0.15580911003053188 320.0946312511725
41 0.9817581954412162 324.0197976082746
42 -0.790045702829957 333.0407029156643
43 3.091848699375987 361.84626739841684
44 3.7990198242478073 390.7517184882046
45 2.168083968339488 400.0413426933392
46 2.3875330903101712 403.13796958654353
47 -3.544122777180746 423.1355871564197
train accuracy: 0.9711042311661506
validation accuracy: 0.9193262411347518
