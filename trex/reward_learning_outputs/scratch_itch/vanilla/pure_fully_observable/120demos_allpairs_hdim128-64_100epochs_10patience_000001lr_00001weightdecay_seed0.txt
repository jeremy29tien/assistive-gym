demos: (480, 200, 19)
demo_rewards: (480,)
sorted_train_rewards: [-1.68281407e+02 -1.45727567e+02 -1.39123043e+02 -1.25906495e+02
 -1.23737226e+02 -1.18441257e+02 -1.15454518e+02 -1.15278652e+02
 -1.14763156e+02 -1.14085096e+02 -1.12885489e+02 -1.11179560e+02
 -1.10579609e+02 -1.10248073e+02 -1.06969949e+02 -1.05880618e+02
 -1.03152139e+02 -1.01565908e+02 -1.00495946e+02 -1.00348353e+02
 -9.79572956e+01 -9.72257679e+01 -9.60581398e+01 -9.47527923e+01
 -9.42721572e+01 -9.39936009e+01 -9.08470847e+01 -8.99058909e+01
 -8.98050349e+01 -8.92193126e+01 -8.88554189e+01 -8.76650055e+01
 -8.71119989e+01 -8.58361739e+01 -8.48467849e+01 -8.42859587e+01
 -8.40914856e+01 -8.33560899e+01 -8.18475632e+01 -8.14466377e+01
 -8.14089062e+01 -8.10067480e+01 -8.08547762e+01 -8.04839138e+01
 -8.02515601e+01 -7.86319117e+01 -7.84173816e+01 -7.80515779e+01
 -7.63592934e+01 -7.50296954e+01 -7.48307224e+01 -7.41288702e+01
 -7.35268215e+01 -7.30055356e+01 -7.26136252e+01 -7.23199016e+01
 -7.10097190e+01 -7.02497554e+01 -6.98788242e+01 -6.90105689e+01
 -6.88032812e+01 -6.82574483e+01 -6.81709241e+01 -6.78589144e+01
 -6.77543594e+01 -6.77033281e+01 -6.58589998e+01 -6.53374190e+01
 -6.49762184e+01 -5.92349209e+01 -5.78572803e+01 -5.71589430e+01
 -5.50587300e+01 -5.45877794e+01 -5.38140519e+01 -5.23998422e+01
 -5.20708438e+01 -5.03190683e+01 -4.94482556e+01 -4.87197115e+01
 -4.55497329e+01 -4.52135310e+01 -4.44901949e+01 -4.39133519e+01
 -4.35323363e+01 -4.26845918e+01 -4.13106519e+01 -3.93647734e+01
 -3.84347912e+01 -3.72825558e+01 -3.64541601e+01 -3.63795012e+01
 -3.56366006e+01 -3.51896507e+01 -3.36956904e+01 -3.33480978e+01
 -2.77930868e+01 -2.71949370e+01 -2.63456513e+01 -2.26604777e+01
 -2.17096738e+01 -2.11615803e+01 -2.04180093e+01 -2.01425951e+01
 -2.01312764e+01 -2.00548875e+01 -1.87912468e+01 -1.74207898e+01
 -1.68901975e+01 -1.61143764e+01 -1.53629384e+01 -1.44711839e+01
 -1.39267768e+01 -1.12508710e+01 -7.28306957e+00 -6.03798033e+00
 -4.48405644e+00 -1.63608121e+00 -1.43319012e+00 -1.25215708e+00
 -5.72842125e-01  2.69474090e-01  8.48755488e-01  9.71479122e-01
  3.13137341e+00  4.09388103e+00  4.38318042e+00  6.23806049e+00
  6.84166284e+00  8.10954932e+00  8.62917691e+00  1.29952266e+01
  1.34336148e+01  1.51800256e+01  1.58979399e+01  1.65923688e+01
  1.89453788e+01  1.94910199e+01  1.94916920e+01  2.05305881e+01
  2.15104917e+01  2.41170029e+01  2.43710703e+01  2.58660332e+01
  2.60724768e+01  2.74672520e+01  2.75751580e+01  2.85285750e+01
  3.05892332e+01  3.27442577e+01  3.36843458e+01  3.37899159e+01
  3.41611587e+01  3.42153602e+01  3.48663961e+01  3.50530887e+01
  3.72456187e+01  3.99267393e+01  3.99602846e+01  4.23875378e+01
  4.39159825e+01  4.42327291e+01  4.48500197e+01  4.83776686e+01
  4.88736658e+01  5.05284149e+01  5.53688861e+01  5.56692378e+01
  5.66357258e+01  5.77674455e+01  5.78923918e+01  5.86309323e+01
  5.93436812e+01  6.02906417e+01  6.47458201e+01  6.49603340e+01
  6.68749790e+01  6.76039372e+01  6.78694515e+01  6.85395993e+01
  6.85552576e+01  6.99023624e+01  7.00722782e+01  7.10566011e+01
  7.18958063e+01  7.42631002e+01  7.64437617e+01  7.80250544e+01
  8.00743291e+01  8.04122550e+01  8.13002353e+01  8.18901469e+01
  8.32565101e+01  8.33459185e+01  8.87279953e+01  9.04900629e+01
  9.13388441e+01  9.22074020e+01  9.22656205e+01  9.30086833e+01
  9.30344412e+01  9.73584524e+01  9.78474792e+01  9.87173322e+01
  9.92848455e+01  1.01506611e+02  1.02399087e+02  1.03162159e+02
  1.03450957e+02  1.03768508e+02  1.04406383e+02  1.07092483e+02
  1.07710068e+02  1.11625387e+02  1.11924895e+02  1.13547690e+02
  1.14761007e+02  1.16179984e+02  1.16837433e+02  1.21326132e+02
  1.25537775e+02  1.33048584e+02  1.33573303e+02  1.36511921e+02
  1.37758285e+02  1.39131419e+02  1.41638120e+02  1.41844812e+02
  1.42424512e+02  1.43496609e+02  1.43510881e+02  1.46199060e+02
  1.46556236e+02  1.48407567e+02  1.48912536e+02  1.49165606e+02
  1.50802776e+02  1.51584630e+02  1.57633889e+02  1.57737232e+02
  1.58454369e+02  1.58956502e+02  1.63267115e+02  1.64188964e+02
  1.64960890e+02  1.66294281e+02  1.68205106e+02  1.68399273e+02
  1.69199237e+02  1.70621405e+02  1.71268575e+02  1.71509314e+02
  1.72966312e+02  1.74644664e+02  1.74710408e+02  1.79019423e+02
  1.81095791e+02  1.82868270e+02  1.82965600e+02  1.85354242e+02
  1.89562752e+02  1.89574834e+02  1.89672310e+02  1.91027077e+02
  2.01784542e+02  2.04149936e+02  2.04559881e+02  2.05267194e+02
  2.06118964e+02  2.08133270e+02  2.09294404e+02  2.09568207e+02
  2.10601509e+02  2.13399135e+02  2.14626304e+02  2.15422119e+02
  2.21445846e+02  2.22947849e+02  2.25145886e+02  2.26628167e+02
  2.28189327e+02  2.28893032e+02  2.33637454e+02  2.35044073e+02
  2.36284670e+02  2.36684500e+02  2.37351876e+02  2.37904515e+02
  2.39673843e+02  2.40087383e+02  2.40746217e+02  2.44455371e+02
  2.45745089e+02  2.47396543e+02  2.49133124e+02  2.50199516e+02
  2.50956709e+02  2.51005724e+02  2.52138755e+02  2.56224103e+02
  2.56233725e+02  2.57266362e+02  2.58179264e+02  2.60083093e+02
  2.60765499e+02  2.62492064e+02  2.63648761e+02  2.65056624e+02
  2.66105443e+02  2.66165893e+02  2.66358699e+02  2.66927189e+02
  2.73760950e+02  2.75046082e+02  2.76765168e+02  2.77043285e+02
  2.78210634e+02  2.78449570e+02  2.82206256e+02  2.82325028e+02
  2.84101176e+02  2.84932306e+02  2.86464187e+02  2.86772706e+02
  2.86931290e+02  2.87806515e+02  2.88479049e+02  2.88826115e+02
  2.89886738e+02  2.90633014e+02  2.90673531e+02  2.91437334e+02
  2.91755546e+02  2.92387265e+02  2.93628281e+02  2.94666653e+02
  2.94932601e+02  2.96188315e+02  2.96502288e+02  2.96822454e+02
  2.97975474e+02  2.98212430e+02  3.00668612e+02  3.01696582e+02
  3.01876822e+02  3.02112561e+02  3.03572646e+02  3.04409455e+02
  3.04449763e+02  3.06727103e+02  3.07812719e+02  3.08096964e+02
  3.10210664e+02  3.11984654e+02  3.12755351e+02  3.14574421e+02
  3.17861441e+02  3.19020009e+02  3.20094631e+02  3.20899374e+02
  3.21383177e+02  3.23073902e+02  3.23170946e+02  3.23359694e+02
  3.23678838e+02  3.24019798e+02  3.26023906e+02  3.26326863e+02
  3.27089227e+02  3.27093677e+02  3.29794865e+02  3.33040703e+02
  3.34824512e+02  3.34942982e+02  3.38064250e+02  3.41586114e+02
  3.42427604e+02  3.43392884e+02  3.45169167e+02  3.45467793e+02
  3.50754649e+02  3.51098770e+02  3.52589335e+02  3.52938639e+02
  3.53122732e+02  3.57327858e+02  3.57432774e+02  3.60404347e+02
  3.60494199e+02  3.61846267e+02  3.63639297e+02  3.65528706e+02
  3.66902709e+02  3.67026251e+02  3.67221496e+02  3.70665008e+02
  3.71474657e+02  3.72391756e+02  3.74044271e+02  3.75975458e+02
  3.76103509e+02  3.78576962e+02  3.79102861e+02  3.81301733e+02
  3.83305336e+02  3.84246014e+02  3.89847138e+02  3.89945653e+02
  3.90751718e+02  3.94941529e+02  3.96037631e+02  4.00041343e+02
  4.03137970e+02  4.06941403e+02  4.07718412e+02  4.13881992e+02
  4.14385640e+02  4.14433011e+02  4.15231967e+02  4.18896984e+02
  4.19530524e+02  4.20454152e+02  4.20949962e+02  4.23135587e+02
  4.29050163e+02  4.31102150e+02  4.34196834e+02  4.34808157e+02
  4.44554017e+02  4.45936030e+02  4.67300177e+02  4.73149208e+02]
sorted_val_rewards: [-133.97354737 -106.29807636 -106.26498585  -97.24485765  -78.93406316
  -65.00607092  -64.31517893  -63.24633649  -63.1014303   -57.66105273
  -56.30990465  -36.57284828  -34.92774699  -34.48765021  -29.59331475
  -21.77695065   -1.89633986    0.53212097    4.23223568    6.83923461
   19.62253484   27.01133577   55.12239522   55.92026357   65.16806407
   87.34870755  105.72097092  148.38223634  158.93814401  194.95027356
  199.51892684  209.04733791  224.80518376  242.29822404  247.42473325
  278.92635304  290.00250527  291.329522    306.38417501  317.59854966
  330.08344617  331.71313838  336.26436621  360.23062633  368.30963475
  368.8718416   370.49736551  373.90298986]
maximum traj length 200
maximum traj length 200
num train_obs 7140
num train_labels 7140
num val_obs 1128
num val_labels 1128
ModuleList(
  (0): Linear(in_features=19, out_features=128, bias=True)
  (1): Linear(in_features=128, out_features=64, bias=True)
  (2): Linear(in_features=64, out_features=1, bias=False)
)
Training reward model from scratch...
Total number of parameters: 10880
Number of trainable paramters: 10880
device: cuda:1
end of epoch 0: val_loss 0.2027077353658107, val_acc 0.9131205673758865
trigger times: 0
saving model weights...
end of epoch 1: val_loss 0.1838339472672568, val_acc 0.9113475177304965
trigger times: 0
saving model weights...
end of epoch 2: val_loss 0.19752316388970706, val_acc 0.9104609929078015
trigger times: 1
end of epoch 3: val_loss 0.18858205467267294, val_acc 0.9148936170212766
trigger times: 2
end of epoch 4: val_loss 0.1852635702601362, val_acc 0.9175531914893617
trigger times: 3
end of epoch 5: val_loss 0.19885700250568925, val_acc 0.9148936170212766
trigger times: 4
end of epoch 6: val_loss 0.19429145736634362, val_acc 0.9175531914893617
trigger times: 5
end of epoch 7: val_loss 0.21547338958707501, val_acc 0.9086879432624113
trigger times: 6
end of epoch 8: val_loss 0.20249424636877206, val_acc 0.9166666666666666
trigger times: 7
end of epoch 9: val_loss 0.20053181549989665, val_acc 0.9131205673758865
trigger times: 8
end of epoch 10: val_loss 0.22177284173727932, val_acc 0.9166666666666666
trigger times: 9
end of epoch 11: val_loss 0.20911801945679145, val_acc 0.9184397163120568
trigger times: 10
Early stopping.
0 -34.72144032269716 -133.973547371322
1 -30.899888575077057 -106.29807635708414
2 -27.53911940008402 -106.26498585222654
3 -29.616690084338188 -97.24485765376211
4 -28.77995255589485 -78.93406316283158
5 -25.10343310236931 -65.00607091797544
6 -26.132822720333934 -64.31517892724126
7 -26.742932192981243 -63.24633649146097
8 -22.711986253008945 -63.101430300225374
9 -25.91020866110921 -57.66105272983283
10 -25.10239427536726 -56.30990465208505
11 -20.899484030436724 -36.57284828127824
12 -16.833210790660814 -34.92774699423874
13 -21.196508403401822 -34.487650213835884
14 -15.45166629605228 -29.593314750499733
15 -19.438687820686027 -21.776950647506872
16 -20.508356563339476 -1.8963398599782397
17 -18.741108643822372 0.5321209736499255
18 -20.504434258909896 4.232235681838149
19 -16.93099313424318 6.8392346078963
20 -16.247053437808063 19.622534836185636
21 -18.378615649417043 27.01133577467053
22 -17.66093586414354 55.12239522211616
23 -13.273364780819975 55.92026357237822
24 -15.804570775013417 65.1680640695934
25 -12.633337327453773 87.3487075539824
26 -13.101847865327727 105.72097091834365
27 -14.109012044616975 148.38223634397093
28 -10.855938137392513 158.9381440127044
29 -9.643145221256418 194.9502735624309
30 -7.3209410527779255 199.51892684347123
31 -7.6600896454183385 209.04733790839154
32 -11.234164423658513 224.80518375748704
33 -7.6721926354803145 242.29822403524432
34 -9.264602584837121 247.4247332535776
35 -7.001982075016713 278.9263530439534
36 -2.9331985852622893 290.0025052732212
37 -10.275778761337278 291.32952200448
38 -3.7879044879809953 306.3841750088036
39 -7.764514816459268 317.59854966426605
40 -4.354012453259202 330.083446167866
41 -3.9276865898864344 331.71313838439016
42 -5.7257502459106036 336.2643662087101
43 -2.5617444964736933 360.2306263300218
44 -5.658129761257442 368.3096347545002
45 -7.759546491899528 368.87184160352797
46 -1.874745793378679 370.4973655070732
47 -5.654803240497131 373.9029898572837
train accuracy: 0.9659663865546219
validation accuracy: 0.9184397163120568
