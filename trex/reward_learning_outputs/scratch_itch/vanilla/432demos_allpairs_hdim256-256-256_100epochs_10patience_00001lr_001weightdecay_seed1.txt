demos: (480, 200, 42)
demo_rewards: (480,)
maximum traj length 200
maximum traj length 200
num train_obs 93096
num train_labels 93096
num val_obs 1128
num val_labels 1128
ModuleList(
  (0): Linear(in_features=42, out_features=256, bias=True)
  (1): Linear(in_features=256, out_features=256, bias=True)
  (2): Linear(in_features=256, out_features=256, bias=True)
  (3): Linear(in_features=256, out_features=1, bias=False)
)
Training reward model from scratch...
Total number of parameters: 142848
Number of trainable paramters: 142848
device: cuda:0
end of epoch 0: val_loss 0.21849955343000815, val_acc 0.9202127659574468
trigger times: 0
saving model weights...
end of epoch 1: val_loss 0.22249379884914142, val_acc 0.9122340425531915
trigger times: 1
end of epoch 2: val_loss 0.23719909813557277, val_acc 0.9113475177304965
trigger times: 2
end of epoch 3: val_loss 0.19973934601093776, val_acc 0.9148936170212766
trigger times: 0
saving model weights...
end of epoch 4: val_loss 0.2017283187820599, val_acc 0.9202127659574468
trigger times: 1
end of epoch 5: val_loss 0.1877719104411077, val_acc 0.924645390070922
trigger times: 0
saving model weights...
end of epoch 6: val_loss 0.2043977463556327, val_acc 0.9219858156028369
trigger times: 1
end of epoch 7: val_loss 0.21519109565132666, val_acc 0.9157801418439716
trigger times: 2
end of epoch 8: val_loss 0.20657389893801908, val_acc 0.9290780141843972
trigger times: 3
end of epoch 9: val_loss 0.21278047438133701, val_acc 0.925531914893617
trigger times: 4
end of epoch 10: val_loss 0.20729179745037102, val_acc 0.9273049645390071
trigger times: 5
end of epoch 11: val_loss 0.19835295798494398, val_acc 0.9237588652482269
trigger times: 6
end of epoch 12: val_loss 0.1785813125593253, val_acc 0.9290780141843972
trigger times: 0
saving model weights...
end of epoch 13: val_loss 0.18874069026560583, val_acc 0.924645390070922
trigger times: 1
end of epoch 14: val_loss 0.18094019278759962, val_acc 0.9317375886524822
trigger times: 2
end of epoch 15: val_loss 0.19344151799023462, val_acc 0.9273049645390071
trigger times: 3
end of epoch 16: val_loss 0.1830430429117058, val_acc 0.9273049645390071
trigger times: 4
end of epoch 17: val_loss 0.22015161720358015, val_acc 0.9202127659574468
trigger times: 5
end of epoch 18: val_loss 0.19400165416662546, val_acc 0.9281914893617021
trigger times: 6
end of epoch 19: val_loss 0.21645319057376358, val_acc 0.9264184397163121
trigger times: 7
end of epoch 20: val_loss 0.21590188134702096, val_acc 0.925531914893617
trigger times: 8
end of epoch 21: val_loss 0.2069273384419134, val_acc 0.9219858156028369
trigger times: 9
end of epoch 22: val_loss 0.19519182720116376, val_acc 0.9273049645390071
trigger times: 10
Early stopping.
0 -25.34255015105009 -103.1521388660611
1 -23.846525540575385 -87.66500551980913
2 -21.67799430899322 -84.84678494475872
3 -20.52205101121217 -81.84756319767409
4 -18.509331034496427 -81.40890616600856
5 -24.15669896453619 -80.85477622402837
6 -20.615575370378792 -80.48391381073206
7 -21.331870863214135 -80.25156008912637
8 -12.30350745562464 -33.34809776864483
9 -12.328669372946024 -20.418009315237114
10 -13.001636242493987 -20.131276401477507
11 -14.215588309802115 -15.362938437720853
12 -9.887830907478929 -1.8963398599782397
13 -11.590725134126842 -0.5728421252635456
14 -6.656298093497753 4.383180415256293
15 -8.38028958439827 6.8392346078963
16 -10.889515101909637 6.841662837067183
17 -9.622928935103118 27.01133577467053
18 -7.910802197642624 33.68434584390655
19 -8.842934326268733 35.05308871945419
20 -8.36840739659965 50.52841485696464
21 -4.361847622320056 56.635725849291575
22 -7.2575345588847995 57.76744549995627
23 -6.733138062991202 69.90236244353298
24 -7.635208890773356 81.30023532085879
25 -0.744042837060988 92.20740196031777
26 -6.079563995823264 92.26562045392546
27 -4.421536760404706 101.50661112827956
28 -6.0752604668959975 125.53777532052302
29 -2.2592452438548207 157.73723206248386
30 -2.2857708605006337 158.4543688649787
31 -2.5301579078659415 169.19923674906562
32 -0.656204940751195 185.35424212127486
33 -3.7855264833196998 204.5598807600962
34 0.586575030349195 205.26719391532652
35 6.571319289505482 214.6263040548001
36 -0.8214926514774561 233.63745376530167
37 2.5416560731828213 266.3586992205008
38 4.3100001104176044 284.9323058364518
39 0.05012676864862442 291.32952200448
40 4.818498608656228 320.0946312511725
41 6.731831598095596 324.0197976082746
42 2.307308285497129 333.0407029156643
43 6.470635055564344 361.84626739841684
44 8.71260449104011 390.7517184882046
45 7.264983680099249 400.0413426933392
46 7.672417821362615 403.13796958654353
47 3.2103665014728904 423.1355871564197
train accuracy: 0.9616847125547822
validation accuracy: 0.9273049645390071
