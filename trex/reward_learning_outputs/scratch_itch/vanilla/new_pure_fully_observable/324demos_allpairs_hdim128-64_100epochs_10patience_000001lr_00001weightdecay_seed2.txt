demos: (480, 200, 20)
demo_rewards: (480,)
maximum traj length 200
maximum traj length 200
num train_obs 52326
num train_labels 52326
num val_obs 1128
num val_labels 1128
ModuleList(
  (0): Linear(in_features=20, out_features=128, bias=True)
  (1): Linear(in_features=128, out_features=64, bias=True)
  (2): Linear(in_features=64, out_features=1, bias=False)
)
Training reward model from scratch...
Total number of parameters: 11008
Number of trainable paramters: 11008
device: cuda:0
end of epoch 0: val_loss 0.06604159984217227, val_acc 0.9716312056737588
trigger times: 0
saving model weights...
end of epoch 1: val_loss 0.05388987868788884, val_acc 0.9769503546099291
trigger times: 0
saving model weights...
end of epoch 2: val_loss 0.04439529822570053, val_acc 0.9831560283687943
trigger times: 0
saving model weights...
end of epoch 3: val_loss 0.04230799598535251, val_acc 0.9822695035460993
trigger times: 0
saving model weights...
end of epoch 4: val_loss 0.035804502473470494, val_acc 0.9867021276595744
trigger times: 0
saving model weights...
end of epoch 5: val_loss 0.033365019761338814, val_acc 0.9849290780141844
trigger times: 0
saving model weights...
end of epoch 6: val_loss 0.0433449970573864, val_acc 0.9831560283687943
trigger times: 1
end of epoch 7: val_loss 0.03558766445420135, val_acc 0.9867021276595744
trigger times: 2
end of epoch 8: val_loss 0.034838652381319814, val_acc 0.9858156028368794
trigger times: 3
end of epoch 9: val_loss 0.030782613107052215, val_acc 0.9867021276595744
trigger times: 0
saving model weights...
end of epoch 10: val_loss 0.03128192934584621, val_acc 0.9884751773049646
trigger times: 1
end of epoch 11: val_loss 0.03732186102310187, val_acc 0.9867021276595744
trigger times: 2
end of epoch 12: val_loss 0.024997291056755334, val_acc 0.9911347517730497
trigger times: 0
saving model weights...
end of epoch 13: val_loss 0.029321225528031618, val_acc 0.9884751773049646
trigger times: 1
end of epoch 14: val_loss 0.023145218878397822, val_acc 0.9884751773049646
trigger times: 0
saving model weights...
end of epoch 15: val_loss 0.04771360040169671, val_acc 0.9831560283687943
trigger times: 1
end of epoch 16: val_loss 0.03906061396327928, val_acc 0.9867021276595744
trigger times: 2
end of epoch 17: val_loss 0.02882715405719688, val_acc 0.9875886524822695
trigger times: 3
end of epoch 18: val_loss 0.02801090189172949, val_acc 0.9858156028368794
trigger times: 4
end of epoch 19: val_loss 0.0219047113197192, val_acc 0.9893617021276596
trigger times: 0
saving model weights...
end of epoch 20: val_loss 0.027556978409855156, val_acc 0.9893617021276596
trigger times: 1
end of epoch 21: val_loss 0.028544250913400605, val_acc 0.9884751773049646
trigger times: 2
end of epoch 22: val_loss 0.022522502687737988, val_acc 0.9911347517730497
trigger times: 3
end of epoch 23: val_loss 0.02371367521850769, val_acc 0.9893617021276596
trigger times: 4
end of epoch 24: val_loss 0.02205353264128659, val_acc 0.9920212765957447
trigger times: 5
end of epoch 25: val_loss 0.03149745505274972, val_acc 0.9875886524822695
trigger times: 6
end of epoch 26: val_loss 0.02871847814745112, val_acc 0.9902482269503546
trigger times: 7
end of epoch 27: val_loss 0.019694843016887068, val_acc 0.9929078014184397
trigger times: 0
saving model weights...
end of epoch 28: val_loss 0.03445125861625017, val_acc 0.9884751773049646
trigger times: 1
end of epoch 29: val_loss 0.02538648095555043, val_acc 0.9893617021276596
trigger times: 2
end of epoch 30: val_loss 0.022883655583363898, val_acc 0.9893617021276596
trigger times: 3
end of epoch 31: val_loss 0.017421326612394337, val_acc 0.9937943262411347
trigger times: 0
saving model weights...
end of epoch 32: val_loss 0.026461937722748963, val_acc 0.9893617021276596
trigger times: 1
end of epoch 33: val_loss 0.031230866565045947, val_acc 0.9867021276595744
trigger times: 2
end of epoch 34: val_loss 0.03277054427508608, val_acc 0.9875886524822695
trigger times: 3
end of epoch 35: val_loss 0.024324833156992524, val_acc 0.9875886524822695
trigger times: 4
end of epoch 36: val_loss 0.017908485721206846, val_acc 0.9929078014184397
trigger times: 5
end of epoch 37: val_loss 0.02873517212585253, val_acc 0.9884751773049646
trigger times: 6
end of epoch 38: val_loss 0.03181440710893585, val_acc 0.9875886524822695
trigger times: 7
end of epoch 39: val_loss 0.025754901832142553, val_acc 0.9884751773049646
trigger times: 8
end of epoch 40: val_loss 0.022955607583301323, val_acc 0.9875886524822695
trigger times: 9
end of epoch 41: val_loss 0.018255233572050854, val_acc 0.9937943262411347
trigger times: 10
Early stopping.
0 -87.31090526282787 -105.98216711742712
1 -66.36453214287758 -76.56190549649224
2 -65.48318145424128 -72.51895167527836
3 -59.03774026222527 -71.91238572832597
4 -64.47312143445015 -65.0447729475643
5 -60.56190233677626 -62.468929493642136
6 -54.91964430361986 -52.67073108492849
7 -55.77534504979849 -51.23339439449891
8 -53.534854270517826 -39.43428523620552
9 -46.583630412817 -32.334780854820806
10 -44.75475905183703 -29.2670803592239
11 -46.3909468613565 -28.32430140278431
12 -43.33799977786839 -20.474216556664466
13 -42.32606936618686 -18.35850790811357
14 -38.576379649341106 -10.414154091154558
15 -36.1472627222538 -8.23453209197286
16 -24.86084533110261 5.860615077611318
17 -26.01716697961092 6.405851138634589
18 -23.72883161716163 10.59045361641601
19 -17.669833317399025 23.11531098032165
20 -3.2580100977793336 42.07542792510302
21 4.484996953979135 58.035310213628016
22 13.77258349955082 71.83091404314686
23 16.11917175538838 73.70710134523536
24 19.48997213318944 81.12720411950356
25 22.70936376787722 82.32866985010293
26 22.042933518067002 94.15973544827216
27 43.566110011190176 127.57280425644888
28 64.59069016203284 154.1078531458257
29 66.64325734972954 157.2296406215669
30 70.76350050978363 162.52503215880944
31 71.38966750726104 165.06380818034006
32 71.84827630408108 168.01804822219268
33 73.89598876610398 174.18616289555482
34 89.14852211624384 200.17430318587992
35 109.56814222037792 234.32338495546477
36 122.07907005026937 245.8505913555113
37 132.84146150387824 272.081841110809
38 145.82488543447107 301.6965823877335
39 148.5211347192526 303.3874010483866
40 163.84033358469605 322.2187597685313
41 172.48324267566204 333.0407029156643
42 172.69368377700448 333.9199654934176
43 176.02997796609998 337.0980913827745
44 179.91557543724775 341.5515801120419
45 178.23667419329286 343.3928836976398
46 229.842856105417 423.1355871564197
47 231.8305781017989 434.80815706930116
train accuracy: 0.9965982494362268
validation accuracy: 0.9937943262411347
