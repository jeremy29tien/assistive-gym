demos: (480, 200, 20)
demo_rewards: (480,)
maximum traj length 200
maximum traj length 200
num train_obs 52326
num train_labels 52326
num val_obs 1128
num val_labels 1128
ModuleList(
  (0): Linear(in_features=20, out_features=128, bias=True)
  (1): Linear(in_features=128, out_features=64, bias=True)
  (2): Linear(in_features=64, out_features=1, bias=False)
)
Training reward model from scratch...
Total number of parameters: 11008
Number of trainable paramters: 11008
device: cuda:3
end of epoch 0: val_loss 0.07394127432722551, val_acc 0.9663120567375887
trigger times: 0
saving model weights...
end of epoch 1: val_loss 0.0474095157792645, val_acc 0.9804964539007093
trigger times: 0
saving model weights...
end of epoch 2: val_loss 0.03494554382435178, val_acc 0.9858156028368794
trigger times: 0
saving model weights...
end of epoch 3: val_loss 0.03119160967352829, val_acc 0.9867021276595744
trigger times: 0
saving model weights...
end of epoch 4: val_loss 0.022817409467466167, val_acc 0.9893617021276596
trigger times: 0
saving model weights...
end of epoch 5: val_loss 0.025091250386071413, val_acc 0.9902482269503546
trigger times: 1
end of epoch 6: val_loss 0.02266584746290773, val_acc 0.9902482269503546
trigger times: 0
saving model weights...
end of epoch 7: val_loss 0.021317578315566806, val_acc 0.9920212765957447
trigger times: 0
saving model weights...
end of epoch 8: val_loss 0.021075349326494675, val_acc 0.9920212765957447
trigger times: 0
saving model weights...
end of epoch 9: val_loss 0.02440204286906143, val_acc 0.9911347517730497
trigger times: 1
end of epoch 10: val_loss 0.020999655500542547, val_acc 0.9902482269503546
trigger times: 0
saving model weights...
end of epoch 11: val_loss 0.01679296165888593, val_acc 0.9911347517730497
trigger times: 0
saving model weights...
end of epoch 12: val_loss 0.014893683440906698, val_acc 0.9920212765957447
trigger times: 0
saving model weights...
end of epoch 13: val_loss 0.02005705436837373, val_acc 0.9893617021276596
trigger times: 1
end of epoch 14: val_loss 0.02191308357547946, val_acc 0.9911347517730497
trigger times: 2
end of epoch 15: val_loss 0.017209272962338047, val_acc 0.9902482269503546
trigger times: 3
end of epoch 16: val_loss 0.017776058129501237, val_acc 0.9920212765957447
trigger times: 4
end of epoch 17: val_loss 0.01418995646141651, val_acc 0.9946808510638298
trigger times: 0
saving model weights...
end of epoch 18: val_loss 0.01496741720572678, val_acc 0.9937943262411347
trigger times: 1
end of epoch 19: val_loss 0.019051695206021273, val_acc 0.9920212765957447
trigger times: 2
end of epoch 20: val_loss 0.02310365321143326, val_acc 0.9920212765957447
trigger times: 3
end of epoch 21: val_loss 0.01768161881039787, val_acc 0.9929078014184397
trigger times: 4
end of epoch 22: val_loss 0.01690370728230459, val_acc 0.9920212765957447
trigger times: 5
end of epoch 23: val_loss 0.021529103796517006, val_acc 0.9920212765957447
trigger times: 6
end of epoch 24: val_loss 0.017645956763506606, val_acc 0.9920212765957447
trigger times: 7
end of epoch 25: val_loss 0.015429457721745189, val_acc 0.9929078014184397
trigger times: 8
end of epoch 26: val_loss 0.023423897252554064, val_acc 0.9920212765957447
trigger times: 9
end of epoch 27: val_loss 0.012942891843366623, val_acc 0.9937943262411347
trigger times: 0
saving model weights...
end of epoch 28: val_loss 0.020906604445786136, val_acc 0.9920212765957447
trigger times: 1
end of epoch 29: val_loss 0.014348797892102236, val_acc 0.9920212765957447
trigger times: 2
end of epoch 30: val_loss 0.020471144932322407, val_acc 0.9911347517730497
trigger times: 3
end of epoch 31: val_loss 0.016286513358886447, val_acc 0.9929078014184397
trigger times: 4
end of epoch 32: val_loss 0.022518829416861647, val_acc 0.9937943262411347
trigger times: 5
end of epoch 33: val_loss 0.02540379045460192, val_acc 0.9929078014184397
trigger times: 6
end of epoch 34: val_loss 0.023048901596901664, val_acc 0.9920212765957447
trigger times: 7
end of epoch 35: val_loss 0.017731165698895733, val_acc 0.9920212765957447
trigger times: 8
end of epoch 36: val_loss 0.01553194890208438, val_acc 0.9929078014184397
trigger times: 9
end of epoch 37: val_loss 0.012259756041075055, val_acc 0.9937943262411347
trigger times: 0
saving model weights...
end of epoch 38: val_loss 0.015366783072793155, val_acc 0.9937943262411347
trigger times: 1
end of epoch 39: val_loss 0.015831091539145425, val_acc 0.9946808510638298
trigger times: 2
end of epoch 40: val_loss 0.01816515061285106, val_acc 0.9929078014184397
trigger times: 3
end of epoch 41: val_loss 0.01809124590226741, val_acc 0.9911347517730497
trigger times: 4
end of epoch 42: val_loss 0.019649931828464588, val_acc 0.9929078014184397
trigger times: 5
end of epoch 43: val_loss 0.02311598113964283, val_acc 0.9929078014184397
trigger times: 6
end of epoch 44: val_loss 0.02268764933947165, val_acc 0.9911347517730497
trigger times: 7
end of epoch 45: val_loss 0.021747548595293507, val_acc 0.9929078014184397
trigger times: 8
end of epoch 46: val_loss 0.0141550269609368, val_acc 0.9937943262411347
trigger times: 9
end of epoch 47: val_loss 0.016249866498359574, val_acc 0.9929078014184397
trigger times: 10
Early stopping.
0 -79.86951416730881 -136.99350747158917
1 -77.93475672602654 -131.20042885027652
2 -47.85066782683134 -79.41740014534255
3 -44.59946068562567 -72.07719821962127
4 -42.643165772315115 -68.25603958887683
5 -33.133680548518896 -66.08528823114615
6 -37.82179522095248 -62.468929493642136
7 -33.271073361858726 -52.381190645137245
8 -22.968268402852118 -34.57667262029811
9 -23.933160933025647 -31.30331487414688
10 -15.291094238869846 -19.556186372048053
11 -4.535322211217135 -4.632852762406387
12 1.6130367582663894 2.8395038580483685
13 14.071216981858015 22.340428764253097
14 12.378540424630046 23.11531098032165
15 13.428702463395894 24.32920711869632
16 14.950266455300152 32.07856584753425
17 21.923698109574616 33.5723511509563
18 27.851764732040465 40.21293197223649
19 33.70938217267394 47.958561210870805
20 35.52589030331001 51.32677716745781
21 34.14893336733803 53.364882104593235
22 39.79661814915016 61.039255622139066
23 44.97746398951858 63.56172262344406
24 46.41530736209825 66.34646031672955
25 50.165851336554624 71.5960198405553
26 49.14366617053747 74.78385238790305
27 56.34416188765317 78.40511603178545
28 70.1726969149895 96.56619963782883
29 96.49112528725527 131.9840844291858
30 105.61355335265398 144.3512376753812
31 108.79071968561038 160.22463620684547
32 127.06763122044504 180.1423363713056
33 145.4945026235655 203.6017904999808
34 155.17532400181517 214.6263040548001
35 164.33534380490892 226.96827270106405
36 169.2390560777858 232.7713587432071
37 195.33710188791156 266.3586992205008
38 192.20909985620528 267.7439522684791
39 233.2789939060458 324.0197976082746
40 237.43497665412724 327.6748194412485
41 239.17796993535012 333.0407029156643
42 245.31526730768383 341.5515801120419
43 258.16347609553486 361.84626739841684
44 280.5569728910923 390.7517184882046
45 289.58897383511066 400.0413426933392
46 292.35356820351444 403.13796958654353
47 311.9714989877539 423.1355871564197
train accuracy: 0.9973626877651646
validation accuracy: 0.9929078014184397
