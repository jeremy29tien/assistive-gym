demos: (480, 200, 20)
demo_rewards: (480,)
maximum traj length 200
maximum traj length 200
num train_obs 7140
num train_labels 7140
num val_obs 1128
num val_labels 1128
ModuleList(
  (0): Linear(in_features=20, out_features=128, bias=True)
  (1): Linear(in_features=128, out_features=64, bias=True)
  (2): Linear(in_features=64, out_features=1, bias=False)
)
Training reward model from scratch...
Total number of parameters: 11008
Number of trainable paramters: 11008
device: cuda:2
end of epoch 0: val_loss 0.1281903631731216, val_acc 0.9592198581560284
trigger times: 0
saving model weights...
end of epoch 1: val_loss 0.10477282851884269, val_acc 0.9565602836879432
trigger times: 0
saving model weights...
end of epoch 2: val_loss 0.09401696419381961, val_acc 0.9601063829787234
trigger times: 0
saving model weights...
end of epoch 3: val_loss 0.09170287767418211, val_acc 0.9618794326241135
trigger times: 0
saving model weights...
end of epoch 4: val_loss 0.08177180089361269, val_acc 0.9618794326241135
trigger times: 0
saving model weights...
end of epoch 5: val_loss 0.07671891407778869, val_acc 0.9645390070921985
trigger times: 0
saving model weights...
end of epoch 6: val_loss 0.07359707800457506, val_acc 0.9654255319148937
trigger times: 0
saving model weights...
end of epoch 7: val_loss 0.07296492057902158, val_acc 0.9671985815602837
trigger times: 0
saving model weights...
end of epoch 8: val_loss 0.07732061634509299, val_acc 0.9680851063829787
trigger times: 1
end of epoch 9: val_loss 0.06523228360972028, val_acc 0.9716312056737588
trigger times: 0
saving model weights...
end of epoch 10: val_loss 0.06710981292995914, val_acc 0.9698581560283688
trigger times: 1
end of epoch 11: val_loss 0.06293717802151816, val_acc 0.9680851063829787
trigger times: 0
saving model weights...
end of epoch 12: val_loss 0.06300542215781404, val_acc 0.9671985815602837
trigger times: 1
end of epoch 13: val_loss 0.05902696969432287, val_acc 0.9716312056737588
trigger times: 0
saving model weights...
end of epoch 14: val_loss 0.06155113498762783, val_acc 0.9707446808510638
trigger times: 1
end of epoch 15: val_loss 0.059735767335957216, val_acc 0.9725177304964538
trigger times: 2
end of epoch 16: val_loss 0.05579272708324548, val_acc 0.976063829787234
trigger times: 0
saving model weights...
end of epoch 17: val_loss 0.05780810530301589, val_acc 0.974290780141844
trigger times: 1
end of epoch 18: val_loss 0.05428367834977438, val_acc 0.974290780141844
trigger times: 0
saving model weights...
end of epoch 19: val_loss 0.0559282438979782, val_acc 0.974290780141844
trigger times: 1
end of epoch 20: val_loss 0.051210352341916565, val_acc 0.976063829787234
trigger times: 0
saving model weights...
end of epoch 21: val_loss 0.054771403800810484, val_acc 0.9725177304964538
trigger times: 1
end of epoch 22: val_loss 0.0501412693829883, val_acc 0.9769503546099291
trigger times: 0
saving model weights...
end of epoch 23: val_loss 0.049887506619534554, val_acc 0.9778368794326241
trigger times: 0
saving model weights...
end of epoch 24: val_loss 0.049914820071836785, val_acc 0.9787234042553191
trigger times: 1
end of epoch 25: val_loss 0.049670967297880696, val_acc 0.9796099290780141
trigger times: 0
saving model weights...
end of epoch 26: val_loss 0.052594629066639066, val_acc 0.9787234042553191
trigger times: 1
end of epoch 27: val_loss 0.04829488097731888, val_acc 0.9769503546099291
trigger times: 0
saving model weights...
end of epoch 28: val_loss 0.04797686326768044, val_acc 0.9778368794326241
trigger times: 0
saving model weights...
end of epoch 29: val_loss 0.05258082050507225, val_acc 0.976063829787234
trigger times: 1
end of epoch 30: val_loss 0.05321167925629041, val_acc 0.976063829787234
trigger times: 2
end of epoch 31: val_loss 0.04895698833023435, val_acc 0.9787234042553191
trigger times: 3
end of epoch 32: val_loss 0.04828849784202445, val_acc 0.9804964539007093
trigger times: 4
end of epoch 33: val_loss 0.0464849698538817, val_acc 0.9813829787234043
trigger times: 0
saving model weights...
end of epoch 34: val_loss 0.04770412501249265, val_acc 0.9787234042553191
trigger times: 1
end of epoch 35: val_loss 0.04879489392333121, val_acc 0.9787234042553191
trigger times: 2
end of epoch 36: val_loss 0.05051989237390105, val_acc 0.9796099290780141
trigger times: 3
end of epoch 37: val_loss 0.05123494548164387, val_acc 0.9778368794326241
trigger times: 4
end of epoch 38: val_loss 0.04757751824710967, val_acc 0.9787234042553191
trigger times: 5
end of epoch 39: val_loss 0.04414382363611596, val_acc 0.9804964539007093
trigger times: 0
saving model weights...
end of epoch 40: val_loss 0.04833364373897162, val_acc 0.9804964539007093
trigger times: 1
end of epoch 41: val_loss 0.053471805715993484, val_acc 0.9787234042553191
trigger times: 2
end of epoch 42: val_loss 0.050292825305831006, val_acc 0.9804964539007093
trigger times: 3
end of epoch 43: val_loss 0.04669954549242662, val_acc 0.9796099290780141
trigger times: 4
end of epoch 44: val_loss 0.04630829247042769, val_acc 0.9804964539007093
trigger times: 5
end of epoch 45: val_loss 0.04601679174698661, val_acc 0.9813829787234043
trigger times: 6
end of epoch 46: val_loss 0.04505615733396675, val_acc 0.9813829787234043
trigger times: 7
end of epoch 47: val_loss 0.0475718712995134, val_acc 0.9822695035460993
trigger times: 8
end of epoch 48: val_loss 0.05166929474545981, val_acc 0.9804964539007093
trigger times: 9
end of epoch 49: val_loss 0.05151795963935242, val_acc 0.9804964539007093
trigger times: 10
Early stopping.
0 -55.11347050219774 -105.98216711742712
1 -44.15612721443176 -76.56190549649224
2 -46.85174674540758 -72.51895167527836
3 -39.19344717171043 -71.91238572832597
4 -43.48933396488428 -65.0447729475643
5 -40.73039817716926 -62.468929493642136
6 -41.58909393288195 -52.67073108492849
7 -40.192558547481894 -51.23339439449891
8 -38.823081608861685 -39.43428523620552
9 -37.142793441191316 -32.334780854820806
10 -34.45431070541963 -29.2670803592239
11 -37.69753894582391 -28.32430140278431
12 -35.30821130797267 -20.474216556664466
13 -35.56334111839533 -18.35850790811357
14 -35.15215793531388 -10.414154091154558
15 -32.018308041617274 -8.23453209197286
16 -30.86986023746431 5.860615077611318
17 -30.216096485964954 6.405851138634589
18 -29.356947503983974 10.59045361641601
19 -26.839923918247223 23.11531098032165
20 -20.47108939755708 42.07542792510302
21 -20.9864041544497 58.035310213628016
22 -15.451249916106462 71.83091404314686
23 -13.103845125064254 73.70710134523536
24 -11.957921654451638 81.12720411950356
25 -12.033111486583948 82.32866985010293
26 -11.842879554256797 94.15973544827216
27 -3.4695866452530026 127.57280425644888
28 6.004321068525314 154.1078531458257
29 7.302326250821352 157.2296406215669
30 8.007483944296837 162.52503215880944
31 8.112564566545188 165.06380818034006
32 5.664348426274955 168.01804822219268
33 10.657894530333579 174.18616289555482
34 13.53780456399545 200.17430318587992
35 23.495174212846905 234.32338495546477
36 29.085520731285214 245.8505913555113
37 30.19496443774551 272.081841110809
38 35.170304061844945 301.6965823877335
39 38.425886334851384 303.3874010483866
40 42.12793976441026 322.2187597685313
41 45.096284583210945 333.0407029156643
42 46.6662215013057 333.9199654934176
43 47.22588525805622 337.0980913827745
44 50.476083769463 341.5515801120419
45 44.3051235023886 343.3928836976398
46 65.81968973018229 423.1355871564197
47 71.62395900813863 434.80815706930116
train accuracy: 0.9966386554621849
validation accuracy: 0.9804964539007093
