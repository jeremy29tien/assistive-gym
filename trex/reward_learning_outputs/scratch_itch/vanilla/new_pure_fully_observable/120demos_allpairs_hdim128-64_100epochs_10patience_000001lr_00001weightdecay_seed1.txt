demos: (480, 200, 20)
demo_rewards: (480,)
maximum traj length 200
maximum traj length 200
num train_obs 7140
num train_labels 7140
num val_obs 1128
num val_labels 1128
ModuleList(
  (0): Linear(in_features=20, out_features=128, bias=True)
  (1): Linear(in_features=128, out_features=64, bias=True)
  (2): Linear(in_features=64, out_features=1, bias=False)
)
Training reward model from scratch...
Total number of parameters: 11008
Number of trainable paramters: 11008
device: cuda:2
end of epoch 0: val_loss 0.16418890420376056, val_acc 0.9273049645390071
trigger times: 0
saving model weights...
end of epoch 1: val_loss 0.14514568891768204, val_acc 0.9317375886524822
trigger times: 0
saving model weights...
end of epoch 2: val_loss 0.13146776465807533, val_acc 0.9352836879432624
trigger times: 0
saving model weights...
end of epoch 3: val_loss 0.11839520711476727, val_acc 0.9432624113475178
trigger times: 0
saving model weights...
end of epoch 4: val_loss 0.10683748904944833, val_acc 0.950354609929078
trigger times: 0
saving model weights...
end of epoch 5: val_loss 0.10279982634364314, val_acc 0.9539007092198581
trigger times: 0
saving model weights...
end of epoch 6: val_loss 0.09386613867447594, val_acc 0.9583333333333334
trigger times: 0
saving model weights...
end of epoch 7: val_loss 0.1005553496955171, val_acc 0.9565602836879432
trigger times: 1
end of epoch 8: val_loss 0.08359978482491098, val_acc 0.9636524822695035
trigger times: 0
saving model weights...
end of epoch 9: val_loss 0.08101987777427136, val_acc 0.9654255319148937
trigger times: 0
saving model weights...
end of epoch 10: val_loss 0.07394003567063868, val_acc 0.9671985815602837
trigger times: 0
saving model weights...
end of epoch 11: val_loss 0.07237825704187285, val_acc 0.9663120567375887
trigger times: 0
saving model weights...
end of epoch 12: val_loss 0.07108958217113587, val_acc 0.9645390070921985
trigger times: 0
saving model weights...
end of epoch 13: val_loss 0.06666646442156395, val_acc 0.9671985815602837
trigger times: 0
saving model weights...
end of epoch 14: val_loss 0.06168351361356639, val_acc 0.9707446808510638
trigger times: 0
saving model weights...
end of epoch 15: val_loss 0.07441698361948317, val_acc 0.9671985815602837
trigger times: 1
end of epoch 16: val_loss 0.06712326908962084, val_acc 0.9671985815602837
trigger times: 2
end of epoch 17: val_loss 0.061774778449001096, val_acc 0.973404255319149
trigger times: 3
end of epoch 18: val_loss 0.0611262851608771, val_acc 0.973404255319149
trigger times: 0
saving model weights...
end of epoch 19: val_loss 0.06113590031529301, val_acc 0.973404255319149
trigger times: 1
end of epoch 20: val_loss 0.06230904273868581, val_acc 0.9716312056737588
trigger times: 2
end of epoch 21: val_loss 0.05288095217973244, val_acc 0.9769503546099291
trigger times: 0
saving model weights...
end of epoch 22: val_loss 0.056361919214968276, val_acc 0.976063829787234
trigger times: 1
end of epoch 23: val_loss 0.04995429822725375, val_acc 0.9787234042553191
trigger times: 0
saving model weights...
end of epoch 24: val_loss 0.04999695308695755, val_acc 0.9787234042553191
trigger times: 1
end of epoch 25: val_loss 0.04937874999081202, val_acc 0.9804964539007093
trigger times: 0
saving model weights...
end of epoch 26: val_loss 0.049465070807424134, val_acc 0.9796099290780141
trigger times: 1
end of epoch 27: val_loss 0.059481831153777705, val_acc 0.9796099290780141
trigger times: 2
end of epoch 28: val_loss 0.05670373977484687, val_acc 0.9804964539007093
trigger times: 3
end of epoch 29: val_loss 0.05031063933687586, val_acc 0.9822695035460993
trigger times: 4
end of epoch 30: val_loss 0.044099299688122255, val_acc 0.9831560283687943
trigger times: 0
saving model weights...
end of epoch 31: val_loss 0.047641796918917616, val_acc 0.9804964539007093
trigger times: 1
end of epoch 32: val_loss 0.0477678156470152, val_acc 0.9822695035460993
trigger times: 2
end of epoch 33: val_loss 0.03928320168889517, val_acc 0.9849290780141844
trigger times: 0
saving model weights...
end of epoch 34: val_loss 0.04411357096007399, val_acc 0.9813829787234043
trigger times: 1
end of epoch 35: val_loss 0.04932199270365421, val_acc 0.9840425531914894
trigger times: 2
end of epoch 36: val_loss 0.039754646511585306, val_acc 0.9831560283687943
trigger times: 3
end of epoch 37: val_loss 0.03754200652097025, val_acc 0.9867021276595744
trigger times: 0
saving model weights...
end of epoch 38: val_loss 0.04345875208615184, val_acc 0.9787234042553191
trigger times: 1
end of epoch 39: val_loss 0.04582578556625535, val_acc 0.9840425531914894
trigger times: 2
end of epoch 40: val_loss 0.04564654064335735, val_acc 0.9849290780141844
trigger times: 3
end of epoch 41: val_loss 0.040844935383033236, val_acc 0.9840425531914894
trigger times: 4
end of epoch 42: val_loss 0.04175517843796669, val_acc 0.9858156028368794
trigger times: 5
end of epoch 43: val_loss 0.03709962265377715, val_acc 0.9858156028368794
trigger times: 0
saving model weights...
end of epoch 44: val_loss 0.035505739515965105, val_acc 0.9849290780141844
trigger times: 0
saving model weights...
end of epoch 45: val_loss 0.035764793394801854, val_acc 0.9840425531914894
trigger times: 1
end of epoch 46: val_loss 0.04517526704032512, val_acc 0.9840425531914894
trigger times: 2
end of epoch 47: val_loss 0.0311345802408937, val_acc 0.9884751773049646
trigger times: 0
saving model weights...
end of epoch 48: val_loss 0.035592585866673514, val_acc 0.9875886524822695
trigger times: 1
end of epoch 49: val_loss 0.030880323759771098, val_acc 0.9875886524822695
trigger times: 0
saving model weights...
end of epoch 50: val_loss 0.033527071042075474, val_acc 0.9875886524822695
trigger times: 1
end of epoch 51: val_loss 0.03767689734868851, val_acc 0.9840425531914894
trigger times: 2
end of epoch 52: val_loss 0.03237097360526776, val_acc 0.9875886524822695
trigger times: 3
end of epoch 53: val_loss 0.03552217491854073, val_acc 0.9875886524822695
trigger times: 4
end of epoch 54: val_loss 0.038723639556132505, val_acc 0.9858156028368794
trigger times: 5
end of epoch 55: val_loss 0.04358269919889079, val_acc 0.9849290780141844
trigger times: 6
end of epoch 56: val_loss 0.03706530235551508, val_acc 0.9858156028368794
trigger times: 7
end of epoch 57: val_loss 0.035092913746015184, val_acc 0.9884751773049646
trigger times: 8
end of epoch 58: val_loss 0.026815288394927885, val_acc 0.9893617021276596
trigger times: 0
saving model weights...
end of epoch 59: val_loss 0.04043568654892877, val_acc 0.9867021276595744
trigger times: 1
end of epoch 60: val_loss 0.025519094930282094, val_acc 0.9884751773049646
trigger times: 0
saving model weights...
end of epoch 61: val_loss 0.033998108536477646, val_acc 0.9875886524822695
trigger times: 1
end of epoch 62: val_loss 0.0285226237263755, val_acc 0.9893617021276596
trigger times: 2
end of epoch 63: val_loss 0.03388562091962622, val_acc 0.9858156028368794
trigger times: 3
end of epoch 64: val_loss 0.039720186065663805, val_acc 0.9867021276595744
trigger times: 4
end of epoch 65: val_loss 0.038190402375495515, val_acc 0.9858156028368794
trigger times: 5
end of epoch 66: val_loss 0.033361464033943945, val_acc 0.9867021276595744
trigger times: 6
end of epoch 67: val_loss 0.02990023607351744, val_acc 0.9893617021276596
trigger times: 7
end of epoch 68: val_loss 0.04015392236709906, val_acc 0.9858156028368794
trigger times: 8
end of epoch 69: val_loss 0.028900983215462046, val_acc 0.9893617021276596
trigger times: 9
end of epoch 70: val_loss 0.029187569265951643, val_acc 0.9884751773049646
trigger times: 10
Early stopping.
0 -49.78732027485967 -136.99350747158917
1 -48.21838517766446 -131.20042885027652
2 -35.08980503305793 -79.41740014534255
3 -32.445302293868735 -72.07719821962127
4 -28.73042552615516 -68.25603958887683
5 -23.39081351645291 -66.08528823114615
6 -28.10751946642995 -62.468929493642136
7 -28.293657148256898 -52.381190645137245
8 -20.954271727532614 -34.57667262029811
9 -22.86105940886773 -31.30331487414688
10 -19.654678318242077 -19.556186372048053
11 -14.573545817285776 -4.632852762406387
12 -11.413117770571262 2.8395038580483685
13 -4.296407096844632 22.340428764253097
14 -5.885456586547662 23.11531098032165
15 -4.9229708556085825 24.32920711869632
16 -5.918918679650233 32.07856584753425
17 -4.227402240969241 33.5723511509563
18 3.3071091999299824 40.21293197223649
19 2.3377083181403577 47.958561210870805
20 2.7774034729227424 51.32677716745781
21 4.747122752480209 53.364882104593235
22 3.788971700472757 61.039255622139066
23 6.926354686962441 63.56172262344406
24 8.047537795035169 66.34646031672955
25 8.914556076284498 71.5960198405553
26 9.964803836657666 74.78385238790305
27 10.531746158841997 78.40511603178545
28 16.602343471720815 96.56619963782883
29 30.277658968116157 131.9840844291858
30 33.98543577856617 144.3512376753812
31 36.5376379895024 160.22463620684547
32 42.339467009704094 180.1423363713056
33 50.779741999693215 203.6017904999808
34 54.14224969933275 214.6263040548001
35 55.77662610806874 226.96827270106405
36 58.67671626294032 232.7713587432071
37 65.1075973273255 266.3586992205008
38 69.48615981056355 267.7439522684791
39 84.67795464640949 324.0197976082746
40 87.92676955333445 327.6748194412485
41 87.1258496362716 333.0407029156643
42 89.69551524636336 341.5515801120419
43 96.11769526964054 361.84626739841684
44 104.99306165985763 390.7517184882046
45 108.01887721873936 400.0413426933392
46 110.37153401225805 403.13796958654353
47 114.94440406747162 423.1355871564197
train accuracy: 0.9994397759103641
validation accuracy: 0.9884751773049646
