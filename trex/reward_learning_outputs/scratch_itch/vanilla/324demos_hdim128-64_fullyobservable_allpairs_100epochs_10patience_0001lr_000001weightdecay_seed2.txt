demos: (480, 200, 42)
demo_rewards: (480,)
sorted_train_rewards: [-1.68281407e+02 -1.45727567e+02 -1.39123043e+02 -1.33973547e+02
 -1.25906495e+02 -1.23737226e+02 -1.18441257e+02 -1.15454518e+02
 -1.15278652e+02 -1.14763156e+02 -1.14085096e+02 -1.12885489e+02
 -1.11179560e+02 -1.10579609e+02 -1.10248073e+02 -1.06969949e+02
 -1.06298076e+02 -1.06264986e+02 -1.05880618e+02 -1.03152139e+02
 -1.01565908e+02 -1.00495946e+02 -1.00348353e+02 -9.79572956e+01
 -9.72257679e+01 -9.60581398e+01 -9.47527923e+01 -9.42721572e+01
 -9.39936009e+01 -9.08470847e+01 -8.99058909e+01 -8.98050349e+01
 -8.92193126e+01 -8.88554189e+01 -8.76650055e+01 -8.71119989e+01
 -8.58361739e+01 -8.42859587e+01 -8.40914856e+01 -8.33560899e+01
 -8.18475632e+01 -8.14466377e+01 -8.14089062e+01 -8.10067480e+01
 -8.08547762e+01 -8.04839138e+01 -8.02515601e+01 -7.86319117e+01
 -7.84173816e+01 -7.80515779e+01 -7.63592934e+01 -7.48307224e+01
 -7.41288702e+01 -7.35268215e+01 -7.30055356e+01 -7.23199016e+01
 -7.10097190e+01 -7.02497554e+01 -6.98788242e+01 -6.90105689e+01
 -6.88032812e+01 -6.82574483e+01 -6.81709241e+01 -6.78589144e+01
 -6.77543594e+01 -6.58589998e+01 -6.53374190e+01 -6.50060709e+01
 -6.49762184e+01 -6.43151789e+01 -6.32463365e+01 -6.31014303e+01
 -5.92349209e+01 -5.78572803e+01 -5.76610527e+01 -5.71589430e+01
 -5.63099047e+01 -5.50587300e+01 -5.45877794e+01 -5.23998422e+01
 -5.20708438e+01 -5.03190683e+01 -4.94482556e+01 -4.87197115e+01
 -4.55497329e+01 -4.52135310e+01 -4.39133519e+01 -4.35323363e+01
 -4.26845918e+01 -3.93647734e+01 -3.84347912e+01 -3.72825558e+01
 -3.65728483e+01 -3.63795012e+01 -3.49277470e+01 -3.44876502e+01
 -3.36956904e+01 -3.33480978e+01 -2.95933148e+01 -2.77930868e+01
 -2.71949370e+01 -2.63456513e+01 -2.26604777e+01 -2.17769506e+01
 -2.11615803e+01 -2.04180093e+01 -2.01312764e+01 -2.00548875e+01
 -1.87912468e+01 -1.74207898e+01 -1.68901975e+01 -1.61143764e+01
 -1.53629384e+01 -1.39267768e+01 -1.12508710e+01 -7.28306957e+00
 -6.03798033e+00 -4.48405644e+00 -1.63608121e+00 -1.43319012e+00
 -1.25215708e+00 -5.72842125e-01  2.69474090e-01  5.32120974e-01
  8.48755488e-01  3.13137341e+00  4.09388103e+00  4.23223568e+00
  4.38318042e+00  6.23806049e+00  6.83923461e+00  6.84166284e+00
  8.10954932e+00  8.62917691e+00  1.29952266e+01  1.34336148e+01
  1.51800256e+01  1.58979399e+01  1.65923688e+01  1.89453788e+01
  1.94910199e+01  1.96225348e+01  2.15104917e+01  2.41170029e+01
  2.43710703e+01  2.58660332e+01  2.60724768e+01  2.70113358e+01
  2.74672520e+01  2.75751580e+01  3.05892332e+01  3.27442577e+01
  3.36843458e+01  3.37899159e+01  3.41611587e+01  3.48663961e+01
  3.50530887e+01  3.72456187e+01  3.99267393e+01  3.99602846e+01
  4.23875378e+01  4.39159825e+01  4.42327291e+01  4.48500197e+01
  4.83776686e+01  4.88736658e+01  5.05284149e+01  5.51223952e+01
  5.53688861e+01  5.56692378e+01  5.59202636e+01  5.66357258e+01
  5.77674455e+01  5.78923918e+01  5.86309323e+01  5.93436812e+01
  6.02906417e+01  6.49603340e+01  6.51680641e+01  6.68749790e+01
  6.76039372e+01  6.78694515e+01  6.85395993e+01  6.85552576e+01
  6.99023624e+01  7.00722782e+01  7.10566011e+01  7.18958063e+01
  7.42631002e+01  7.64437617e+01  7.80250544e+01  8.00743291e+01
  8.04122550e+01  8.13002353e+01  8.33459185e+01  8.73487076e+01
  8.87279953e+01  9.04900629e+01  9.13388441e+01  9.22074020e+01
  9.22656205e+01  9.30086833e+01  9.30344412e+01  9.73584524e+01
  9.78474792e+01  9.87173322e+01  1.01506611e+02  1.02399087e+02
  1.03162159e+02  1.03450957e+02  1.03768508e+02  1.04406383e+02
  1.05720971e+02  1.07092483e+02  1.07710068e+02  1.11625387e+02
  1.11924895e+02  1.13547690e+02  1.14761007e+02  1.16179984e+02
  1.16837433e+02  1.25537775e+02  1.33048584e+02  1.33573303e+02
  1.39131419e+02  1.41638120e+02  1.41844812e+02  1.43496609e+02
  1.43510881e+02  1.46199060e+02  1.46556236e+02  1.48382236e+02
  1.48407567e+02  1.48912536e+02  1.49165606e+02  1.50802776e+02
  1.51584630e+02  1.57633889e+02  1.57737232e+02  1.58454369e+02
  1.58938144e+02  1.58956502e+02  1.64960890e+02  1.66294281e+02
  1.68205106e+02  1.69199237e+02  1.70621405e+02  1.71268575e+02
  1.71509314e+02  1.72966312e+02  1.74644664e+02  1.74710408e+02
  1.79019423e+02  1.81095791e+02  1.82868270e+02  1.82965600e+02
  1.85354242e+02  1.89574834e+02  1.91027077e+02  1.94950274e+02
  1.99518927e+02  2.01784542e+02  2.04149936e+02  2.04559881e+02
  2.05267194e+02  2.09047338e+02  2.09294404e+02  2.09568207e+02
  2.10601509e+02  2.13399135e+02  2.14626304e+02  2.15422119e+02
  2.22947849e+02  2.24805184e+02  2.25145886e+02  2.26628167e+02
  2.28189327e+02  2.28893032e+02  2.36284670e+02  2.36684500e+02
  2.37351876e+02  2.39673843e+02  2.40087383e+02  2.40746217e+02
  2.42298224e+02  2.44455371e+02  2.45745089e+02  2.47396543e+02
  2.47424733e+02  2.49133124e+02  2.50199516e+02  2.50956709e+02
  2.51005724e+02  2.52138755e+02  2.56224103e+02  2.56233725e+02
  2.57266362e+02  2.58179264e+02  2.60083093e+02  2.62492064e+02
  2.63648761e+02  2.65056624e+02  2.66105443e+02  2.66165893e+02
  2.66358699e+02  2.66927189e+02  2.73760950e+02  2.75046082e+02
  2.76765168e+02  2.77043285e+02  2.78210634e+02  2.78449570e+02
  2.78926353e+02  2.82325028e+02  2.84101176e+02  2.84932306e+02
  2.86464187e+02  2.86772706e+02  2.86931290e+02  2.87806515e+02
  2.88479049e+02  2.88826115e+02  2.89886738e+02  2.90633014e+02
  2.90673531e+02  2.91329522e+02  2.91437334e+02  2.91755546e+02
  2.92387265e+02  2.93628281e+02  2.94666653e+02  2.94932601e+02
  2.96188315e+02  2.96502288e+02  2.96822454e+02  2.97975474e+02
  2.98212430e+02  3.00668612e+02  3.01876822e+02  3.02112561e+02
  3.03572646e+02  3.04409455e+02  3.04449763e+02  3.06384175e+02
  3.06727103e+02  3.07812719e+02  3.08096964e+02  3.10210664e+02
  3.11984654e+02  3.12755351e+02  3.14574421e+02  3.17598550e+02
  3.17861441e+02  3.19020009e+02  3.20094631e+02  3.20899374e+02
  3.21383177e+02  3.23073902e+02  3.23170946e+02  3.23359694e+02
  3.23678838e+02  3.24019798e+02  3.26023906e+02  3.26326863e+02
  3.27089227e+02  3.27093677e+02  3.29794865e+02  3.30083446e+02
  3.31713138e+02  3.34824512e+02  3.34942982e+02  3.36264366e+02
  3.38064250e+02  3.41586114e+02  3.42427604e+02  3.45169167e+02
  3.45467793e+02  3.50754649e+02  3.51098770e+02  3.52589335e+02
  3.52938639e+02  3.53122732e+02  3.57327858e+02  3.57432774e+02
  3.60230626e+02  3.60404347e+02  3.60494199e+02  3.61846267e+02
  3.63639297e+02  3.65528706e+02  3.66902709e+02  3.67026251e+02
  3.67221496e+02  3.68309635e+02  3.68871842e+02  3.70497366e+02
  3.70665008e+02  3.71474657e+02  3.72391756e+02  3.73902990e+02
  3.74044271e+02  3.75975458e+02  3.76103509e+02  3.78576962e+02
  3.79102861e+02  3.81301733e+02  3.83305336e+02  3.84246014e+02
  3.89847138e+02  3.89945653e+02  3.90751718e+02  3.94941529e+02
  3.96037631e+02  4.00041343e+02  4.03137970e+02  4.06941403e+02
  4.07718412e+02  4.13881992e+02  4.14385640e+02  4.14433011e+02
  4.15231967e+02  4.18896984e+02  4.19530524e+02  4.20454152e+02
  4.20949962e+02  4.29050163e+02  4.31102150e+02  4.34196834e+02
  4.44554017e+02  4.45936030e+02  4.67300177e+02  4.73149208e+02]
sorted_val_rewards: [-97.24485765 -84.84678494 -78.93406316 -75.02969541 -72.6136252
 -67.70332814 -53.81405192 -44.4901949  -41.31065187 -36.4541601
 -35.63660061 -35.18965073 -21.70967377 -20.14259509 -14.47118388
  -1.89633986   0.97147912  19.49169204  20.53058809  28.52857496
  34.21536024  64.7458201   81.89014686  83.25651006  99.28484545
 121.32613156 136.51192078 137.75828464 142.42451181 163.26711477
 164.18896384 168.39927287 189.56275248 189.67231025 206.11896428
 208.13326989 221.44584608 233.63745377 235.04407254 237.90451472
 260.76549875 282.20625599 290.00250527 301.69658239 333.04070292
 343.3928837  423.13558716 434.80815707]
maximum traj length 200
maximum traj length 200
num train_obs 52326
num train_labels 52326
num val_obs 1128
num val_labels 1128
ModuleList(
  (0): Linear(in_features=42, out_features=128, bias=True)
  (1): Linear(in_features=128, out_features=64, bias=True)
  (2): Linear(in_features=64, out_features=1, bias=False)
)
Training reward model from scratch...
Total number of parameters: 13824
Number of trainable paramters: 13824
device: cuda:3
end of epoch 0: val_loss 0.15626676547128796, val_acc 0.9317375886524822
trigger times: 0
saving model weights...
end of epoch 1: val_loss 0.13525353665110745, val_acc 0.9441489361702128
trigger times: 0
saving model weights...
end of epoch 2: val_loss 0.11008286560714937, val_acc 0.9574468085106383
trigger times: 0
saving model weights...
end of epoch 3: val_loss 0.13976829757185935, val_acc 0.9397163120567376
trigger times: 1
end of epoch 4: val_loss 0.12751765834724052, val_acc 0.950354609929078
trigger times: 2
end of epoch 5: val_loss 0.19132005908174832, val_acc 0.9476950354609929
trigger times: 3
end of epoch 6: val_loss 0.1402601019155926, val_acc 0.9521276595744681
trigger times: 4
end of epoch 7: val_loss 0.15394901491234306, val_acc 0.9476950354609929
trigger times: 5
end of epoch 8: val_loss 0.13911988031740988, val_acc 0.9485815602836879
trigger times: 6
end of epoch 9: val_loss 0.1347294859287342, val_acc 0.9468085106382979
trigger times: 7
end of epoch 10: val_loss 0.15243197334646516, val_acc 0.9450354609929078
trigger times: 8
end of epoch 11: val_loss 0.20182135577229907, val_acc 0.9370567375886525
trigger times: 9
end of epoch 12: val_loss 0.14217206529694296, val_acc 0.9450354609929078
trigger times: 10
Early stopping.
0 -24.427583241078537 -97.24485765376211
1 -18.459220358519815 -84.84678494475872
2 -21.512027689954266 -78.93406316283158
3 -11.59970662878186 -75.02969540587696
4 -13.015068757231347 -72.61362520197201
5 -12.642945307306945 -67.70332814138712
6 -7.6888195799983805 -53.814051919860674
7 -7.9706321796402335 -44.49019489529177
8 -4.389951026532799 -41.3106518668958
9 -6.247088102303678 -36.45416009522412
10 -5.9538625492714345 -35.636600609806095
11 -5.351300142734544 -35.189650726025825
12 -1.5634964953642339 -21.70967376674228
13 -2.5614728013024433 -20.14259508741993
14 -4.366859268397093 -14.4711838787269
15 -2.42348955032503 -1.8963398599782397
16 -1.0231904070387827 0.971479121789783
17 2.696957611857215 19.491692038206416
18 0.7126862867735326 20.530588087221908
19 -0.3070478729205206 28.52857496230795
20 -0.8982478954130784 34.21536023715924
21 -0.3473274690913968 64.74582010073695
22 4.458416783163557 81.89014686183334
23 5.111078286907286 83.25651005762352
24 2.558518031175481 99.28484545080774
25 3.0905430072452873 121.32613156169126
26 10.413673776492942 136.51192077875302
27 4.2485394512768835 137.7582846380186
28 10.576120225363411 142.42451181000234
29 11.254942167244735 163.26711477318133
30 10.914291976718232 164.18896384382953
31 9.896536323911278 168.3992728696738
32 12.77852048393106 189.56275247801355
33 11.407996268186253 189.6723102456173
34 12.44374344778771 206.11896428081653
35 12.702310774911894 208.13326989135442
36 12.497064396477072 221.44584607902624
37 10.319722011161502 233.63745376530167
38 14.025678783807962 235.04407254128563
39 12.383427416301856 237.90451471965713
40 17.633229533967096 260.765498753965
41 17.51111057898379 282.2062559864006
42 26.711240455071675 290.0025052732212
43 14.460362992540468 301.6965823877335
44 17.352144777367357 333.0407029156643
45 19.32373712741537 343.3928836976398
46 19.253866516053677 423.1355871564197
47 27.317711099924054 434.80815706930116
train accuracy: 0.9781752857088254
validation accuracy: 0.9450354609929078
