demo lengths 200
demos: (120, 200, 25)
demo_rewards: (120,)
[-238.5653939  -226.82452825 -226.22417315 -208.89755486 -196.98407553
 -194.40174577 -193.75394353 -173.38768743 -172.73844576 -172.58495982
 -148.80630048 -146.54022995 -144.91636018 -144.50987996 -129.52710351
 -119.67891388 -119.53338183 -115.00841352 -113.49466461 -107.45837168
 -105.499371   -101.91049433 -101.6629413   -98.89606861  -95.19099379
  -93.31854914  -85.41926577  -83.18012153  -79.47665069  -77.34308622
  -60.56041622  -58.68833689  -22.79021188  -19.65788927  -16.74518768
  -13.7194023     4.23518987    5.09528062   10.17879679   13.54105579
   14.98971093   21.80202968   31.12027906   40.64550157   40.69898986
   50.09032867   57.29053552   60.51441689   62.58785811   63.47489587
   65.39553199   68.71330703   69.48459209   72.16624272   74.22332021
   79.16074532   80.25553157   87.50520028   90.28646232   90.72533901
   91.52552636   91.95773979   92.9922131    94.14052713   94.28590507
   95.24073533   96.09581961   96.50341248   97.4582029    97.90553231
   98.27346636   98.35872828   98.92550904   99.09003072   99.89253842
  100.07765056  101.35869828  103.56921378  103.74194541  104.00039884
  104.36031384  104.79584302  105.40349711  105.60678193  106.26867976
  106.37916921  106.67969424  106.81132709  107.05410486  107.44441498
  107.68792314  107.72369032  108.58631071  108.79454915  109.15712102
  109.71287331  110.48639228  111.46302588  112.59201368  113.45309909
  114.85996347  115.04838323  115.56466246  115.7702745   116.29805012
  116.38499267  116.41989071  117.08008836  117.29357602  118.29160886
  119.01062501  120.85290512  120.89021502  121.40892075  122.30522808
  129.13346806  129.67718524  129.79664443  130.61780867  131.40806577]
maximum traj length 200
maximum traj length 200
num training_obs 90
num training_labels 90
num val_obs 10
num val_labels 10
num test_obs 7140
num test_labels 7140
ModuleList(
  (0): Linear(in_features=25, out_features=128, bias=True)
  (1): Linear(in_features=128, out_features=64, bias=True)
  (2): Linear(in_features=64, out_features=1, bias=False)
)
Total number of parameters: 11648
Number of trainable paramters: 11648
device: cuda:0
end of epoch 0: val_loss 0.5864169932809091, val_acc 0.9
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 0.0291,  0.1611, -0.1407,  ..., -0.0511,  0.1801, -0.0185],
        [-0.0707,  0.2313, -0.1215,  ...,  0.0402, -0.1512, -0.0173],
        [ 0.2023,  0.0599,  0.0858,  ..., -0.0146,  0.1659,  0.2432],
        ...,
        [-0.1303, -0.0071,  0.0216,  ...,  0.1437, -0.0905, -0.1369],
        [-0.0380,  0.0829, -0.2322,  ..., -0.0346, -0.1513,  0.1674],
        [-0.2637, -0.0484, -0.0743,  ...,  0.0564, -0.0546, -0.2345]],
       device='cuda:0')), ('fcs.0.bias', tensor([-9.6538e-03, -1.3389e-01, -4.1928e-02, -1.6360e-01, -1.1334e-01,
        -1.8690e-03, -1.2020e-01, -1.0976e-01, -4.2806e-02,  6.2933e-02,
         2.2606e-01,  9.9325e-02, -1.4135e-01, -9.3806e-02,  1.7485e-02,
         4.7823e-02,  6.5635e-02,  1.3918e-01,  2.1185e-01,  1.7142e-01,
        -1.3166e-01,  2.6488e-02,  9.4139e-02,  6.3548e-03, -3.3759e-02,
        -8.3062e-02,  9.7143e-02,  7.7385e-02,  1.2554e-01,  3.5807e-02,
         3.1030e-02, -1.0597e-01,  1.8620e-01, -1.2034e-01,  9.2882e-02,
        -1.3333e-01,  6.7461e-02,  7.5582e-04,  3.7720e-02,  1.6505e-01,
         1.1276e-02, -1.2331e-01,  1.4229e-01,  2.2377e-01,  4.7406e-02,
        -2.4910e-01, -6.7770e-02,  2.3691e-01,  1.1586e-01,  9.5657e-02,
         9.9932e-02, -1.0246e-02, -6.7973e-02, -2.2629e-01, -4.3393e-02,
         5.6348e-02, -2.0140e-04, -1.4439e-01, -1.0053e-01,  3.2188e-02,
        -5.2423e-03,  1.7170e-02, -1.4169e-01, -1.6218e-01,  9.0649e-02,
         8.0510e-02, -2.4463e-01, -1.4634e-01, -5.0759e-02, -1.7541e-02,
        -1.5981e-01,  3.6015e-03,  1.2942e-01, -6.0074e-03, -1.0041e-01,
        -1.7640e-01, -1.0689e-01,  5.6626e-02, -1.2900e-01, -2.5441e-03,
        -1.1091e-01,  2.0645e-01, -1.0466e-01,  1.4517e-01, -1.8582e-01,
        -1.5659e-01,  4.6020e-02, -1.4852e-01,  2.8621e-02, -1.6465e-01,
         6.3405e-02,  3.0562e-01, -5.9256e-02, -4.3849e-02,  1.6696e-01,
         1.8681e-02, -1.3176e-01,  1.5820e-03, -1.9080e-01,  2.3241e-01,
        -5.3350e-02,  1.0036e-02, -1.8479e-01, -7.6936e-02,  5.2578e-02,
         6.1342e-02, -8.7385e-02, -3.1993e-02,  1.9824e-01,  1.3858e-01,
        -8.2362e-02,  1.1208e-01,  1.1726e-01,  1.2089e-01,  5.5059e-04,
        -2.0906e-01, -2.3627e-02,  7.8289e-02,  1.3190e-01, -2.1078e-01,
         1.2002e-01, -2.4936e-01,  1.6028e-01,  1.4417e-01,  1.7924e-02,
        -3.8067e-02,  7.6224e-02, -1.4583e-01], device='cuda:0')), ('fcs.1.weight', tensor([[ 4.8867e-02, -3.6909e-03,  7.6699e-02,  ..., -1.2920e-02,
          4.3859e-03, -2.8458e-02],
        [ 1.0516e-02,  1.2989e-03, -4.2544e-02,  ...,  3.9704e-05,
          6.4736e-03, -3.5482e-02],
        [-8.4284e-02, -1.3991e-02, -5.7665e-02,  ...,  1.1099e-02,
         -6.9127e-02,  1.5769e-02],
        ...,
        [ 3.9856e-03,  1.4463e-02,  6.4087e-02,  ..., -1.6690e-02,
         -7.2051e-02,  2.7959e-02],
        [ 2.8074e-02,  8.3878e-02, -1.0356e-01,  ...,  5.7525e-02,
          2.5348e-02, -1.5630e-02],
        [ 1.4047e-01,  3.4077e-02,  1.3105e-01,  ..., -5.5521e-02,
         -2.1618e-02, -9.0644e-02]], device='cuda:0')), ('fcs.1.bias', tensor([-2.6506e-02, -1.6223e-02, -5.7905e-02, -1.6106e-02,  8.2770e-03,
        -1.1308e-01,  9.6797e-02, -7.2142e-02, -1.0991e-01, -2.2475e-02,
        -3.6792e-02,  8.6698e-02, -5.6331e-02, -4.0962e-02,  1.2744e-01,
         8.6174e-02,  1.4550e-02,  3.0362e-02,  3.1562e-02, -5.4637e-02,
        -8.8009e-02, -1.0745e-01,  1.2868e-04,  5.4286e-03,  2.8228e-02,
        -1.1443e-03, -2.4036e-02,  4.5261e-03,  6.7770e-02,  3.8195e-02,
         2.0065e-02, -1.1758e-02, -6.7827e-02,  1.0632e-01, -7.2542e-02,
        -5.0994e-02, -8.6295e-02, -5.6741e-02,  8.8964e-02,  7.3406e-02,
        -3.8428e-02, -3.7136e-02,  3.5651e-02,  2.0787e-03, -6.5660e-02,
         9.6119e-02, -5.1223e-02,  2.9719e-04, -3.4647e-02, -6.0039e-03,
         1.3618e-01, -4.1332e-03, -2.9029e-02, -6.4834e-02, -4.6671e-04,
        -1.2450e-02, -5.4057e-02, -8.3480e-02,  1.1103e-01,  1.0703e-01,
        -7.2512e-02,  5.5693e-02,  5.8889e-03,  4.4344e-02], device='cuda:0')), ('fcs.2.weight', tensor([[ 1.5270e-02, -4.6795e-03, -6.1919e-02, -2.2793e-02, -1.0823e-03,
          2.5141e-03,  1.2568e-02, -9.1159e-03,  6.3996e-02,  1.8843e-02,
          1.1508e-01, -2.2062e-02, -4.0457e-02, -3.2962e-02, -1.7432e-02,
          1.5944e-02,  6.7626e-02, -4.8323e-02,  3.4422e-02, -1.0858e-02,
         -3.2511e-03, -1.8360e-03, -2.0743e-02, -6.0023e-02,  1.2568e-02,
         -2.5115e-02,  3.4819e-02,  6.5287e-03,  5.6619e-03, -4.7646e-02,
         -3.6206e-02, -2.5454e-02, -2.0619e-02,  4.0677e-02,  4.9450e-02,
         -2.3384e-02, -1.7376e-02, -9.5229e-02,  1.4568e-02, -7.5262e-03,
         -3.9305e-02,  2.9407e-03, -6.1593e-02,  4.9059e-02, -3.0070e-02,
         -5.6133e-03, -3.8512e-02,  2.0303e-02,  1.7548e-02,  4.9040e-02,
          3.0942e-02,  3.6949e-04,  8.1574e-04, -1.7974e-02,  9.7446e-04,
          9.3461e-03, -3.1179e-02, -1.8049e-02,  4.5341e-02, -9.9074e-03,
         -1.1443e-02, -2.5930e-03, -1.0075e-04,  2.5456e-03]], device='cuda:0'))])
end of epoch 1: val_loss 0.01820962073688861, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 0.0066,  0.1697, -0.0632,  ..., -0.0703,  0.1133,  0.0055],
        [-0.0434,  0.2225, -0.1142,  ...,  0.0310, -0.1480, -0.0165],
        [ 0.2172,  0.0786,  0.1329,  ..., -0.0308,  0.1578,  0.2382],
        ...,
        [-0.0591,  0.0012,  0.0027,  ...,  0.0968, -0.0118, -0.0624],
        [-0.0408,  0.0801, -0.2251,  ..., -0.0313, -0.1526,  0.1367],
        [-0.2612, -0.0485, -0.0725,  ...,  0.0559, -0.0539, -0.2178]],
       device='cuda:0')), ('fcs.0.bias', tensor([-5.6051e-02, -1.3042e-01, -4.4689e-02, -1.9136e-01, -1.2321e-01,
         9.3123e-02, -1.1866e-01, -7.1918e-03, -3.6682e-02,  6.2230e-02,
         1.7994e-01,  9.4528e-02, -1.3583e-01, -9.4758e-02, -1.1242e-02,
         4.0975e-02,  5.8252e-02,  9.0106e-02,  1.8784e-01,  1.7817e-01,
        -1.2629e-01,  2.3090e-02,  9.2978e-02,  5.7426e-03, -3.5071e-03,
        -3.8639e-02,  9.3789e-02,  7.5767e-02,  1.2403e-01, -9.7281e-03,
        -6.5175e-03, -1.0512e-01,  1.8240e-01, -1.0217e-01,  7.4321e-02,
        -8.4120e-02,  8.1030e-02,  1.3966e-03,  3.4752e-02,  3.1004e-01,
        -1.0166e-02, -1.2970e-01,  1.2955e-01,  2.5120e-01,  2.6146e-02,
        -2.4351e-01, -9.3494e-02,  1.9297e-01,  9.6687e-02,  6.2711e-02,
         9.7697e-02, -2.6909e-02, -7.1434e-02, -2.2581e-01, -5.7995e-02,
         5.5956e-02,  8.1144e-02, -1.4151e-01, -1.4586e-01,  3.4043e-02,
        -4.4126e-03,  1.6620e-02, -1.5500e-01, -1.6082e-01,  9.0793e-02,
        -1.1575e-02, -2.6976e-01, -1.4249e-01, -6.9673e-05,  4.6280e-03,
        -1.5714e-01, -2.5215e-02,  1.4378e-01,  6.1593e-02, -1.0817e-01,
        -1.7614e-01, -6.5929e-02,  4.9623e-02, -1.4980e-01,  4.2390e-02,
        -1.0942e-01,  1.8437e-01, -1.0893e-01,  1.3505e-01, -1.8521e-01,
        -1.3540e-01,  6.1525e-02, -1.4717e-01, -8.0037e-03, -1.5227e-01,
         1.3859e-01,  2.9218e-01, -5.8618e-02, -6.4527e-02,  1.9056e-01,
         1.8540e-02, -1.3649e-01, -5.1950e-03, -1.8555e-01,  2.2505e-01,
        -7.0765e-02,  1.8148e-02, -1.6839e-01, -2.2016e-02, -4.7596e-02,
         5.9230e-02, -5.5216e-02, -3.5549e-02,  1.0765e-01,  1.3098e-01,
        -8.0838e-02,  1.1108e-01,  7.9670e-02,  1.1986e-01, -6.5581e-03,
        -2.1523e-01, -5.8493e-03,  1.7719e-02,  8.6715e-02, -2.0866e-01,
         9.4741e-02, -2.4713e-01,  1.6642e-01,  1.1517e-01,  1.6141e-02,
        -9.7432e-03,  7.3576e-02, -1.4437e-01], device='cuda:0')), ('fcs.1.weight', tensor([[ 0.0243, -0.0030,  0.1084,  ..., -0.0085,  0.0041, -0.0290],
        [-0.0014,  0.0002, -0.0175,  ...,  0.0012, -0.0045, -0.0021],
        [-0.0710, -0.0126, -0.0241,  ..., -0.0231, -0.0592,  0.0156],
        ...,
        [ 0.0058,  0.0143,  0.0641,  ..., -0.0074, -0.0710,  0.0272],
        [ 0.0258,  0.0825, -0.1038,  ...,  0.0396,  0.0251, -0.0156],
        [ 0.0867,  0.0599,  0.1396,  ..., -0.0191, -0.0422, -0.0314]],
       device='cuda:0')), ('fcs.1.bias', tensor([ 0.0074, -0.0166, -0.0067, -0.0467,  0.0077, -0.1115,  0.0571, -0.0790,
        -0.1071, -0.0252, -0.0468,  0.0857, -0.0561, -0.0408,  0.1268,  0.1117,
         0.0145, -0.0956, -0.0952, -0.0592, -0.0878, -0.2022, -0.1111,  0.0054,
         0.0389, -0.0049, -0.1183,  0.0023,  0.0927, -0.0836,  0.0198, -0.0114,
        -0.0891, -0.1067, -0.0723, -0.0726, -0.0791, -0.0566,  0.0896,  0.0727,
        -0.0380, -0.0369,  0.0348,  0.0033, -0.0806,  0.1373, -0.0491, -0.0314,
        -0.1648, -0.0073,  0.0742, -0.0042, -0.0288, -0.0644, -0.0281,  0.0007,
        -0.0538, -0.0825, -0.0097,  0.1065, -0.0703,  0.0479, -0.0201,  0.0389],
       device='cuda:0')), ('fcs.2.weight', tensor([[ 0.0211,  0.0137, -0.1064, -0.0052, -0.0043,  0.0155,  0.0210, -0.0114,
          0.0505,  0.0116,  0.1057,  0.0172, -0.0521, -0.0359, -0.0035,  0.0349,
          0.0635, -0.0420,  0.0252,  0.0123, -0.0072, -0.0146,  0.1102, -0.0588,
         -0.0100, -0.0127,  0.0252,  0.0175,  0.0239, -0.0394, -0.0303, -0.0010,
         -0.0061,  0.0093,  0.0522, -0.0083, -0.0205, -0.1018,  0.0517, -0.0063,
         -0.0374,  0.0042, -0.0548,  0.0572, -0.0055,  0.0253, -0.0170,  0.0331,
          0.0413,  0.0529,  0.0010,  0.0010, -0.0014, -0.0374, -0.0183, -0.0095,
         -0.0375, -0.0217,  0.0304,  0.0068, -0.0031, -0.0107, -0.0227,  0.0064]],
       device='cuda:0'))])
end of epoch 2: val_loss 0.15086858870795367, val_acc 0.9
trigger times: 1
end of epoch 3: val_loss 0.3180246439820621, val_acc 0.8
trigger times: 2
end of epoch 4: val_loss 0.29086325418320486, val_acc 0.9
trigger times: 3
end of epoch 5: val_loss 0.19216520954532826, val_acc 0.9
trigger times: 4
end of epoch 6: val_loss 0.26214924374971815, val_acc 0.8
trigger times: 5
end of epoch 7: val_loss 0.29889382513938473, val_acc 0.9
trigger times: 6
end of epoch 8: val_loss 0.26432873457669076, val_acc 0.8
trigger times: 7
end of epoch 9: val_loss 0.4164884619368962, val_acc 0.9
trigger times: 8
end of epoch 10: val_loss 0.46891437556739674, val_acc 0.7
trigger times: 9
end of epoch 11: val_loss 18.15709228515625, val_acc 0.6
trigger times: 10
Early stopping.
0 767.0628855228424 -238.56539389647227
1 765.0958323478699 -226.82452825484978
2 677.9773271083832 -226.2241731451399
3 740.8569650650024 -208.89755486387574
4 676.9339537620544 -196.9840755292238
5 881.8380537033081 -194.4017457710484
6 669.6214258670807 -193.75394353311003
7 768.3303020000458 -173.38768743356906
8 644.4445040225983 -172.73844575529262
9 718.2422635555267 -172.5849598191294
10 808.4378967285156 -148.80630048130243
11 743.8583285808563 -146.54022994848935
12 762.8378229141235 -144.9163601843784
13 835.9650630950928 -144.5098799638122
14 757.3833513259888 -129.52710350510273
15 800.0822460651398 -119.6789138826375
16 818.0956544876099 -119.53338183357056
17 847.7043261528015 -115.00841352193844
18 768.2885715961456 -113.49466461352053
19 915.547744512558 -107.45837168117659
20 921.0494532585144 -105.49937100040788
21 931.8934001922607 -101.9104943327425
22 786.0087113380432 -101.66294130080523
23 883.4504806995392 -98.89606860541423
24 916.064658164978 -95.1909937931514
25 874.0992794036865 -93.31854913617367
26 899.8020038604736 -85.41926577166943
27 912.4000821113586 -83.18012153468804
28 805.8298540115356 -79.47665068598401
29 790.5973756313324 -77.34308621853297
30 935.5439801216125 -60.56041622227008
31 1020.6920313835144 -58.68833689293549
32 967.5176410675049 -22.79021187897909
33 955.500250339508 -19.65788926803626
34 971.6404318809509 -16.74518768263467
35 957.9786510467529 -13.719402302108403
36 957.023669719696 4.235189873860978
37 881.5392315387726 5.0952806210809465
38 986.6885285377502 10.178796790507759
39 930.7691388130188 13.541055788508864
40 921.9551618099213 14.989710929193077
41 974.6238541603088 21.802029683432238
42 861.6418578624725 31.12027905920427
43 952.3847057819366 40.64550156746333
44 1008.1421670913696 40.69898986216935
45 918.4361181259155 50.09032867204584
46 965.9801273345947 57.290535515424786
47 871.0883631706238 60.51441689036072
48 850.0869047641754 62.587858111632386
49 952.9726119041443 63.47489586756552
50 910.4843790531158 65.395531990224
51 965.0693249702454 68.71330703108626
52 929.6216540336609 69.48459209048262
53 977.4994740486145 72.16624272108386
54 919.2885723114014 74.2233202149037
55 921.1306092739105 79.16074531670823
56 917.0417110919952 80.25553156558418
57 942.0026121139526 87.50520028403979
58 944.3772916793823 90.28646231697512
59 968.3904795646667 90.72533900600311
60 964.588173866272 91.52552635781885
61 948.9621157646179 91.95773979158345
62 825.991396188736 92.99221310223136
63 854.1137893199921 94.14052712880752
64 926.0788226127625 94.28590507273401
65 929.0630941390991 95.24073532592021
66 934.2325801849365 96.09581961281374
67 1002.8938031196594 96.50341248035636
68 969.7904024124146 97.45820290396632
69 1000.5350904464722 97.90553231413178
70 918.5442023277283 98.27346635731779
71 943.0712194442749 98.35872828331676
72 944.9147820472717 98.9255090371917
73 945.5092806816101 99.09003071828721
74 908.3902850151062 99.89253842063019
75 975.3240523338318 100.07765055593329
76 985.8528985977173 101.35869827851857
77 873.0132944583893 103.56921378052652
78 990.9352340698242 103.74194540937737
79 942.9730787277222 104.00039883786899
80 962.7811665534973 104.36031383612816
81 942.2325134277344 104.79584301893571
82 943.0913572311401 105.40349710769756
83 995.7829632759094 105.60678192821229
84 975.760986328125 106.26867976298877
85 862.560174703598 106.37916921043517
86 1009.7638688087463 106.67969423997131
87 990.406090259552 106.81132709017433
88 984.2314438819885 107.05410485829283
89 972.898187160492 107.44441498172971
90 930.8473877906799 107.68792314282867
91 976.9070677757263 107.72369032284489
92 883.3932321071625 108.58631070626225
93 962.432590007782 108.79454915391223
94 1004.7620272636414 109.15712102315346
95 1026.1283292770386 109.71287331230647
96 995.4015717506409 110.48639228144049
97 1009.581850528717 111.4630258761226
98 954.075617313385 112.59201367677376
99 914.844156742096 113.4530990931055
100 948.5965497493744 114.85996346749971
101 956.5112097263336 115.04838323377467
102 985.0950860977173 115.5646624637931
103 855.4520723819733 115.77027450439896
104 913.2280602455139 116.29805012422126
105 1017.5478091239929 116.38499266629886
106 962.7136464118958 116.4198907102986
107 936.450222492218 117.08008835928221
108 932.072767496109 117.29357601720739
109 954.3902561664581 118.29160885622866
110 1002.7419505119324 119.01062500757773
111 983.4461960792542 120.85290512447664
112 1047.4231810569763 120.8902150231427
113 1031.9902448654175 121.40892075278066
114 978.5300829410553 122.30522808413322
115 1046.639591217041 129.13346806288703
116 1066.2618174552917 129.67718524437547
117 995.9666175842285 129.79664443488912
118 990.412606716156 130.61780866873775
119 1139.5636992454529 131.40806576766226
train accuracy: 0.8555555555555555
validation accuracy: 0.6
test accuracy: 0.6455182072829132
