demo lengths 200
demos: (120, 200, 25)
demo_rewards: (120,)
[-238.5653939  -226.82452825 -226.22417315 -208.89755486 -196.98407553
 -194.40174577 -193.75394353 -173.38768743 -172.73844576 -172.58495982
 -148.80630048 -146.54022995 -144.91636018 -144.50987996 -129.52710351
 -119.67891388 -119.53338183 -115.00841352 -113.49466461 -107.45837168
 -105.499371   -101.91049433 -101.6629413   -98.89606861  -95.19099379
  -93.31854914  -85.41926577  -83.18012153  -79.47665069  -77.34308622
  -60.56041622  -58.68833689  -22.79021188  -19.65788927  -16.74518768
  -13.7194023     4.23518987    5.09528062   10.17879679   13.54105579
   14.98971093   21.80202968   31.12027906   40.64550157   40.69898986
   50.09032867   57.29053552   60.51441689   62.58785811   63.47489587
   65.39553199   68.71330703   69.48459209   72.16624272   74.22332021
   79.16074532   80.25553157   87.50520028   90.28646232   90.72533901
   91.52552636   91.95773979   92.9922131    94.14052713   94.28590507
   95.24073533   96.09581961   96.50341248   97.4582029    97.90553231
   98.27346636   98.35872828   98.92550904   99.09003072   99.89253842
  100.07765056  101.35869828  103.56921378  103.74194541  104.00039884
  104.36031384  104.79584302  105.40349711  105.60678193  106.26867976
  106.37916921  106.67969424  106.81132709  107.05410486  107.44441498
  107.68792314  107.72369032  108.58631071  108.79454915  109.15712102
  109.71287331  110.48639228  111.46302588  112.59201368  113.45309909
  114.85996347  115.04838323  115.56466246  115.7702745   116.29805012
  116.38499267  116.41989071  117.08008836  117.29357602  118.29160886
  119.01062501  120.85290512  120.89021502  121.40892075  122.30522808
  129.13346806  129.67718524  129.79664443  130.61780867  131.40806577]
maximum traj length 200
maximum traj length 200
num training_obs 90
num training_labels 90
num val_obs 10
num val_labels 10
num test_obs 7140
num test_labels 7140
ModuleList(
  (0): Linear(in_features=25, out_features=128, bias=True)
  (1): Linear(in_features=128, out_features=64, bias=True)
  (2): Linear(in_features=64, out_features=1, bias=False)
)
Total number of parameters: 11648
Number of trainable paramters: 11648
device: cuda:0
end of epoch 0: val_loss 0.5013996546389535, val_acc 0.9
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-0.0303,  0.1799, -0.1477,  ..., -0.0634,  0.1041, -0.0928],
        [-0.0922,  0.2325, -0.2834,  ...,  0.1657, -0.0893, -0.1277],
        [ 0.2459,  0.1096,  0.0581,  ...,  0.0751,  0.2781,  0.0477],
        ...,
        [-0.1340,  0.1059, -0.0718,  ...,  0.1712, -0.1846, -0.2062],
        [-0.0237,  0.0208, -0.2145,  ...,  0.0928, -0.1356, -0.0337],
        [-0.1230, -0.0171, -0.0336,  ...,  0.0239,  0.1520, -0.2591]],
       device='cuda:0')), ('fcs.0.bias', tensor([-0.1213, -0.0209,  0.0562, -0.2923, -0.0748, -0.0113,  0.0269, -0.1475,
        -0.0267,  0.0878,  0.0726,  0.0553, -0.1998,  0.0831, -0.0645,  0.0233,
         0.0378,  0.1192,  0.0710,  0.1871, -0.1578,  0.0522,  0.0860,  0.0784,
        -0.1717, -0.1517,  0.0049,  0.0376,  0.1380, -0.0220,  0.0944, -0.0695,
         0.2286,  0.0652,  0.0369, -0.1138, -0.0851,  0.0407,  0.0896, -0.2029,
        -0.0244, -0.0830,  0.0840,  0.0825,  0.0292, -0.2639, -0.2084,  0.2073,
        -0.1696, -0.0798,  0.1746, -0.1041,  0.0566, -0.2525,  0.0101, -0.0062,
        -0.0788, -0.2115, -0.2111,  0.0735, -0.0515, -0.1454, -0.1296, -0.1926,
         0.1971,  0.0559, -0.2497, -0.1308, -0.1591,  0.1215, -0.1469, -0.1086,
        -0.1136, -0.2034, -0.3089, -0.1901, -0.2865, -0.0317, -0.0287, -0.0158,
        -0.0899,  0.1964, -0.1347, -0.0250, -0.0616, -0.1290,  0.1399,  0.0471,
         0.0363,  0.0338,  0.0272,  0.1412, -0.0561,  0.0909,  0.1977,  0.1319,
        -0.2939, -0.0474, -0.1927,  0.1088,  0.0304,  0.0238, -0.1906, -0.1154,
        -0.0143,  0.2851, -0.2013, -0.0186,  0.3045,  0.0885, -0.0871,  0.0682,
         0.1335,  0.2370, -0.0352, -0.2187,  0.0022,  0.0032,  0.0751, -0.2394,
         0.1944, -0.1231,  0.0604,  0.2711,  0.1671, -0.0390,  0.1133,  0.1416],
       device='cuda:0')), ('fcs.1.weight', tensor([[-0.0773, -0.0645,  0.0284,  ..., -0.0055,  0.0338,  0.0073],
        [-0.1036, -0.0838, -0.0578,  ...,  0.0319, -0.0506, -0.0712],
        [-0.0787, -0.0835,  0.0985,  ...,  0.0551,  0.0642,  0.1147],
        ...,
        [ 0.0172, -0.0007, -0.0086,  ...,  0.0359, -0.0543, -0.0172],
        [ 0.1110,  0.1088, -0.0402,  ...,  0.0527,  0.1217,  0.0471],
        [ 0.0095,  0.0214,  0.1150,  ..., -0.0279,  0.0958, -0.0101]],
       device='cuda:0')), ('fcs.1.bias', tensor([-4.9849e-02, -7.2397e-02,  1.1071e-01, -9.3945e-02,  2.7472e-03,
        -9.7177e-02, -2.9497e-02, -7.6225e-02, -1.4300e-01, -1.1664e-01,
         2.4787e-02,  2.4096e-02, -3.3623e-02, -3.9345e-02,  1.4484e-02,
         6.8902e-02,  2.1782e-02, -5.8311e-02, -6.0559e-02, -8.7140e-02,
        -5.4809e-02, -1.2074e-01, -2.4819e-02, -8.8574e-05, -7.2316e-02,
        -7.4953e-02, -8.6801e-02, -1.6337e-02, -5.5968e-02, -6.2085e-02,
         2.9734e-02, -6.3843e-03, -9.3115e-02,  3.1673e-02, -4.1727e-02,
         1.3573e-01, -9.1479e-03,  9.6129e-02, -2.4284e-02, -9.2781e-02,
        -3.2825e-02,  3.4232e-02, -5.1501e-02,  8.9411e-02, -9.4830e-02,
         8.5279e-02, -6.2085e-02, -4.6017e-03, -5.5443e-02, -1.6032e-02,
        -2.2635e-02, -7.1095e-02, -3.4636e-02, -5.8010e-02, -4.7752e-02,
        -6.2039e-02, -4.4572e-02, -1.1576e-01,  9.9767e-03,  1.3095e-01,
         1.9183e-01, -4.1154e-02,  5.2560e-02,  7.4369e-02], device='cuda:0')), ('fcs.2.weight', tensor([[ 0.0179,  0.0030,  0.0020,  0.0668, -0.0564, -0.0548, -0.1081,  0.0149,
          0.0080,  0.0559,  0.0083,  0.0102, -0.0616,  0.0182,  0.0128,  0.0138,
          0.0056, -0.0722,  0.0030, -0.0383, -0.0487, -0.0637,  0.0025, -0.0726,
         -0.0471,  0.0410, -0.0610, -0.0097,  0.0103, -0.1384,  0.0236,  0.0368,
         -0.0537,  0.0036,  0.0247,  0.0031, -0.0275, -0.0433,  0.0714, -0.0448,
          0.0358, -0.0066, -0.0343, -0.0186, -0.0922,  0.0026,  0.0095,  0.0194,
         -0.0389, -0.0054, -0.0062,  0.0015,  0.0491, -0.0038,  0.0015, -0.0074,
         -0.0417, -0.0189,  0.0040, -0.0109, -0.0310,  0.0228, -0.0223, -0.0204]],
       device='cuda:0'))])
end of epoch 1: val_loss 0.5806777832915031, val_acc 0.9
trigger times: 1
end of epoch 2: val_loss 0.6007351546897552, val_acc 0.9
trigger times: 2
end of epoch 3: val_loss 0.35740383947886584, val_acc 0.9
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-0.0303,  0.1782, -0.1444,  ..., -0.0628,  0.1027, -0.0919],
        [-0.1845,  0.2275, -0.2860,  ...,  0.1473, -0.2380, -0.1321],
        [ 0.2284,  0.1247,  0.0813,  ...,  0.0887,  0.2503,  0.0543],
        ...,
        [-0.1330,  0.0985, -0.0695,  ...,  0.1651, -0.1833, -0.0435],
        [-0.0263,  0.0241, -0.2106,  ...,  0.0902, -0.1405, -0.0335],
        [-0.1276, -0.0244, -0.0074,  ...,  0.0097,  0.1473, -0.2499]],
       device='cuda:0')), ('fcs.0.bias', tensor([-1.2049e-01, -1.8712e-01,  4.8536e-02, -1.6506e-01, -9.1523e-02,
        -1.1035e-02, -5.0138e-04, -1.4529e-02, -2.6458e-02,  8.7277e-02,
         7.2237e-02,  4.9637e-02, -2.0003e-01,  8.9305e-02, -6.0655e-02,
         2.1324e-02,  4.4315e-02,  1.1399e-01,  6.3861e-02,  1.8515e-01,
        -1.2585e-01,  4.7091e-02,  8.1538e-02,  9.1480e-02, -2.6467e-02,
        -1.4560e-01,  4.8618e-03,  1.9337e-03,  1.3616e-01, -2.1524e-02,
         7.6151e-02, -6.8508e-02,  2.3341e-01,  5.2770e-02,  3.5972e-02,
        -1.1357e-01, -8.1802e-02,  4.0406e-02,  8.6473e-02, -3.0943e-02,
        -1.4449e-02, -8.8017e-02,  2.5079e-04,  8.2197e-02,  2.4179e-02,
        -2.6267e-01, -2.0717e-01,  2.0270e-01, -6.4403e-02, -7.9697e-02,
         1.7868e-01, -7.0808e-02,  5.8865e-02, -2.5764e-01,  7.8727e-03,
        -1.6115e-03, -1.2343e-02, -2.0358e-01, -2.1075e-01,  6.7784e-02,
        -5.2835e-02, -1.4487e-01, -3.2967e-02, -1.8877e-01,  2.0341e-01,
         6.3252e-02, -2.4497e-01, -1.3074e-01, -1.0213e-01,  1.2210e-01,
        -1.4614e-01, -1.0721e-01, -2.3913e-02, -2.0017e-01, -3.0742e-01,
        -1.8774e-01, -2.2248e-01, -3.1508e-02, -2.3788e-02, -2.5144e-02,
        -8.9332e-02,  1.9647e-01, -1.3641e-01, -2.5965e-02, -6.1826e-02,
        -6.5620e-02,  1.4504e-01,  4.7525e-02,  2.1168e-02,  3.4473e-02,
         2.6896e-02,  8.8684e-02, -5.3584e-02,  7.7911e-02,  1.9906e-01,
         1.2711e-01, -2.9168e-01, -4.7176e-02, -1.9927e-01,  1.0663e-01,
         2.2208e-02,  2.3502e-02, -1.8955e-01, -1.1413e-01, -3.1782e-02,
         2.7876e-01, -1.8312e-01, -1.9022e-02,  2.9656e-01,  8.3360e-02,
        -8.6568e-02,  2.3753e-02,  1.2393e-01,  2.4377e-01, -4.6111e-03,
        -2.0418e-01,  9.0767e-03,  2.8775e-03,  1.7591e-02, -2.2219e-01,
         2.1660e-01, -1.3178e-01,  5.9962e-02,  2.8049e-01,  1.6692e-01,
        -3.8718e-02,  1.0514e-01,  1.4538e-01], device='cuda:0')), ('fcs.1.weight', tensor([[-0.0764, -0.0637,  0.0281,  ..., -0.0047,  0.0328,  0.0069],
        [-0.0957, -0.0788, -0.0545,  ...,  0.0002, -0.0492, -0.0701],
        [-0.0763, -0.1010,  0.0349,  ...,  0.0413,  0.0610,  0.0650],
        ...,
        [ 0.0002,  0.0097, -0.0028,  ...,  0.0009, -0.0434, -0.0004],
        [ 0.1094,  0.0737, -0.0476,  ...,  0.0515,  0.1192,  0.0208],
        [ 0.0099, -0.0237,  0.0254,  ...,  0.0003,  0.0918, -0.0516]],
       device='cuda:0')), ('fcs.1.bias', tensor([-4.9550e-02, -7.1432e-02,  1.0961e-01, -9.0773e-02,  2.5669e-03,
        -9.6514e-02, -2.9492e-02, -7.2822e-02, -1.4052e-01, -1.2005e-01,
         1.9849e-02,  2.3178e-02, -3.2919e-02, -3.8993e-02,  1.4830e-02,
        -3.4816e-02,  2.1588e-02, -5.5992e-02, -6.4206e-02, -8.6757e-02,
        -5.4323e-02, -1.1992e-01, -2.4471e-02, -9.6995e-05, -7.0693e-02,
        -7.4374e-02, -8.6119e-02, -1.6588e-02, -5.5402e-02, -1.5221e-01,
         1.1133e-02, -6.7063e-03, -8.9914e-02,  2.9271e-02, -4.1948e-02,
         5.7824e-02, -9.0344e-03,  8.8967e-02, -2.4067e-02, -8.7207e-02,
        -3.1778e-02,  2.9557e-02, -5.1358e-02,  8.7449e-02, -9.4571e-02,
         8.4035e-02, -5.9616e-02, -8.0640e-03, -5.5224e-02, -2.1764e-02,
        -1.4864e-01, -6.7496e-02, -3.4455e-02, -2.6428e-02, -4.7434e-02,
        -5.9811e-02, -3.5513e-02, -1.1279e-01,  9.9052e-03,  1.2952e-01,
         1.9988e-01, -3.3962e-02,  4.7853e-02,  7.3882e-02], device='cuda:0')), ('fcs.2.weight', tensor([[ 1.4365e-02, -4.5123e-03,  2.2885e-02,  6.9277e-02, -5.5230e-02,
         -5.3831e-02, -1.0969e-01, -3.8444e-03,  7.9454e-03,  5.4544e-02,
         -5.4552e-04,  9.6358e-03, -6.9856e-02,  2.0812e-02,  4.5426e-02,
          3.7146e-02,  9.1747e-03, -7.2870e-02, -3.0321e-02, -3.7686e-02,
         -4.3198e-02, -6.0543e-02,  4.1078e-03, -6.8077e-02, -4.9218e-02,
          4.0145e-02, -6.5175e-02, -8.3622e-03,  7.5831e-03, -8.9168e-02,
          2.2809e-02,  3.7909e-02, -5.1432e-02,  2.2490e-03,  2.4701e-02,
         -7.4439e-05,  2.2622e-02, -1.6277e-02,  7.7359e-02, -2.3909e-02,
          3.6499e-02,  3.5327e-03, -1.3500e-02,  1.7401e-02, -9.1682e-02,
          1.2273e-02,  9.7027e-03,  8.7855e-03, -4.1317e-02, -8.4560e-03,
          1.3078e-02, -1.2337e-02,  4.9462e-02, -1.2317e-02,  3.8533e-03,
         -9.9752e-03, -2.3838e-02, -1.8342e-02,  1.7473e-02,  1.4828e-02,
         -3.3930e-02,  3.2256e-03, -1.8052e-02,  2.3713e-02]], device='cuda:0'))])
end of epoch 4: val_loss 2.2716229160883814, val_acc 0.9
trigger times: 1
end of epoch 5: val_loss 0.5653529273375171, val_acc 0.9
trigger times: 2
end of epoch 6: val_loss 0.42620157613418996, val_acc 0.8
trigger times: 3
end of epoch 7: val_loss 0.28533667016308756, val_acc 0.9
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-0.0279,  0.1770, -0.1366,  ..., -0.0598,  0.1017, -0.0886],
        [-0.1766,  0.2256, -0.2691,  ...,  0.1456, -0.2270, -0.1293],
        [ 0.6274,  0.2209,  0.2265,  ...,  0.1699,  0.5669,  0.0452],
        ...,
        [-0.1308,  0.0737, -0.0660,  ...,  0.1501, -0.1805, -0.0242],
        [-0.0220,  0.0227, -0.1953,  ...,  0.0891, -0.1322, -0.0325],
        [-0.2623, -0.1184, -0.0665,  ...,  0.1312, -0.0494, -0.2484]],
       device='cuda:0')), ('fcs.0.bias', tensor([-0.1166, -0.1780,  0.3362, -0.0593, -0.2461, -0.0078, -0.2042, -0.0349,
        -0.0233,  0.0867,  0.0725,  0.0172, -0.1929,  0.3086, -0.0418,  0.0211,
         0.2759,  0.0310,  0.0578,  0.1823, -0.0577,  0.0348,  0.0251, -0.0778,
        -0.1720, -0.1424,  0.0124, -0.1602,  0.1331, -0.0204, -0.0771, -0.0670,
         0.3501,  0.3544,  0.0317, -0.1159, -0.1009,  0.0387,  0.0760, -0.2059,
        -0.2873, -0.0944, -0.0204,  0.0809,  0.1779, -0.2598, -0.2033,  0.4682,
        -0.0800, -0.0770, -0.0126, -0.0438, -0.0764, -0.2698,  0.0043, -0.0215,
        -0.0924, -0.1915, -0.2070, -0.0416, -0.0594, -0.1488, -0.2090, -0.1742,
         0.4759, -0.0957, -0.2334, -0.1260, -0.1344,  0.0172, -0.1441, -0.1014,
         0.0006, -0.1879, -0.3035, -0.1946, -0.0728, -0.0316, -0.1509, -0.1563,
        -0.0870,  0.0293, -0.1337, -0.0197,  0.1006, -0.2054,  0.4680, -0.2652,
        -0.1252, -0.1677,  0.0274,  0.0894, -0.0503,  0.0174,  0.4799,  0.0017,
        -0.2837, -0.0472, -0.2144,  0.1043, -0.0448,  0.0679, -0.1868, -0.1097,
        -0.1604,  0.1284, -0.1311, -0.0182,  0.4322,  0.0777, -0.0852,  0.1366,
         0.3887,  0.2843, -0.2262, -0.1650,  0.1815, -0.0023, -0.0382, -0.1858,
         0.2085, -0.1526,  0.0586,  0.4289, -0.0576, -0.0385,  0.1076,  0.0899],
       device='cuda:0')), ('fcs.1.weight', tensor([[-7.4270e-02, -6.1937e-02,  2.7705e-02,  ..., -3.4340e-03,
          3.0815e-02,  5.6337e-03],
        [-7.9594e-02, -6.9526e-02, -3.3849e-02,  ...,  4.3161e-03,
         -4.5882e-02, -7.0159e-02],
        [-6.7340e-02, -9.8896e-02, -3.7250e-02,  ..., -2.6326e-02,
          5.9953e-02,  2.4851e-01],
        ...,
        [ 2.1071e-04,  1.9192e-02, -1.9150e-01,  ..., -4.4036e-03,
         -2.1087e-02, -2.1288e-01],
        [ 1.0985e-01,  7.4043e-02, -2.1979e-01,  ...,  5.0313e-02,
          1.1725e-01, -4.6740e-02],
        [ 5.8942e-03, -2.0223e-02, -2.2651e-01,  ...,  4.3625e-02,
          9.0830e-02, -1.7488e-01]], device='cuda:0')), ('fcs.1.bias', tensor([-4.8803e-02, -6.8935e-02,  1.9634e-01, -1.1023e-01,  2.5120e-03,
        -9.4718e-02, -2.9397e-02, -1.8513e-01, -1.3322e-01, -1.1374e-01,
         1.6641e-02,  2.2570e-02, -1.9204e-01, -3.8174e-02,  1.4450e-02,
        -3.1090e-02,  2.1375e-02, -5.1011e-02, -2.2967e-02, -8.5276e-02,
        -5.3163e-02, -1.1805e-01, -2.3314e-02, -9.6438e-05, -6.7099e-02,
        -6.9975e-02, -8.4499e-02, -1.6324e-02, -5.4090e-02, -1.4530e-01,
         1.0177e-02, -6.5736e-03, -2.8897e-01,  2.4621e-02, -3.9806e-02,
         5.2031e-02, -1.6475e-01,  9.7437e-02, -2.3552e-02, -7.4033e-02,
        -2.9475e-02, -1.8420e-02, -5.1015e-02,  6.3011e-02, -9.3364e-02,
         2.4942e-02, -5.0450e-02, -7.9177e-03, -5.4681e-02,  1.8677e-01,
        -1.4044e-01, -5.9814e-02, -1.6480e-01,  5.0368e-02, -4.6672e-02,
        -5.5018e-02, -1.4258e-02, -1.0566e-01,  9.7641e-03,  1.2578e-01,
         3.6752e-01, -2.2843e-01, -9.8538e-02, -7.5482e-02], device='cuda:0')), ('fcs.2.weight', tensor([[-0.0012,  0.0384, -0.0127,  0.0063, -0.0447, -0.0457, -0.1036, -0.0014,
          0.0090,  0.0474,  0.0027,  0.0077, -0.0656,  0.0208, -0.0053,  0.0402,
          0.0235, -0.0772,  0.0109, -0.0347, -0.0309, -0.0506,  0.0082, -0.0485,
         -0.0444,  0.0405, -0.0776, -0.0042,  0.0017, -0.1115,  0.0221,  0.0412,
         -0.0300, -0.0015,  0.0260, -0.0006, -0.0011,  0.0208,  0.0817,  0.0272,
          0.0296, -0.0171,  0.0355, -0.0143, -0.0877,  0.0649,  0.0076,  0.0153,
         -0.0508,  0.0285,  0.0104,  0.0147, -0.0477,  0.0479,  0.0155, -0.0126,
          0.0301, -0.0066,  0.0259, -0.0319, -0.0356, -0.0292, -0.0550,  0.0317]],
       device='cuda:0'))])
end of epoch 8: val_loss 0.5756773006403819, val_acc 0.9
trigger times: 1
end of epoch 9: val_loss 0.6493499639749644, val_acc 0.8
trigger times: 2
end of epoch 10: val_loss 0.30451171640888786, val_acc 0.9
trigger times: 3
end of epoch 11: val_loss 0.405502152023837, val_acc 0.9
trigger times: 4
end of epoch 12: val_loss 0.5032450151164085, val_acc 0.8
trigger times: 5
end of epoch 13: val_loss 0.34958199614775365, val_acc 0.9
trigger times: 6
end of epoch 14: val_loss 0.8766616781190351, val_acc 0.8
trigger times: 7
end of epoch 15: val_loss 0.6293558352976106, val_acc 0.9
trigger times: 8
end of epoch 16: val_loss 0.3959713249467313, val_acc 0.9
trigger times: 9
end of epoch 17: val_loss 0.07933321980162873, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-0.0255,  0.1624, -0.1095,  ..., -0.0535,  0.0927, -0.0763],
        [-0.1534,  0.2165, -0.2131,  ...,  0.1367, -0.1898, -0.1186],
        [ 0.5562,  0.1142,  0.1676,  ...,  0.0792,  0.5250,  0.0352],
        ...,
        [-0.1215,  0.0410, -0.0476,  ...,  0.1040, -0.1682, -0.0150],
        [-0.0213,  0.0224, -0.1435,  ...,  0.0795, -0.1193, -0.0275],
        [-0.1238, -0.1417, -0.0925,  ...,  0.1502, -0.1243, -0.1395]],
       device='cuda:0')), ('fcs.0.bias', tensor([-1.0645e-01, -1.4910e-01,  3.1430e-01, -1.4625e-04, -2.2169e-01,
        -6.4396e-03, -1.9307e-01,  9.6691e-03, -2.0738e-02,  8.1433e-02,
         6.9259e-02,  7.7790e-03, -2.0385e-01,  3.0792e-01, -2.1103e-02,
         2.6086e-03,  2.6092e-01,  1.5021e-01,  4.6502e-02,  2.0771e-01,
        -5.8058e-02,  3.0364e-02, -1.1732e-01, -9.5086e-02, -3.7530e-02,
        -8.7573e-02,  8.4113e-03, -1.5399e-01,  1.1586e-01, -5.0028e-02,
        -6.6372e-02, -5.7281e-02,  4.0911e-01,  3.1795e-01,  2.5892e-02,
        -1.1190e-01, -8.6650e-02,  3.5548e-02,  5.2002e-02, -4.4132e-02,
        -8.1463e-02, -1.0504e-01, -7.2716e-02,  7.8303e-02,  1.4949e-01,
        -2.4748e-01, -1.9020e-01,  4.5171e-01, -1.1351e-01, -7.0520e-02,
        -1.1856e-02, -5.0988e-02,  2.4138e-02, -2.0466e-01,  1.3743e-03,
        -1.4806e-04, -9.7961e-04, -1.3004e-01, -1.9444e-01, -3.7640e-02,
        -5.1335e-02, -1.2815e-01, -1.6042e-01, -1.3692e-01,  4.4789e-01,
        -8.7014e-02, -1.9272e-01, -1.1128e-01, -1.8373e-03,  1.6105e-02,
        -1.3615e-01, -8.8698e-02, -7.0084e-04, -1.5912e-01, -2.8309e-01,
        -1.7191e-01, -5.1450e-03, -2.9377e-02, -1.3910e-01, -1.5001e-01,
        -8.1289e-02,  2.8459e-02, -1.2324e-01, -3.5751e-02,  9.4830e-02,
        -6.6816e-02,  4.4977e-01, -2.3688e-01, -3.0984e-03, -1.6687e-01,
         2.5799e-02,  8.0686e-02, -3.1726e-02,  3.5026e-02,  4.4924e-01,
         1.3886e-03, -2.5812e-01, -4.4713e-02, -2.0641e-01,  9.7644e-02,
        -3.6939e-02,  7.6759e-02, -1.7605e-01, -9.5783e-02, -1.5292e-01,
         1.7592e-01, -4.9237e-02, -1.6416e-02,  3.6866e-01,  6.7647e-02,
        -8.0142e-02, -3.7399e-02,  3.6648e-01,  2.9503e-01, -1.2108e-01,
        -8.0650e-02,  1.7145e-01, -2.5930e-03,  2.6130e-07,  8.6999e-02,
         2.2721e-01, -1.0926e-01,  5.4378e-02,  4.0339e-01, -5.5431e-02,
        -3.6065e-02,  9.4102e-02,  1.9943e-01], device='cuda:0')), ('fcs.1.weight', tensor([[-0.0655, -0.0546,  0.0235,  ..., -0.0007,  0.0234,  0.0083],
        [-0.0349, -0.0401, -0.0152,  ...,  0.0018, -0.0337, -0.0565],
        [-0.0465, -0.0858, -0.1641,  ..., -0.0023,  0.0451,  0.2311],
        ...,
        [-0.0041,  0.0049, -0.1406,  ...,  0.0053, -0.0022, -0.0652],
        [ 0.0962,  0.0690, -0.2174,  ...,  0.0383,  0.1040, -0.0382],
        [ 0.0044, -0.0181, -0.2133,  ..., -0.0007,  0.0744, -0.1716]],
       device='cuda:0')), ('fcs.1.bias', tensor([-4.5618e-02, -5.8856e-02,  1.4837e-01, -1.0091e-01,  2.2817e-03,
        -8.7138e-02, -2.8975e-02, -1.2600e-01, -1.0509e-01, -8.9488e-02,
         1.5524e-02,  2.0055e-02, -1.8976e-01, -3.4739e-02,  1.1653e-02,
        -1.8789e-02,  2.0457e-02, -3.3802e-02, -9.9039e-03, -7.9000e-02,
        -4.8304e-02, -1.1010e-01, -1.8802e-02, -9.4025e-05, -5.3215e-02,
        -5.3364e-02, -7.7881e-02, -1.5199e-02, -4.8629e-02, -1.1823e-01,
         6.8284e-03, -6.0152e-03, -2.5700e-01,  1.1390e-02, -3.1536e-02,
         3.2535e-02, -1.5339e-01,  9.5250e-02, -3.2996e-02, -3.5692e-02,
        -3.6916e-02, -1.5482e-02, -4.9519e-02,  6.7248e-02, -8.8191e-02,
        -1.1145e-02, -2.3833e-02, -7.2993e-03, -5.2332e-02,  2.0335e-01,
        -1.0915e-01, -3.9304e-02, -1.5961e-01,  3.7229e-02, -4.3432e-02,
        -3.7950e-02,  3.4115e-02, -7.9049e-02,  9.1614e-03,  1.8901e-01,
         4.8050e-01, -1.3300e-01, -9.3004e-02, -7.0920e-02], device='cuda:0')), ('fcs.2.weight', tensor([[-0.0294, -0.0257,  0.0118, -0.0146, -0.0367, -0.0450, -0.1295, -0.0849,
          0.0074,  0.0310, -0.0004,  0.0042, -0.1956, -0.0061, -0.0083,  0.0410,
          0.0259, -0.1273, -0.0352, -0.0344, -0.0185, -0.0753,  0.0059, -0.1732,
         -0.0769,  0.0395, -0.1058, -0.0051, -0.0283, -0.2612,  0.0197,  0.0428,
         -0.0593, -0.0054,  0.0253, -0.0016, -0.0023, -0.0004,  0.0720,  0.0032,
          0.0100, -0.0141, -0.0004, -0.0142, -0.0892,  0.0667,  0.0041,  0.0244,
         -0.0753,  0.0027,  0.0032, -0.0190, -0.0788,  0.0527, -0.0153, -0.0226,
          0.0733, -0.0223,  0.0100, -0.0272, -0.0244, -0.0853, -0.0643,  0.0259]],
       device='cuda:0'))])
end of epoch 18: val_loss 2.813937782784342, val_acc 0.9
trigger times: 1
end of epoch 19: val_loss 0.7295073007275164, val_acc 0.8
trigger times: 2
end of epoch 20: val_loss 6.86112284658775, val_acc 0.8
trigger times: 3
end of epoch 21: val_loss 4.1785180879795, val_acc 0.8
trigger times: 4
end of epoch 22: val_loss 2.978934073448147, val_acc 0.9
trigger times: 5
end of epoch 23: val_loss 0.8794627311250451, val_acc 0.9
trigger times: 6
end of epoch 24: val_loss 0.8347561381728099, val_acc 0.8
trigger times: 7
end of epoch 25: val_loss 0.7075963816577258, val_acc 0.8
trigger times: 8
end of epoch 26: val_loss 0.4081404248167928, val_acc 0.9
trigger times: 9
end of epoch 27: val_loss 0.5534306078627083, val_acc 0.8
trigger times: 10
Early stopping.
0 -22.541971500962973 -238.56539389647227
1 -21.284856639802456 -226.82452825484978
2 -37.53497878462076 -226.2241731451399
3 -19.18221379071474 -208.89755486387574
4 -27.203143648803234 -196.9840755292238
5 -9.630716562271118 -194.4017457710484
6 -27.04428720474243 -193.75394353311003
7 -24.312866237014532 -173.38768743356906
8 -28.06599234417081 -172.73844575529262
9 -18.262118799611926 -172.5849598191294
10 -12.235113678500056 -148.80630048130243
11 -22.78114467486739 -146.54022994848935
12 -16.481118477880955 -144.9163601843784
13 -16.64756340160966 -144.5098799638122
14 -13.4749038182199 -129.52710350510273
15 -14.425711231306195 -119.6789138826375
16 -10.952319920063019 -119.53338183357056
17 -11.73053902387619 -115.00841352193844
18 -15.022562883794308 -113.49466461352053
19 -6.727691982872784 -107.45837168117659
20 -10.995035774772987 -105.49937100040788
21 -3.6271295621991158 -101.9104943327425
22 -8.690437576500699 -101.66294130080523
23 -8.784229134209454 -98.89606860541423
24 -7.18385105393827 -95.1909937931514
25 -7.142936930060387 -93.31854913617367
26 -9.056563522201031 -85.41926577166943
27 -7.638644279446453 -83.18012153468804
28 -4.541026196675375 -79.47665068598401
29 -10.655280973296613 -77.34308621853297
30 -1.6020095497369766 -60.56041622227008
31 -7.687996375840157 -58.68833689293549
32 -5.121567882131785 -22.79021187897909
33 -4.670575986150652 -19.65788926803626
34 -3.1607945288997144 -16.74518768263467
35 -7.075977795757353 -13.719402302108403
36 -2.220516534987837 4.235189873860978
37 -5.79509840044193 5.0952806210809465
38 -3.721810129471123 10.178796790507759
39 -8.63671922730282 13.541055788508864
40 -8.098814089782536 14.989710929193077
41 -4.311448432505131 21.802029683432238
42 -8.0527836503461 31.12027905920427
43 -4.546429955167696 40.64550156746333
44 -6.803854161640629 40.69898986216935
45 -3.9841022230684757 50.09032867204584
46 -4.822642643004656 57.290535515424786
47 -0.8670351733453572 60.51441689036072
48 -2.2158845476806164 62.587858111632386
49 -9.120924461632967 63.47489586756552
50 -6.045017227996141 65.395531990224
51 -2.456454790662974 68.71330703108626
52 -5.6180271385237575 69.48459209048262
53 -3.2347588527482003 72.16624272108386
54 -5.449759915471077 74.2233202149037
55 -8.67494741617702 79.16074531670823
56 -2.875187306199223 80.25553156558418
57 -9.017021547071636 87.50520028403979
58 -7.9011953982990235 90.28646231697512
59 -5.64620942575857 90.72533900600311
60 -6.961574316490442 91.52552635781885
61 -1.6409230371937156 91.95773979158345
62 -5.299331100890413 92.99221310223136
63 -6.614027582574636 94.14052712880752
64 -6.387917891610414 94.28590507273401
65 -5.265517657622695 95.24073532592021
66 -4.931697698775679 96.09581961281374
67 -4.648902337998152 96.50341248035636
68 -9.726251274812967 97.45820290396632
69 -5.422923616599292 97.90553231413178
70 -6.85896558733657 98.27346635731779
71 -6.712763614486903 98.35872828331676
72 -6.274485575733706 98.9255090371917
73 -7.189000513404608 99.09003071828721
74 -3.447221212554723 99.89253842063019
75 -6.044651929754764 100.07765055593329
76 -4.532548493240029 101.35869827851857
77 -7.193478815257549 103.56921378052652
78 -4.438918745145202 103.74194540937737
79 -3.883098911959678 104.00039883786899
80 -7.267864218680188 104.36031383612816
81 -3.9896987369284034 104.79584301893571
82 -3.7105197212658823 105.40349710769756
83 -4.009570903610438 105.60678192821229
84 -7.159631460905075 106.26867976298877
85 -3.0916016614064574 106.37916921043517
86 -1.7176536640617996 106.67969423997131
87 -3.9840825712308288 106.81132709017433
88 -4.338581619318575 107.05410485829283
89 -2.821905928198248 107.44441498172971
90 -2.912947335280478 107.68792314282867
91 -5.575247820466757 107.72369032284489
92 -4.283546673133969 108.58631070626225
93 -3.1406397935934365 108.79454915391223
94 -5.627145625650883 109.15712102315346
95 -2.5989670362323523 109.71287331230647
96 -3.9978907029144466 110.48639228144049
97 -2.5845655160956085 111.4630258761226
98 -4.161513533908874 112.59201367677376
99 -3.4109762783627957 113.4530990931055
100 -1.6196110430173576 114.85996346749971
101 -3.260297341737896 115.04838323377467
102 -3.412271616514772 115.5646624637931
103 -4.221592734800652 115.77027450439896
104 -2.7927115689963102 116.29805012422126
105 -1.8984615015797317 116.38499266629886
106 -4.869917839299887 116.4198907102986
107 -2.272851800080389 117.08008835928221
108 -2.1508422773331404 117.29357601720739
109 -2.922510160598904 118.29160885622866
110 -0.6420884071849287 119.01062500757773
111 -1.7280516689643264 120.85290512447664
112 -3.4590829419903457 120.8902150231427
113 -1.3766754930838943 121.40892075278066
114 0.04729909962043166 122.30522808413322
115 -1.1651036515831947 129.13346806288703
116 -0.3775427956134081 129.67718524437547
117 -0.9583515333943069 129.79664443488912
118 -2.2485730377957225 130.61780866873775
119 0.6036590500734746 131.40806576766226
train accuracy: 0.8777777777777778
validation accuracy: 0.8
test accuracy: 0.7145658263305322
