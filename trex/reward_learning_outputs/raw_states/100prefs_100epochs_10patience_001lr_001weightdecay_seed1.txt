demo lengths 200
demos: (120, 200, 25)
demo_rewards: (120,)
[-238.5653939  -226.82452825 -226.22417315 -208.89755486 -196.98407553
 -194.40174577 -193.75394353 -173.38768743 -172.73844576 -172.58495982
 -148.80630048 -146.54022995 -144.91636018 -144.50987996 -129.52710351
 -119.67891388 -119.53338183 -115.00841352 -113.49466461 -107.45837168
 -105.499371   -101.91049433 -101.6629413   -98.89606861  -95.19099379
  -93.31854914  -85.41926577  -83.18012153  -79.47665069  -77.34308622
  -60.56041622  -58.68833689  -22.79021188  -19.65788927  -16.74518768
  -13.7194023     4.23518987    5.09528062   10.17879679   13.54105579
   14.98971093   21.80202968   31.12027906   40.64550157   40.69898986
   50.09032867   57.29053552   60.51441689   62.58785811   63.47489587
   65.39553199   68.71330703   69.48459209   72.16624272   74.22332021
   79.16074532   80.25553157   87.50520028   90.28646232   90.72533901
   91.52552636   91.95773979   92.9922131    94.14052713   94.28590507
   95.24073533   96.09581961   96.50341248   97.4582029    97.90553231
   98.27346636   98.35872828   98.92550904   99.09003072   99.89253842
  100.07765056  101.35869828  103.56921378  103.74194541  104.00039884
  104.36031384  104.79584302  105.40349711  105.60678193  106.26867976
  106.37916921  106.67969424  106.81132709  107.05410486  107.44441498
  107.68792314  107.72369032  108.58631071  108.79454915  109.15712102
  109.71287331  110.48639228  111.46302588  112.59201368  113.45309909
  114.85996347  115.04838323  115.56466246  115.7702745   116.29805012
  116.38499267  116.41989071  117.08008836  117.29357602  118.29160886
  119.01062501  120.85290512  120.89021502  121.40892075  122.30522808
  129.13346806  129.67718524  129.79664443  130.61780867  131.40806577]
maximum traj length 200
maximum traj length 200
num training_obs 90
num training_labels 90
num val_obs 10
num val_labels 10
num test_obs 7140
num test_labels 7140
ModuleList(
  (0): Linear(in_features=25, out_features=128, bias=True)
  (1): Linear(in_features=128, out_features=64, bias=True)
  (2): Linear(in_features=64, out_features=1, bias=False)
)
Total number of parameters: 11648
Number of trainable paramters: 11648
device: cuda:0
end of epoch 0: val_loss 1.3290377798184636, val_acc 0.8
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-0.0608,  0.0017, -0.0240,  ..., -0.0301, -0.0691, -0.0266],
        [-0.0006,  0.0483,  0.1138,  ...,  0.0013,  0.0877, -0.0216],
        [-0.1662, -0.0170,  0.2165,  ...,  0.2153, -0.0379,  0.0284],
        ...,
        [-0.1868, -0.0301, -0.0527,  ..., -0.0421, -0.1032, -0.0478],
        [ 0.0896,  0.1433, -0.0592,  ...,  0.0069, -0.0091, -0.1485],
        [ 0.1036, -0.1068,  0.0821,  ...,  0.1256,  0.2303,  0.1895]],
       device='cuda:0')), ('fcs.0.bias', tensor([-0.0683,  0.3579,  0.0947, -0.0404,  0.0428, -0.0647,  0.0383,  0.2840,
        -0.0920,  0.1175, -0.0860, -0.0125,  0.0612, -0.2015,  0.0096,  0.0436,
        -0.0484, -0.0937,  0.3273, -0.1088, -0.1563,  0.3320, -0.2140, -0.1527,
         0.1852,  0.0491, -0.0528, -0.2708, -0.1427, -0.0235,  0.0574,  0.0899,
        -0.0517, -0.1206, -0.0059, -0.0346, -0.0285,  0.3129, -0.0425, -0.1147,
         0.0546, -0.0915, -0.0827,  0.1635, -0.2101,  0.0647, -0.1170, -0.0375,
        -0.1593, -0.1713,  0.1907, -0.0592,  0.0178, -0.0503, -0.2047, -0.1099,
        -0.1068,  0.0685,  0.1076,  0.0645, -0.0682, -0.0947,  0.0414, -0.1218,
         0.0880,  0.1849, -0.1403, -0.1190,  0.0008, -0.3234, -0.2204, -0.1078,
        -0.0330, -0.2273,  0.1570,  0.3722,  0.0985, -0.1335, -0.0042, -0.0436,
         0.1604,  0.0248, -0.0106, -0.0839,  0.0646,  0.1732, -0.0339, -0.0246,
         0.0192,  0.0176, -0.2026,  0.0478, -0.2150, -0.0583,  0.0974, -0.0790,
        -0.0542, -0.0845, -0.0243,  0.0039, -0.0960, -0.0104, -0.2356,  0.0244,
        -0.0856, -0.1114, -0.0021, -0.1568,  0.1663,  0.0132,  0.0204,  0.0802,
         0.1502, -0.0511, -0.1508, -0.0779, -0.2564,  0.1969, -0.1529, -0.0391,
         0.1381,  0.2538, -0.0142, -0.0848, -0.1095, -0.0954, -0.1008,  0.2597],
       device='cuda:0')), ('fcs.1.weight', tensor([[-0.0004, -0.0443, -0.1070,  ...,  0.0008, -0.0345, -0.0435],
        [ 0.0506, -0.1100, -0.0622,  ...,  0.0403,  0.0395, -0.0355],
        [ 0.0003,  0.0142, -0.1550,  ...,  0.0317,  0.0183,  0.0465],
        ...,
        [ 0.0958,  0.1423,  0.1581,  ..., -0.0556, -0.0257,  0.1319],
        [-0.0079,  0.0394,  0.0281,  ..., -0.0065,  0.0401, -0.0086],
        [ 0.0007,  0.0078, -0.0018,  ..., -0.0003,  0.0002, -0.0177]],
       device='cuda:0')), ('fcs.1.bias', tensor([-0.1351, -0.0059, -0.1628, -0.0323,  0.1825, -0.0848, -0.0289, -0.1082,
        -0.1317, -0.1111,  0.0155, -0.1436, -0.0521, -0.0842,  0.0730, -0.0573,
         0.1393, -0.0732, -0.0255, -0.1412,  0.1109, -0.0339,  0.0803, -0.0379,
        -0.0657,  0.1430,  0.1397,  0.1438, -0.1643, -0.1078,  0.0304, -0.0476,
         0.0024,  0.0775, -0.0750, -0.0880,  0.1206, -0.0577,  0.0103, -0.1320,
         0.0036, -0.0082, -0.1210, -0.0762,  0.0744,  0.0526, -0.0817, -0.1397,
        -0.1070,  0.0367, -0.0657,  0.0243, -0.0376, -0.0193,  0.1400, -0.1471,
         0.0312, -0.0640,  0.0689, -0.1118, -0.0208,  0.0829,  0.0879, -0.0734],
       device='cuda:0')), ('fcs.2.weight', tensor([[ 0.0104,  0.0410, -0.0107, -0.0223,  0.0223, -0.0186, -0.0135,  0.0814,
          0.0532, -0.0135, -0.0371,  0.0061,  0.0039,  0.0534, -0.0218, -0.0026,
         -0.0344,  0.0617, -0.0762, -0.0089, -0.0496, -0.0445, -0.0272, -0.0032,
         -0.0006,  0.0180, -0.0361, -0.0031,  0.0384, -0.0023, -0.0348, -0.0130,
         -0.0288, -0.0160, -0.0410, -0.0304, -0.0017,  0.1454,  0.0122,  0.0102,
         -0.0341, -0.0426,  0.0030,  0.0570, -0.0113, -0.0408,  0.0179,  0.0212,
          0.0019,  0.0088,  0.0802,  0.0145,  0.0005,  0.0082,  0.1528, -0.0219,
          0.0041, -0.0044, -0.0062, -0.0406, -0.0071, -0.0546, -0.0003,  0.0111]],
       device='cuda:0'))])
end of epoch 1: val_loss 2.1357206390122885, val_acc 0.7
trigger times: 1
end of epoch 2: val_loss 0.7529606789350509, val_acc 0.6
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-0.0014, -0.0023, -0.0005,  ..., -0.0041, -0.0015, -0.0266],
        [-0.0120,  0.0548,  0.1216,  ...,  0.0179,  0.0679, -0.0139],
        [-0.1656, -0.0091,  0.1936,  ...,  0.2150, -0.0508,  0.0355],
        ...,
        [-0.0986, -0.0246, -0.0128,  ..., -0.0244, -0.0759, -0.0426],
        [ 0.0730,  0.1190, -0.0437,  ...,  0.0056, -0.0148, -0.0079],
        [ 0.1360, -0.0883,  0.0836,  ...,  0.1351,  0.2453,  0.1936]],
       device='cuda:0')), ('fcs.0.bias', tensor([-1.8350e-03,  3.2296e-01,  7.5438e-02, -4.3075e-02,  5.3093e-02,
        -6.3270e-02,  2.9619e-02,  2.4123e-01, -8.6342e-03,  1.5834e-01,
        -9.8140e-02, -1.4796e-02,  5.3691e-02, -1.6687e-01,  3.1641e-02,
         5.8095e-02, -9.4243e-04, -5.1089e-02,  2.8294e-01, -9.6677e-02,
        -1.5131e-01,  3.2115e-01, -1.2568e-01, -1.4462e-01,  1.6504e-01,
         4.6171e-02, -4.8385e-02, -2.5596e-01, -1.3110e-01, -3.5810e-02,
         6.2264e-02,  9.5597e-02, -4.6299e-02, -1.0866e-01, -1.3165e-01,
        -3.4442e-02,  3.9789e-05,  3.0943e-01, -3.9229e-02, -1.0359e-01,
        -8.1743e-02, -9.4756e-02, -7.8537e-02,  1.4170e-01, -1.2553e-01,
         5.6811e-02, -1.0683e-01, -3.5277e-02, -3.2126e-02, -1.6862e-01,
         1.8611e-01, -2.5601e-02,  1.0878e-02, -4.5893e-02, -1.9195e-01,
        -1.0672e-01, -8.3073e-02,  7.4231e-02,  7.9579e-02,  5.8825e-02,
        -5.0646e-02, -4.9072e-02, -2.5979e-03, -1.1850e-01,  8.1895e-02,
         1.0442e-01, -4.6924e-02, -1.1809e-01,  6.2416e-04, -2.9118e-01,
        -1.6377e-01, -8.4425e-03, -2.8214e-02, -2.1954e-01,  1.6052e-01,
         3.5989e-01,  8.5270e-02, -1.0895e-01, -3.8718e-02, -4.1724e-02,
         1.5288e-01,  6.4618e-02, -9.7127e-03, -1.2164e-01,  6.1301e-02,
         1.6367e-01, -3.7423e-02, -9.1704e-02,  3.9995e-03,  6.7863e-05,
        -1.9233e-01,  4.2423e-02, -2.0204e-01, -3.3550e-03,  8.3713e-02,
        -7.6417e-02, -5.2782e-02,  6.7010e-02, -3.3816e-02, -3.7511e-06,
        -6.7737e-02, -1.0160e-02, -2.3442e-01,  2.3298e-02, -7.2585e-02,
        -1.1188e-01,  1.8818e-01, -9.3321e-02,  1.6652e-01,  1.2337e-02,
         3.4700e-02,  8.1629e-02,  1.6957e-01, -4.6125e-02, -1.4646e-01,
        -7.5166e-02, -2.0400e-01,  1.8327e-01, -1.6973e-01, -6.8125e-02,
         1.2216e-01,  1.8971e-01, -1.1085e-06, -8.7712e-02, -1.0497e-01,
        -7.2497e-02, -9.5761e-02,  2.4236e-01], device='cuda:0')), ('fcs.1.weight', tensor([[ 3.5600e-06, -2.1463e-02, -3.3093e-02,  ...,  1.6121e-05,
         -3.9824e-03,  5.7318e-03],
        [ 8.1272e-05, -1.1509e-01, -6.0250e-02,  ...,  2.4583e-05,
          4.6701e-04, -4.1181e-02],
        [-1.8439e-05,  1.2041e-02, -1.1448e-01,  ...,  6.9113e-06,
          1.3995e-02,  4.3245e-02],
        ...,
        [ 1.7279e-03,  3.7732e-02,  1.5070e-01,  ..., -7.8621e-03,
         -2.1548e-03,  6.8251e-02],
        [ 3.8436e-04, -3.6964e-03,  2.9215e-02,  ...,  2.4971e-03,
          2.1028e-02, -2.8408e-02],
        [ 1.0092e-04, -4.5808e-02,  1.8701e-03,  ...,  2.7679e-04,
         -5.4340e-04,  7.3924e-02]], device='cuda:0')), ('fcs.1.bias', tensor([-0.1127, -0.0280, -0.1338, -0.0211,  0.1705, -0.0773, -0.0157, -0.0183,
        -0.0887, -0.1111, -0.0331, -0.1413, -0.0459, -0.1390, -0.0106, -0.0498,
         0.1242, -0.0660, -0.0243, -0.1086,  0.0576, -0.0295, -0.0263, -0.0315,
        -0.0612,  0.1054,  0.1102,  0.1344, -0.1635, -0.0651,  0.1788, -0.0420,
        -0.0093,  0.0732, -0.0779, -0.0839,  0.0714, -0.0486, -0.0101, -0.1325,
        -0.0722,  0.0754, -0.1157, -0.0807,  0.0705,  0.0391, -0.0785, -0.1357,
        -0.0979,  0.0278, -0.0643,  0.0231, -0.0258, -0.0195,  0.1401, -0.1248,
        -0.0374, -0.0598,  0.0665, -0.0789, -0.0142,  0.2038,  0.0614, -0.0939],
       device='cuda:0')), ('fcs.2.weight', tensor([[ 0.0035,  0.0420, -0.0113, -0.0161, -0.0110, -0.0156,  0.0084,  0.0119,
          0.0162, -0.0114, -0.0035,  0.0072,  0.0037,  0.0523,  0.0160, -0.0009,
          0.0003,  0.0617, -0.0653, -0.0055,  0.0103, -0.0413,  0.0038,  0.0085,
          0.0017,  0.0144,  0.0057,  0.0061,  0.0371,  0.0061,  0.0042, -0.0111,
          0.0141, -0.0272, -0.0462,  0.0320, -0.0337,  0.1158,  0.0084,  0.0105,
          0.0435, -0.0023,  0.0093,  0.0349, -0.0181,  0.0167,  0.0100,  0.0195,
          0.0059, -0.0141,  0.0811, -0.0098, -0.0035,  0.0056,  0.0412, -0.0231,
         -0.0058, -0.0016, -0.0176, -0.0328,  0.0020,  0.0319,  0.0053, -0.1439]],
       device='cuda:0'))])
end of epoch 3: val_loss 0.7806911485734872, val_acc 0.7
trigger times: 1
end of epoch 4: val_loss 1.899290224929473, val_acc 0.4
trigger times: 2
end of epoch 5: val_loss 1.4485598076131048, val_acc 0.6
trigger times: 3
end of epoch 6: val_loss 0.8060523824242296, val_acc 0.7
trigger times: 4
end of epoch 7: val_loss 10.917002105712891, val_acc 0.7
trigger times: 5
end of epoch 8: val_loss 8.176419842170072, val_acc 0.8
trigger times: 6
end of epoch 9: val_loss 2.2916921744465073, val_acc 0.8
trigger times: 7
end of epoch 10: val_loss 3.682649843202671, val_acc 0.7
trigger times: 8
end of epoch 11: val_loss 1.927856112884183, val_acc 0.4
trigger times: 9
end of epoch 12: val_loss 2.254896914958954, val_acc 0.7
trigger times: 10
Early stopping.
0 -5.469878548523411 -238.56539389647227
1 -3.2160052061080933 -226.82452825484978
2 -22.6634870757116 -226.2241731451399
3 9.599083848646842 -208.89755486387574
4 -1.5465128609212115 -196.9840755292238
5 9.836876208428293 -194.4017457710484
6 -5.748944394639693 -193.75394353311003
7 13.137371272896416 -173.38768743356906
8 8.11569299385883 -172.73844575529262
9 5.441905810846947 -172.5849598191294
10 21.856454270891845 -148.80630048130243
11 15.688514269888401 -146.54022994848935
12 18.175232954323292 -144.9163601843784
13 16.507785701425746 -144.5098799638122
14 18.623059682548046 -129.52710350510273
15 22.264398649334908 -119.6789138826375
16 19.06669546663761 -119.53338183357056
17 13.438480481505394 -115.00841352193844
18 23.399854630231857 -113.49466461352053
19 37.188679948449135 -107.45837168117659
20 24.645839489996433 -105.49937100040788
21 23.108937837183475 -101.9104943327425
22 28.35717160254717 -101.66294130080523
23 27.94401267170906 -98.89606860541423
24 26.730197682976723 -95.1909937931514
25 22.552700199186802 -93.31854913617367
26 31.815418422222137 -85.41926577166943
27 26.55975030362606 -83.18012153468804
28 29.717045955359936 -79.47665068598401
29 27.435293704271317 -77.34308621853297
30 30.63633245974779 -60.56041622227008
31 30.641853503882885 -58.68833689293549
32 28.946519032120705 -22.79021187897909
33 32.06536189839244 -19.65788926803626
34 37.12931577116251 -16.74518768263467
35 30.802408553659916 -13.719402302108403
36 33.82189705222845 4.235189873860978
37 28.785310693085194 5.0952806210809465
38 37.91026150435209 10.178796790507759
39 28.047828018665314 13.541055788508864
40 26.7355541549623 14.989710929193077
41 35.02209731191397 21.802029683432238
42 27.53636096417904 31.12027905920427
43 34.11059848591685 40.64550156746333
44 34.814208656549454 40.69898986216935
45 36.61887788772583 50.09032867204584
46 36.271162286400795 57.290535515424786
47 33.83284416794777 60.51441689036072
48 34.699391297996044 62.587858111632386
49 30.93880718946457 63.47489586756552
50 35.08455244451761 65.395531990224
51 36.93987438082695 68.71330703108626
52 36.93808324635029 69.48459209048262
53 38.12328455597162 72.16624272108386
54 28.542247638106346 74.2233202149037
55 23.631744172424078 79.16074531670823
56 32.101724937558174 80.25553156558418
57 27.343994788825512 87.50520028403979
58 33.465322107076645 90.28646231697512
59 30.8160752505064 90.72533900600311
60 33.869944766163826 91.52552635781885
61 31.336241506040096 91.95773979158345
62 27.358224883675575 92.99221310223136
63 31.938618376851082 94.14052712880752
64 32.5626270994544 94.28590507273401
65 28.93925630301237 95.24073532592021
66 30.704760417342186 96.09581961281374
67 34.51523004472256 96.50341248035636
68 28.87034545838833 97.45820290396632
69 30.17268531024456 97.90553231413178
70 31.838989287614822 98.27346635731779
71 30.81562526524067 98.35872828331676
72 31.058717355132103 98.9255090371917
73 34.99524750560522 99.09003071828721
74 36.95872173458338 99.89253842063019
75 35.298740677535534 100.07765055593329
76 39.33174277096987 101.35869827851857
77 30.642663419246674 103.56921378052652
78 34.947506844997406 103.74194540937737
79 38.6000387519598 104.00039883786899
80 30.26002947241068 104.36031383612816
81 34.59130459278822 104.79584301893571
82 34.43505645543337 105.40349710769756
83 35.76820773631334 105.60678192821229
84 30.970052361488342 106.26867976298877
85 36.829006657004356 106.37916921043517
86 34.27419939264655 106.67969423997131
87 34.311450339853764 106.81132709017433
88 35.28620085865259 107.05410485829283
89 34.45472730696201 107.44441498172971
90 37.19280110299587 107.68792314282867
91 31.39544077217579 107.72369032284489
92 36.875213876366615 108.58631070626225
93 32.41096764057875 108.79454915391223
94 38.057594016194344 109.15712102315346
95 38.26330231875181 109.71287331230647
96 33.17182959616184 110.48639228144049
97 34.326073959469795 111.4630258761226
98 41.311290100216866 112.59201367677376
99 34.33678964525461 113.4530990931055
100 41.405176639556885 114.85996346749971
101 35.90624471753836 115.04838323377467
102 42.83115877211094 115.5646624637931
103 33.532090082764626 115.77027450439896
104 36.462840400636196 116.29805012422126
105 38.47930843383074 116.38499266629886
106 37.53506975620985 116.4198907102986
107 39.626343086361885 117.08008835928221
108 39.73905435204506 117.29357601720739
109 39.144313998520374 118.29160885622866
110 42.135633021593094 119.01062500757773
111 36.25311924517155 120.85290512447664
112 43.44860592484474 120.8902150231427
113 41.951009787619114 121.40892075278066
114 41.45065066963434 122.30522808413322
115 44.70033589750528 129.13346806288703
116 45.020223528146744 129.67718524437547
117 43.47994714230299 129.79664443488912
118 42.360273241996765 130.61780866873775
119 49.863599479198456 131.40806576766226
train accuracy: 0.9222222222222223
validation accuracy: 0.7
test accuracy: 0.7746498599439776
