demo lengths 200
demos: (120, 200, 25)
demo_rewards: (120,)
[-238.5653939  -226.82452825 -226.22417315 -208.89755486 -196.98407553
 -194.40174577 -193.75394353 -173.38768743 -172.73844576 -172.58495982
 -148.80630048 -146.54022995 -144.91636018 -144.50987996 -129.52710351
 -119.67891388 -119.53338183 -115.00841352 -113.49466461 -107.45837168
 -105.499371   -101.91049433 -101.6629413   -98.89606861  -95.19099379
  -93.31854914  -85.41926577  -83.18012153  -79.47665069  -77.34308622
  -60.56041622  -58.68833689  -22.79021188  -19.65788927  -16.74518768
  -13.7194023     4.23518987    5.09528062   10.17879679   13.54105579
   14.98971093   21.80202968   31.12027906   40.64550157   40.69898986
   50.09032867   57.29053552   60.51441689   62.58785811   63.47489587
   65.39553199   68.71330703   69.48459209   72.16624272   74.22332021
   79.16074532   80.25553157   87.50520028   90.28646232   90.72533901
   91.52552636   91.95773979   92.9922131    94.14052713   94.28590507
   95.24073533   96.09581961   96.50341248   97.4582029    97.90553231
   98.27346636   98.35872828   98.92550904   99.09003072   99.89253842
  100.07765056  101.35869828  103.56921378  103.74194541  104.00039884
  104.36031384  104.79584302  105.40349711  105.60678193  106.26867976
  106.37916921  106.67969424  106.81132709  107.05410486  107.44441498
  107.68792314  107.72369032  108.58631071  108.79454915  109.15712102
  109.71287331  110.48639228  111.46302588  112.59201368  113.45309909
  114.85996347  115.04838323  115.56466246  115.7702745   116.29805012
  116.38499267  116.41989071  117.08008836  117.29357602  118.29160886
  119.01062501  120.85290512  120.89021502  121.40892075  122.30522808
  129.13346806  129.67718524  129.79664443  130.61780867  131.40806577]
maximum traj length 200
maximum traj length 200
num training_obs 450
num training_labels 450
num val_obs 50
num val_labels 50
num test_obs 7140
num test_labels 7140
ModuleList(
  (0): Linear(in_features=25, out_features=128, bias=True)
  (1): Linear(in_features=128, out_features=64, bias=True)
  (2): Linear(in_features=64, out_features=1, bias=False)
)
Total number of parameters: 11648
Number of trainable paramters: 11648
device: cuda:0
end of epoch 0: val_loss 0.2902957264154975, val_acc 0.84
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 0.1334,  0.0821,  0.0087,  ...,  0.0576,  0.2442, -0.0521],
        [ 0.2346,  0.1995, -0.0449,  ...,  0.0858,  0.0435,  0.2170],
        [ 0.1397,  0.0889,  0.1063,  ...,  0.0359,  0.1464,  0.2406],
        ...,
        [ 0.2630,  0.0499, -0.0809,  ...,  0.4544, -0.1080, -0.0012],
        [-0.0058,  0.0407, -0.1220,  ...,  0.1315, -0.1268,  0.0117],
        [-0.1395, -0.0246,  0.0741,  ..., -0.1357,  0.0104, -0.0954]],
       device='cuda:0')), ('fcs.0.bias', tensor([ 9.2324e-03, -3.3066e-02, -7.5442e-02, -3.3237e-03,  1.2146e-01,
        -5.0154e-02, -8.4010e-02, -1.4695e-01,  1.6228e-01,  3.5023e-02,
         3.4028e-01, -5.1709e-02, -1.1483e-01, -2.8969e-02, -5.0016e-02,
        -8.2652e-02, -7.5628e-02,  1.5076e-01,  4.1653e-02,  2.0464e-01,
        -7.5995e-02,  2.4493e-01,  5.2101e-02, -7.5300e-02,  1.4620e-01,
        -9.1565e-02,  6.5322e-03, -3.6928e-02,  3.8408e-01,  1.2604e-01,
        -5.7356e-02, -6.0181e-02,  6.3051e-02, -8.5955e-02, -2.2226e-02,
        -9.8911e-02,  6.1017e-02,  2.9164e-02, -1.5275e-01, -7.7606e-02,
        -1.9021e-03, -8.5522e-02, -2.2569e-04,  8.5916e-03,  1.6266e-01,
        -1.5692e-01,  3.4897e-03,  3.2398e-02, -3.4592e-02, -2.7590e-02,
         1.7651e-01,  1.0978e-01, -9.4844e-02, -1.9102e-01, -4.9413e-02,
        -1.1492e-01, -2.5076e-03, -1.4504e-01, -1.4549e-01, -3.2975e-02,
         6.9889e-03, -1.1415e-01, -1.0891e-01, -1.1070e-01,  4.6598e-02,
        -1.6310e-03, -1.9848e-01, -7.6468e-02,  8.1591e-02, -6.7419e-02,
        -4.1595e-02, -4.3856e-03, -3.9538e-02, -8.8380e-02,  1.6223e-01,
        -1.3667e-01,  1.5351e-01,  6.6684e-02, -1.9525e-01, -9.0770e-02,
         4.7992e-02,  7.2940e-02, -1.2943e-01,  1.5811e-01, -1.7451e-01,
         2.8377e-04, -5.5135e-02, -4.8080e-02, -4.5932e-02, -1.7246e-02,
        -1.7369e-03,  1.7177e-01, -8.1067e-02, -1.1348e-02,  1.1884e-01,
         5.5694e-02, -2.4043e-01, -1.1938e-02, -1.5902e-01,  2.5366e-01,
         1.4958e-01, -7.0348e-03, -1.6335e-01, -1.0226e-01, -1.1101e-01,
         4.9132e-02, -1.1195e-01, -1.0655e-02,  9.8288e-02,  2.5241e-01,
         4.7983e-02,  8.5403e-02,  3.0417e-02, -7.1549e-03, -1.0241e-02,
        -1.4420e-01, -1.0646e-01, -7.0737e-02,  2.1146e-04, -3.2802e-02,
        -3.5581e-02, -1.9981e-01,  5.3403e-02,  1.1406e-01, -2.2083e-02,
        -2.1298e-02, -4.7246e-02,  1.9426e-02], device='cuda:0')), ('fcs.1.weight', tensor([[-0.1744,  0.0080,  0.0598,  ...,  0.0052, -0.0428,  0.0090],
        [ 0.0772, -0.0083, -0.0049,  ..., -0.2771, -0.0326,  0.1287],
        [-0.0308, -0.0256, -0.1239,  ..., -0.0045,  0.0602,  0.2182],
        ...,
        [ 0.0678, -0.1333, -0.0476,  ...,  0.0011,  0.0510,  0.0166],
        [ 0.0009, -0.0100, -0.1021,  ..., -0.0003,  0.1022,  0.0797],
        [-0.0347, -0.0218, -0.0004,  ..., -0.0048,  0.0003, -0.0315]],
       device='cuda:0')), ('fcs.1.bias', tensor([-0.0403,  0.0661,  0.0520, -0.0658, -0.0310, -0.0938, -0.0272, -0.0850,
        -0.0679, -0.0312,  0.1222, -0.0008,  0.1502, -0.0335,  0.0174,  0.0146,
        -0.1692,  0.0086, -0.1164, -0.0295, -0.0332, -0.0525, -0.0651, -0.0296,
        -0.0433, -0.1180,  0.2141, -0.0795, -0.0148, -0.0473, -0.0017,  0.1129,
        -0.0769, -0.0945, -0.0358,  0.0058, -0.1525, -0.0324, -0.0324, -0.0489,
        -0.0561, -0.0933,  0.0074,  0.0178, -0.0589, -0.0097, -0.0692, -0.0947,
        -0.0210, -0.1488, -0.0339, -0.0038, -0.0408, -0.1094, -0.0570, -0.0420,
        -0.0108, -0.0516, -0.0099, -0.1568,  0.1052,  0.0046,  0.0703, -0.0349],
       device='cuda:0')), ('fcs.2.weight', tensor([[ 1.9997e-02, -9.8314e-03,  7.6450e-03, -6.4161e-02,  2.9377e-02,
         -4.7000e-02,  2.2423e-03, -5.7649e-02,  9.4867e-04,  1.6829e-02,
          5.0298e-02, -6.4496e-02, -1.1077e-03,  2.6288e-02,  2.4173e-02,
          1.1730e-02,  3.5063e-03, -4.9915e-03,  3.8267e-02,  1.3854e-02,
          1.9046e-02,  4.6123e-04,  1.1216e-02, -6.9070e-02,  5.6521e-05,
         -2.1731e-02,  2.6392e-03,  3.1502e-02,  4.7529e-02, -7.1158e-02,
         -2.3087e-02,  1.0145e-02,  4.5504e-02, -3.2403e-03,  1.6140e-02,
         -1.0607e-02,  1.5271e-02, -5.8673e-04,  9.6828e-02, -2.3391e-02,
          2.8150e-02,  3.2755e-03,  5.2258e-03, -8.8449e-03,  9.7018e-03,
          5.6009e-03,  6.6512e-03, -6.9082e-02,  7.5911e-04, -2.6008e-02,
          3.0456e-03, -5.9932e-02,  3.4873e-03,  2.5082e-02, -2.4929e-02,
          1.9832e-02, -1.1941e-02,  1.3025e-02,  1.3809e-03,  3.8878e-02,
         -1.4941e-03, -1.2436e-03, -2.4942e-03,  5.6454e-03]], device='cuda:0'))])
end of epoch 1: val_loss 3.7276425568721585, val_acc 0.74
trigger times: 1
end of epoch 2: val_loss 0.2509846916194607, val_acc 0.86
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 0.1559,  0.1296,  0.0621,  ...,  0.0593,  0.2694,  0.0017],
        [ 0.1541,  0.1869,  0.0230,  ...,  0.1345,  0.2234,  0.0738],
        [ 0.0285,  0.1069,  0.0220,  ...,  0.1037,  0.0365,  0.1265],
        ...,
        [-0.1816, -0.1123, -0.1017,  ...,  0.0097, -0.3698, -0.0782],
        [-0.0026,  0.0321, -0.0425,  ...,  0.0954, -0.0657,  0.0030],
        [-0.1619,  0.0345,  0.0195,  ..., -0.1175, -0.0697, -0.0355]],
       device='cuda:0')), ('fcs.0.bias', tensor([-1.6308e-02,  6.2960e-02, -1.6408e-01,  1.1043e-07,  7.3140e-02,
         1.0731e-01, -1.0739e-01, -3.3450e-02, -6.9782e-02,  2.2695e-02,
         2.1290e-03,  1.2774e-01,  1.8052e-01,  2.3017e-02, -3.3834e-02,
        -6.9425e-02, -9.5984e-02,  2.6442e-02,  1.0806e-02,  3.4076e-01,
        -2.9185e-02,  2.8740e-02,  3.4249e-02, -2.5922e-02,  1.4304e-01,
        -4.2733e-02, -1.4821e-03, -4.7554e-02,  9.4554e-03, -1.1392e-01,
        -2.8340e-02, -2.5548e-02,  2.0981e-01, -2.9360e-02, -1.1217e-01,
        -4.9602e-02,  1.8006e-01,  1.9344e-02, -9.7236e-03, -1.4982e-03,
        -1.3454e-05, -7.3516e-02, -2.2364e-02,  2.6068e-03,  1.0599e-01,
        -2.3985e-02, -1.6292e-01,  9.2839e-03, -2.7115e-05, -1.4456e-02,
        -2.4854e-02, -7.7734e-02, -7.2250e-02, -1.4665e-01, -6.1373e-03,
        -4.8085e-02, -1.8922e-01, -4.7112e-02, -6.0220e-02, -2.6078e-04,
        -9.4169e-03, -1.1385e-01, -1.9099e-02, -5.5109e-02,  7.7335e-03,
        -7.9059e-04, -9.8203e-02, -4.4107e-02, -8.8618e-02, -3.3663e-03,
        -1.9086e-01, -1.0147e-01, -3.1487e-02, -3.0836e-02,  7.7842e-02,
        -1.1082e-01, -2.7729e-03, -1.1001e-01, -9.7985e-02, -3.6261e-02,
         8.7324e-02,  3.1111e-02, -6.6693e-02,  2.3975e-01, -1.3257e-01,
         9.4497e-02, -2.0886e-02, -2.1139e-01, -5.7963e-04, -1.3209e-01,
        -8.9792e-04,  1.3503e-02, -4.2697e-02, -8.3668e-03,  9.2096e-02,
        -1.0965e-01, -1.5628e-01, -4.1103e-03, -9.6052e-02,  7.2376e-02,
         6.6649e-02, -2.4861e-03, -8.6575e-02, -7.3236e-02, -5.5070e-02,
         8.1622e-03, -7.3759e-02, -5.7455e-02,  2.7937e-03, -8.3952e-02,
         1.9732e-01,  3.9137e-02, -1.2032e-02, -2.5307e-03, -1.8350e-01,
        -4.1868e-02, -6.1524e-02, -3.0885e-02, -2.4567e-01,  2.1828e-01,
        -2.2451e-01, -6.6013e-02,  2.0595e-02,  7.0503e-02, -2.5973e-05,
        -2.7759e-01, -2.3911e-02, -5.5199e-02], device='cuda:0')), ('fcs.1.weight', tensor([[-0.0877, -0.0009,  0.0306,  ..., -0.0004, -0.0055,  0.0042],
        [-0.0275,  0.0273, -0.0128,  ..., -0.0980,  0.0004, -0.0280],
        [-0.0267, -0.0142, -0.0543,  ..., -0.0002,  0.0116,  0.0823],
        ...,
        [ 0.0398, -0.0624, -0.0221,  ..., -0.0002,  0.0145,  0.0062],
        [-0.0230,  0.1120, -0.1020,  ...,  0.1093,  0.0401,  0.0534],
        [-0.0120,  0.0018, -0.0002,  ...,  0.0002, -0.0004, -0.0012]],
       device='cuda:0')), ('fcs.1.bias', tensor([-1.7322e-02,  1.1188e-01,  2.6605e-03, -1.6362e-01, -1.3412e-02,
        -1.8499e-03, -6.3105e-03, -1.1802e-01, -2.5119e-02, -4.6082e-03,
         2.5897e-01,  3.2295e-02, -7.5205e-02, -4.3548e-02,  2.8024e-03,
        -4.0847e-02, -3.1630e-04,  1.1221e-01, -4.1454e-02, -2.4457e-02,
        -2.6920e-02, -4.0646e-03, -1.2670e-02, -2.6087e-02, -8.1504e-03,
        -3.7227e-02, -5.7883e-03, -5.2328e-02,  8.4829e-02, -2.7029e-02,
        -1.3349e-03,  1.6526e-01, -6.0930e-03, -1.4070e-02, -2.7426e-02,
         1.0028e-03, -6.2237e-02, -1.9537e-01, -4.8537e-02, -5.1663e-02,
         2.3287e-02, -9.6526e-03, -2.1315e-03,  3.7837e-03, -3.5492e-02,
         1.2247e-01, -4.9133e-02,  2.8231e-02, -1.5134e-01, -1.5299e-02,
         7.9043e-03, -1.3173e-02, -1.3964e-01, -2.3707e-05, -5.8208e-03,
        -3.0564e-02,  3.8009e-02, -1.3178e-02, -7.9538e-03, -1.4979e-01,
         9.6898e-03,  1.0245e-03,  3.9435e-02, -2.7440e-02], device='cuda:0')), ('fcs.2.weight', tensor([[ 0.0131,  0.0006,  0.0068,  0.0004,  0.0042, -0.0376, -0.0007,  0.0345,
         -0.0008, -0.0003,  0.0547, -0.0440,  0.0180,  0.0079, -0.0137, -0.0318,
         -0.0026, -0.0033,  0.0054,  0.0123,  0.0037,  0.0035, -0.0012, -0.0220,
         -0.0037, -0.0160, -0.0465,  0.0124,  0.0225, -0.0621, -0.0021,  0.0273,
          0.0011, -0.0008,  0.0011, -0.0077,  0.0082, -0.0272, -0.0040, -0.0956,
         -0.0191,  0.0007,  0.0013, -0.0056,  0.0015,  0.0074,  0.0026,  0.0282,
         -0.0483, -0.0227, -0.0122,  0.0469, -0.0518, -0.0003, -0.0172,  0.0233,
         -0.0344,  0.0006, -0.0055,  0.0291,  0.0184, -0.0033,  0.0166, -0.0309]],
       device='cuda:0'))])
end of epoch 3: val_loss 0.2819524866665188, val_acc 0.86
trigger times: 1
end of epoch 4: val_loss 0.35156949371797963, val_acc 0.84
trigger times: 2
end of epoch 5: val_loss 65.8657373046875, val_acc 0.72
trigger times: 3
end of epoch 6: val_loss 0.7501022228172686, val_acc 0.78
trigger times: 4
end of epoch 7: val_loss 0.4640788309337698, val_acc 0.82
trigger times: 5
end of epoch 8: val_loss 0.5921965064171935, val_acc 0.84
trigger times: 6
end of epoch 9: val_loss 0.20131277841135842, val_acc 0.92
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-5.7489e-02,  1.1521e-01,  1.9158e-01,  ..., -2.3108e-01,
         -1.2167e-02,  7.6329e-02],
        [ 6.9392e-01,  3.2034e-01,  1.0598e-01,  ..., -1.2979e-01,
          2.2179e-01,  5.8457e-01],
        [-8.3283e-02, -4.3696e-02, -7.5377e-03,  ...,  4.2710e-02,
         -7.8005e-02,  1.5201e-01],
        ...,
        [ 4.2506e-01, -3.2505e-02,  3.2091e-01,  ...,  2.0686e-01,
          7.8891e-01, -4.1979e-01],
        [-1.0237e-05,  1.3335e-04, -2.1454e-06,  ...,  7.2090e-04,
          3.6750e-06, -1.3260e-03],
        [-4.2944e-04,  5.8284e-03,  3.1687e-05,  ..., -1.1684e-03,
         -1.7777e-05, -1.2822e-03]], device='cuda:0')), ('fcs.0.bias', tensor([-1.1902e-01,  3.9379e-01, -1.4479e-01, -4.5080e-01, -1.5775e-03,
         6.2359e-02,  5.7851e-01, -6.0190e-06, -1.6513e-03, -1.3697e-03,
        -5.0354e-04, -2.6889e-03, -2.8301e-02, -2.1583e-02, -1.9270e-02,
         1.3900e-02, -3.4687e-03,  2.4057e-01,  2.5416e-06,  2.0826e-01,
        -1.5472e-01, -4.9152e-07,  1.0904e-04, -2.3954e-01, -1.6358e-01,
        -1.0028e-01, -3.7168e-04,  1.0706e-06, -8.5485e-03, -3.1007e-05,
        -2.3098e-04, -1.8317e-01, -5.4545e-03,  1.7615e-01, -2.9880e-05,
        -1.4037e-04, -6.8395e-02, -1.7843e-03,  6.6384e-01,  5.7535e-01,
        -1.2093e-02, -7.3412e-04, -1.6572e-05,  3.8111e-01, -5.4062e-04,
         5.0581e-01, -7.3874e-03, -1.0400e-03,  1.1961e-01, -1.3052e-04,
        -3.7425e-05, -2.6302e-01, -3.5040e-03, -5.2506e-05, -8.6064e-02,
        -8.1221e-02, -2.1504e-01,  7.9934e-01, -3.4657e-01,  6.1576e-02,
        -2.0287e-05, -6.2842e-03,  4.4097e-01,  2.6934e-02, -3.3444e-02,
        -2.7521e-02, -7.7047e-03, -1.8919e-01, -1.3749e-05, -1.4290e-01,
        -6.5433e-03, -7.0545e-02, -3.7176e-03,  6.8184e-02, -1.1168e-02,
        -3.0881e-03, -2.0163e-01, -1.0800e-04, -3.7567e-05, -4.3056e-05,
         9.6134e-02, -6.4396e-06, -3.3058e-06, -3.4771e-01,  1.9349e-02,
        -2.1999e-02, -3.3541e-06, -1.5066e-05,  2.2857e-01, -1.2226e-02,
        -4.0707e-07, -4.4932e-06, -1.5704e-05,  3.3296e-01,  5.8005e-01,
        -1.2219e-03,  2.3011e-02,  1.0672e-01, -3.2980e-05, -7.5906e-02,
        -1.4857e-01, -1.2710e-03, -4.8633e-02, -5.3370e-04,  2.1118e-01,
        -1.3714e-02, -1.0665e-02, -2.5217e-06, -3.2496e-02, -2.0277e-02,
        -5.4817e-01, -8.3627e-05, -1.3053e-01, -6.9148e-03,  2.9239e-01,
        -1.3424e-01, -4.8208e-04,  4.4113e-01,  7.0934e-01, -1.5603e-01,
         6.3387e-01, -8.2480e-02,  8.2260e-08,  2.2458e-04, -1.3928e-02,
         5.8576e-01,  7.3850e-06, -1.6683e-04], device='cuda:0')), ('fcs.1.weight', tensor([[-1.8791e-03, -6.3375e-03,  5.5451e-05,  ..., -5.0376e-04,
         -5.9349e-08,  6.1595e-07],
        [-8.8872e-03, -1.1272e-02, -1.0261e-03,  ..., -4.6329e-03,
         -2.0200e-07, -1.5813e-04],
        [ 2.5080e-01,  6.0986e-02, -5.9105e-03,  ...,  1.7518e-03,
          4.3639e-06,  5.2048e-06],
        ...,
        [-7.0212e-02,  7.5737e-02,  5.8886e-05,  ..., -9.7523e-05,
         -6.2143e-08,  1.8759e-06],
        [-5.4087e-02, -9.5862e-02, -3.8468e-03,  ..., -9.2648e-02,
          1.9528e-06,  5.1587e-04],
        [-1.2649e-03, -3.7077e-03,  4.6855e-05,  ..., -1.9677e-04,
         -3.9679e-07, -1.4912e-08]], device='cuda:0')), ('fcs.1.bias', tensor([ 2.2962e-03,  2.0073e-05,  1.7471e-02,  1.0839e-01,  1.8059e-01,
         3.9126e-08,  1.2890e-04, -3.4090e-02,  2.1839e-02, -9.4287e-03,
         2.2576e-01, -8.7184e-02, -1.0229e-02, -2.6372e-02,  1.3755e-01,
        -8.9209e-02, -2.3939e-10, -1.1029e-03, -7.1590e-03,  1.9153e-01,
        -4.1127e-02, -2.8799e-03, -9.1382e-03, -2.1607e-02, -4.3714e-02,
        -4.3763e-03,  2.6496e-02, -9.8098e-02,  2.3771e-01, -2.0337e-02,
         1.2862e-02, -6.4485e-02, -1.3312e-04, -1.4310e-01, -7.5055e-03,
        -2.1078e-01, -5.4223e-07, -4.5030e-03, -7.4074e-02, -5.7458e-02,
        -3.9327e-02, -3.1178e-03, -2.0144e-02, -1.1085e-03,  1.0469e-01,
         6.6584e-04, -6.0683e-02, -1.4518e-01, -5.7758e-03, -1.4337e-09,
        -7.4060e-04,  8.2751e-03, -1.2704e-01,  9.9168e-02,  1.3305e-01,
        -6.1609e-04,  1.4591e-02, -1.0265e-01, -4.1847e-03,  1.4931e-01,
        -5.3473e-05,  1.1361e-02,  2.4508e-02, -2.0851e-05], device='cuda:0')), ('fcs.2.weight', tensor([[-4.4723e-04, -5.2733e-04, -6.3958e-03, -1.8161e-02,  3.9731e-02,
         -1.3103e-03,  4.3008e-02,  7.1061e-02, -1.4177e-02,  1.4405e-01,
          3.9457e-03,  1.2485e-02,  3.3157e-03, -8.3313e-02,  8.4597e-04,
         -2.7899e-02, -4.9868e-05,  1.4764e-02, -2.0509e-01, -2.2441e-02,
          1.5172e-02, -4.9799e-02,  1.4362e-02, -1.4794e-01, -2.2264e-02,
          3.7532e-02, -2.6549e-02,  1.2562e-01, -5.9411e-03, -5.7368e-03,
         -3.6711e-02, -2.6561e-02, -4.1972e-04,  3.3242e-01, -2.1270e-04,
         -1.2823e-01,  2.6431e-05, -5.4259e-04, -5.4861e-03,  1.0983e-03,
          5.6184e-02, -8.0740e-04,  7.5404e-02, -2.3177e-03, -7.8051e-02,
          3.3982e-02, -3.4255e-03,  1.1830e-02,  4.8920e-02, -6.5316e-04,
         -5.0295e-03,  1.4626e-01,  7.8507e-02,  1.2686e-01, -6.3193e-02,
         -2.0113e-03,  1.1247e-02,  8.2562e-02, -4.8540e-04, -4.8824e-03,
         -8.2417e-04,  2.8677e-03,  1.1267e-01, -8.3948e-05]], device='cuda:0'))])
end of epoch 10: val_loss 0.39294526372295635, val_acc 0.8
trigger times: 1
end of epoch 11: val_loss 0.6705136364441628, val_acc 0.82
trigger times: 2
end of epoch 12: val_loss 0.6774108426394636, val_acc 0.82
trigger times: 3
end of epoch 13: val_loss 0.3287986055128509, val_acc 0.92
trigger times: 4
end of epoch 14: val_loss 0.24291504462308097, val_acc 0.88
trigger times: 5
end of epoch 15: val_loss 0.32487431675366424, val_acc 0.78
trigger times: 6
end of epoch 16: val_loss 0.3388318577350583, val_acc 0.88
trigger times: 7
end of epoch 17: val_loss 3.746656405385562, val_acc 0.78
trigger times: 8
end of epoch 18: val_loss 0.4029434819240123, val_acc 0.84
trigger times: 9
end of epoch 19: val_loss 0.3456959917330096, val_acc 0.78
trigger times: 10
Early stopping.
0 -3.4319305066019297 -238.56539389647227
1 -2.9419638477265835 -226.82452825484978
2 -2.6166329085826874 -226.2241731451399
3 -1.942937832325697 -208.89755486387574
4 -1.767365787178278 -196.9840755292238
5 -0.8052068036049604 -194.4017457710484
6 -2.142956420779228 -193.75394353311003
7 0.33531635627150536 -173.38768743356906
8 -0.4144353400915861 -172.73844575529262
9 -0.7341092266142368 -172.5849598191294
10 0.4562745653092861 -148.80630048130243
11 1.3715670742094517 -146.54022994848935
12 0.4087298661470413 -144.9163601843784
13 1.574864611029625 -144.5098799638122
14 1.351137027144432 -129.52710350510273
15 2.3241207376122475 -119.6789138826375
16 1.3192787617444992 -119.53338183357056
17 0.5921451970934868 -115.00841352193844
18 2.42319830134511 -113.49466461352053
19 4.10812583565712 -107.45837168117659
20 2.1101250238716602 -105.49937100040788
21 2.1918720677495003 -101.9104943327425
22 2.4910346530377865 -101.66294130080523
23 3.710507605224848 -98.89606860541423
24 3.2519805431365967 -95.1909937931514
25 1.9654108323156834 -93.31854913617367
26 3.8423975855112076 -85.41926577166943
27 3.804838325828314 -83.18012153468804
28 2.438117265701294 -79.47665068598401
29 2.374126948416233 -77.34308621853297
30 4.06328622251749 -60.56041622227008
31 4.548130687326193 -58.68833689293549
32 2.911807131022215 -22.79021187897909
33 4.852332707494497 -19.65788926803626
34 4.9808153957128525 -16.74518768263467
35 3.6387966722249985 -13.719402302108403
36 4.300893474370241 4.235189873860978
37 3.008666381239891 5.0952806210809465
38 4.540962383151054 10.178796790507759
39 3.072947956621647 13.541055788508864
40 3.4714033529162407 14.989710929193077
41 4.2655930519104 21.802029683432238
42 3.066485285758972 31.12027905920427
43 4.264672476798296 40.64550156746333
44 5.200754877179861 40.69898986216935
45 4.3955493830144405 50.09032867204584
46 4.806106027215719 57.290535515424786
47 2.9710509702563286 60.51441689036072
48 4.001408640295267 62.587858111632386
49 3.4603871926665306 63.47489586756552
50 3.9232590533792973 65.395531990224
51 4.3379229567945 68.71330703108626
52 3.5353307276964188 69.48459209048262
53 4.291090589016676 72.16624272108386
54 3.459817659109831 74.2233202149037
55 2.806367974728346 79.16074531670823
56 3.5104191973805428 80.25553156558418
57 3.255556497722864 87.50520028403979
58 3.9245001077651978 90.28646231697512
59 3.871667880564928 90.72533900600311
60 4.489539783447981 91.52552635781885
61 3.531407907605171 91.95773979158345
62 2.4583896584808826 92.99221310223136
63 3.621616382151842 94.14052712880752
64 4.64746992662549 94.28590507273401
65 3.242689624428749 95.24073532592021
66 4.593487948179245 96.09581961281374
67 4.652507349848747 96.50341248035636
68 4.129939191043377 97.45820290396632
69 4.271168801933527 97.90553231413178
70 3.3409293331205845 98.27346635731779
71 3.255459997802973 98.35872828331676
72 3.7799848951399326 98.9255090371917
73 4.1764100305736065 99.09003071828721
74 4.544539403170347 99.89253842063019
75 4.664603345096111 100.07765055593329
76 4.684914145618677 101.35869827851857
77 3.3997001349925995 103.56921378052652
78 4.054068718105555 103.74194540937737
79 4.34202292189002 104.00039883786899
80 3.645075459033251 104.36031383612816
81 3.3905340172350407 104.79584301893571
82 4.433597769588232 105.40349710769756
83 5.058882005512714 105.60678192821229
84 3.6768824718892574 106.26867976298877
85 3.7356327027082443 106.37916921043517
86 4.469358738511801 106.67969423997131
87 4.3913462944328785 106.81132709017433
88 4.869092490524054 107.05410485829283
89 4.842156447470188 107.44441498172971
90 4.247458379715681 107.68792314282867
91 4.120403461158276 107.72369032284489
92 4.119292479008436 108.58631070626225
93 4.725830968469381 108.79454915391223
94 4.86284201964736 109.15712102315346
95 5.8628447242081165 109.71287331230647
96 4.291393104940653 110.48639228144049
97 5.053126636892557 111.4630258761226
98 4.682175949215889 112.59201367677376
99 4.268627818673849 113.4530990931055
100 5.067202031612396 114.85996346749971
101 4.298568908125162 115.04838323377467
102 5.770922407507896 115.5646624637931
103 3.8359821438789368 115.77027450439896
104 4.079340033233166 116.29805012422126
105 6.136834796518087 116.38499266629886
106 4.846246685832739 116.4198907102986
107 4.953469961881638 117.08008835928221
108 4.908967532217503 117.29357601720739
109 4.690998483449221 118.29160885622866
110 5.647475570440292 119.01062500757773
111 5.512176007032394 120.85290512447664
112 6.0423194617033005 120.8902150231427
113 5.676915027201176 121.40892075278066
114 5.0136075131595135 122.30522808413322
115 6.4128482937812805 129.13346806288703
116 7.1931105479598045 129.67718524437547
117 5.797526154667139 129.79664443488912
118 5.427506420761347 130.61780866873775
119 7.628969464451075 131.40806576766226
train accuracy: 0.8088888888888889
validation accuracy: 0.78
test accuracy: 0.7476190476190476
