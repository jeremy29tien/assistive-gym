demos: (480, 200, 19)
demo_rewards: (480,)
maximum traj length 200
maximum traj length 200
num train_obs 52326
num train_labels 52326
num val_obs 1128
num val_labels 1128
ModuleList(
  (0): Linear(in_features=19, out_features=256, bias=True)
  (1): Linear(in_features=256, out_features=256, bias=True)
  (2): Linear(in_features=256, out_features=256, bias=True)
  (3): Linear(in_features=256, out_features=1, bias=False)
)
Training reward model from scratch...
Total number of parameters: 136960
Number of trainable paramters: 136960
device: cuda:1
end of epoch 0: val_loss 0.07098571308372882, val_acc 0.9725177304964538
trigger times: 0
saving model weights...
end of epoch 1: val_loss 0.05844147303226454, val_acc 0.9787234042553191
trigger times: 0
saving model weights...
end of epoch 2: val_loss 0.044923333109027165, val_acc 0.9813829787234043
trigger times: 0
saving model weights...
end of epoch 3: val_loss 0.04689805983833549, val_acc 0.9840425531914894
trigger times: 1
end of epoch 4: val_loss 0.04635581990598083, val_acc 0.9822695035460993
trigger times: 2
end of epoch 5: val_loss 0.03532940649533512, val_acc 0.9875886524822695
trigger times: 0
saving model weights...
end of epoch 6: val_loss 0.040279341830541965, val_acc 0.9831560283687943
trigger times: 1
end of epoch 7: val_loss 0.05483560033881405, val_acc 0.9813829787234043
trigger times: 2
end of epoch 8: val_loss 0.03720936598387638, val_acc 0.9849290780141844
trigger times: 3
end of epoch 9: val_loss 0.043935481095802476, val_acc 0.9831560283687943
trigger times: 4
end of epoch 10: val_loss 0.039668462916050126, val_acc 0.9867021276595744
trigger times: 5
end of epoch 11: val_loss 0.04216813891998847, val_acc 0.9831560283687943
trigger times: 6
end of epoch 12: val_loss 0.040095091387807924, val_acc 0.9822695035460993
trigger times: 7
end of epoch 13: val_loss 0.032416334811919474, val_acc 0.9875886524822695
trigger times: 0
saving model weights...
end of epoch 14: val_loss 0.034838594685632246, val_acc 0.9858156028368794
trigger times: 1
end of epoch 15: val_loss 0.034456559646862235, val_acc 0.9858156028368794
trigger times: 2
end of epoch 16: val_loss 0.05096815403242401, val_acc 0.9796099290780141
trigger times: 3
end of epoch 17: val_loss 0.027059387867692047, val_acc 0.9893617021276596
trigger times: 0
saving model weights...
end of epoch 18: val_loss 0.03781896880380713, val_acc 0.9867021276595744
trigger times: 1
end of epoch 19: val_loss 0.03158630018349584, val_acc 0.9875886524822695
trigger times: 2
end of epoch 20: val_loss 0.031711924012764264, val_acc 0.9875886524822695
trigger times: 3
end of epoch 21: val_loss 0.028685347115409227, val_acc 0.9884751773049646
trigger times: 4
end of epoch 22: val_loss 0.033134327387584296, val_acc 0.9867021276595744
trigger times: 5
end of epoch 23: val_loss 0.035416361620176647, val_acc 0.9867021276595744
trigger times: 6
end of epoch 24: val_loss 0.029565132575599003, val_acc 0.9884751773049646
trigger times: 7
end of epoch 25: val_loss 0.029488697171907635, val_acc 0.9893617021276596
trigger times: 8
end of epoch 26: val_loss 0.02525253306630305, val_acc 0.9884751773049646
trigger times: 0
saving model weights...
end of epoch 27: val_loss 0.024636633089167814, val_acc 0.9902482269503546
trigger times: 0
saving model weights...
end of epoch 28: val_loss 0.026124644994627095, val_acc 0.9911347517730497
trigger times: 1
end of epoch 29: val_loss 0.02666839832230667, val_acc 0.9893617021276596
trigger times: 2
end of epoch 30: val_loss 0.028767838753655132, val_acc 0.9893617021276596
trigger times: 3
end of epoch 31: val_loss 0.02611200815723885, val_acc 0.9884751773049646
trigger times: 4
end of epoch 32: val_loss 0.03525364353793735, val_acc 0.9884751773049646
trigger times: 5
end of epoch 33: val_loss 0.027864570248636644, val_acc 0.9875886524822695
trigger times: 6
end of epoch 34: val_loss 0.02694636345186719, val_acc 0.9893617021276596
trigger times: 7
end of epoch 35: val_loss 0.02358798411875309, val_acc 0.9902482269503546
trigger times: 0
saving model weights...
end of epoch 36: val_loss 0.020710381250822404, val_acc 0.9929078014184397
trigger times: 0
saving model weights...
end of epoch 37: val_loss 0.024653782095090424, val_acc 0.9902482269503546
trigger times: 1
end of epoch 38: val_loss 0.02653748547465651, val_acc 0.9911347517730497
trigger times: 2
end of epoch 39: val_loss 0.030332033251046622, val_acc 0.9875886524822695
trigger times: 3
end of epoch 40: val_loss 0.02748782419110738, val_acc 0.9884751773049646
trigger times: 4
end of epoch 41: val_loss 0.021212635296251676, val_acc 0.9920212765957447
trigger times: 5
end of epoch 42: val_loss 0.019952835178759024, val_acc 0.9911347517730497
trigger times: 0
saving model weights...
end of epoch 43: val_loss 0.02670683908766494, val_acc 0.9893617021276596
trigger times: 1
end of epoch 44: val_loss 0.028282342534259278, val_acc 0.9911347517730497
trigger times: 2
end of epoch 45: val_loss 0.02261112978430953, val_acc 0.9911347517730497
trigger times: 3
end of epoch 46: val_loss 0.02117242041104673, val_acc 0.9911347517730497
trigger times: 4
end of epoch 47: val_loss 0.024996750439495053, val_acc 0.9884751773049646
trigger times: 5
end of epoch 48: val_loss 0.02471316356713036, val_acc 0.9893617021276596
trigger times: 6
end of epoch 49: val_loss 0.025066034387228688, val_acc 0.9893617021276596
trigger times: 7
end of epoch 50: val_loss 0.02443185505731897, val_acc 0.9920212765957447
trigger times: 8
end of epoch 51: val_loss 0.021233972329128725, val_acc 0.9911347517730497
trigger times: 9
end of epoch 52: val_loss 0.020401490455486566, val_acc 0.9902482269503546
trigger times: 10
Early stopping.
0 -161.7301889359951 -199.20912126544414
1 -146.07845240831375 -181.59621720143082
2 -135.3275565057993 -164.41151030608535
3 -128.43487486243248 -161.32605513368566
4 -106.57366885244846 -151.5634741258087
5 -103.18124641478062 -133.76056380009578
6 -99.249261662364 -128.90054905506827
7 -95.55013013724238 -119.90296557087576
8 -91.48829255998135 -119.33378180391257
9 -91.97714314702898 -114.59035433631308
10 -77.76360199600458 -108.00922275200763
11 -63.85243961476954 -89.08705457223661
12 -57.41229446977377 -80.25399517559948
13 -54.24496276827995 -75.17483043591994
14 -49.145534530922305 -73.76362433676923
15 -45.65559838491026 -66.19170494681471
16 -46.15240002726205 -62.40117935748126
17 -30.732282223645598 -25.99016205153756
18 4.477447428856976 -0.07804593106747401
19 36.706212586024776 38.15087589300597
20 39.02466101339087 43.68426122331964
21 53.93239831167739 63.953351629706646
22 58.30101538702729 64.53271247267233
23 62.628536193980835 74.60390063743114
24 65.90095221158117 81.25241929740568
25 70.1020915764966 85.92277304180317
26 77.45107656167238 92.69937930010626
27 82.99983989243628 98.94672478897846
28 83.28027771855704 99.706470840702
29 86.52648745296756 103.1234668642953
30 89.51985222985968 105.49846404467546
31 87.65187944145873 106.70740032169537
32 92.51356318150647 110.39507157450213
33 93.1535209325375 110.82324768128066
34 90.60442053695442 111.56177998492792
35 94.06537612783723 112.21095617362457
36 94.16716222488321 112.73015958534099
37 97.07373127687606 113.05192791883351
38 98.69940191099886 117.07619652114646
39 98.61648728710134 117.34027665325667
40 98.6098129277816 117.83642486880923
41 102.34708796226187 119.20032127761252
42 103.17716770176776 119.43302815589446
43 100.80368879393791 120.15025122129617
44 102.97331428847974 122.63062574324714
45 104.50226212984853 125.78956526488335
46 106.69692357548047 125.85283998079782
47 108.21023516217247 126.58765053715479
train accuracy: 0.9866032182853648
validation accuracy: 0.9902482269503546
