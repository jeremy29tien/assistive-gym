demos: (480, 200, 19)
demo_rewards: (480,)
maximum traj length 200
maximum traj length 200
num train_obs 52326
num train_labels 52326
num val_obs 1128
num val_labels 1128
ModuleList(
  (0): Linear(in_features=19, out_features=256, bias=True)
  (1): Linear(in_features=256, out_features=256, bias=True)
  (2): Linear(in_features=256, out_features=256, bias=True)
  (3): Linear(in_features=256, out_features=1, bias=False)
)
Training reward model from scratch...
Total number of parameters: 136960
Number of trainable paramters: 136960
device: cuda:0
end of epoch 0: val_loss 0.0926785528629826, val_acc 0.9609929078014184
trigger times: 0
saving model weights...
end of epoch 1: val_loss 0.0639753819379103, val_acc 0.973404255319149
trigger times: 0
saving model weights...
end of epoch 2: val_loss 0.12198296428041218, val_acc 0.9680851063829787
trigger times: 1
end of epoch 3: val_loss 0.10904498337384767, val_acc 0.9725177304964538
trigger times: 2
end of epoch 4: val_loss 0.0881651878043547, val_acc 0.9716312056737588
trigger times: 3
end of epoch 5: val_loss 0.08016795815345999, val_acc 0.9787234042553191
trigger times: 4
end of epoch 6: val_loss 0.06902648929970913, val_acc 0.9778368794326241
trigger times: 5
end of epoch 7: val_loss 0.05977776606436519, val_acc 0.9787234042553191
trigger times: 0
saving model weights...
end of epoch 8: val_loss 0.07004883012113823, val_acc 0.9787234042553191
trigger times: 1
end of epoch 9: val_loss 0.053828569000595565, val_acc 0.9822695035460993
trigger times: 0
saving model weights...
end of epoch 10: val_loss 0.06025461641125496, val_acc 0.9822695035460993
trigger times: 1
end of epoch 11: val_loss 0.10936666812641391, val_acc 0.973404255319149
trigger times: 2
end of epoch 12: val_loss 0.07286396923693934, val_acc 0.9804964539007093
trigger times: 3
end of epoch 13: val_loss 0.059339303294715165, val_acc 0.9858156028368794
trigger times: 4
end of epoch 14: val_loss 0.06271469075865428, val_acc 0.9822695035460993
trigger times: 5
end of epoch 15: val_loss 0.08526379963227472, val_acc 0.9804964539007093
trigger times: 6
end of epoch 16: val_loss 0.056311017978352876, val_acc 0.9840425531914894
trigger times: 7
end of epoch 17: val_loss 0.05536544043899662, val_acc 0.9858156028368794
trigger times: 8
end of epoch 18: val_loss 0.08320550291865107, val_acc 0.9796099290780141
trigger times: 9
end of epoch 19: val_loss 0.13236548708682155, val_acc 0.974290780141844
trigger times: 10
Early stopping.
0 -397.64569091796875 -231.98610141016846
1 -291.86065232753754 -180.38100907229617
2 -274.3861361145973 -159.58559605250935
3 -264.7079855799675 -158.91948622182267
4 -231.09887027740479 -144.22340051424408
5 -203.60196062922478 -119.33378180391257
6 -196.0728748217225 -118.93014436813327
7 -186.37326340284199 -111.99728318755238
8 -125.00226680980995 -102.05729730987049
9 -110.3101414758712 -81.78273143585434
10 -137.6530154645443 -81.15486081250215
11 -102.2221356681548 -62.06616489925748
12 -99.3277210406959 -59.021462360023776
13 -81.83243668172508 -57.48973202587643
14 -82.30963758612052 -54.2864062956764
15 -76.50952478172258 -25.99016205153756
16 -40.47651062812656 -18.600859293147124
17 -26.057684052269906 -9.810796929333884
18 -9.071650104015134 -2.58279350160679
19 24.715063558425754 34.523887505208855
20 46.15117394924164 38.85215532611078
21 47.509950201027095 44.83371463291592
22 86.72588445572183 64.53271247267233
23 92.73485183343291 78.39646093135971
24 107.2181160831824 85.11659264541795
25 130.1064368453808 94.60034688743727
26 118.45753369666636 97.31185243955532
27 137.73640270298347 97.75965500483397
28 127.69949820637703 98.47049183311258
29 126.70641910471022 100.53051433426002
30 137.46213159291074 102.03454348571637
31 130.9647899987176 103.89263364013634
32 133.75997213227674 104.89456244575071
33 135.59507451066747 105.33214185027923
34 138.2211735327728 107.03854266018475
35 143.75307608954608 108.39772785012178
36 141.73989183455706 109.54910495619963
37 147.84313030308113 111.56177998492792
38 153.08393470570445 111.92292565511607
39 149.50734406732954 112.02235057401518
40 147.11096569150686 112.32257133288935
41 146.19594256393611 113.2348172145928
42 148.8487505093217 113.8274283128223
43 159.05077533610165 116.41091851337076
44 161.60614446504042 117.06664939486333
45 157.7817033000756 117.10824747619725
46 174.20711121498607 122.23868990266085
47 177.37753614224494 127.2098650437575
train accuracy: 0.9925467262928563
validation accuracy: 0.974290780141844
