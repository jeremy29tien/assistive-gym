demos: (480, 200, 40)
demo_rewards: (480,)
maximum traj length 200
maximum traj length 200
num train_obs 52326
num train_labels 52326
num val_obs 1128
num val_labels 1128
ModuleList(
  (0): Linear(in_features=40, out_features=256, bias=True)
  (1): Linear(in_features=256, out_features=256, bias=True)
  (2): Linear(in_features=256, out_features=256, bias=True)
  (3): Linear(in_features=256, out_features=1, bias=False)
)
Training reward model from scratch...
Total number of parameters: 142336
Number of trainable paramters: 142336
device: cuda:2
end of epoch 0: val_loss 0.080445816077138, val_acc 0.9671985815602837
trigger times: 0
saving model weights...
end of epoch 1: val_loss 0.05711307332359851, val_acc 0.9698581560283688
trigger times: 0
saving model weights...
end of epoch 2: val_loss 0.1026392347937363, val_acc 0.9671985815602837
trigger times: 1
end of epoch 3: val_loss 0.07822544155534289, val_acc 0.9778368794326241
trigger times: 2
end of epoch 4: val_loss 0.04644547119075229, val_acc 0.9804964539007093
trigger times: 0
saving model weights...
end of epoch 5: val_loss 0.06729135616579279, val_acc 0.9778368794326241
trigger times: 1
end of epoch 6: val_loss 0.07787664920551018, val_acc 0.974290780141844
trigger times: 2
end of epoch 7: val_loss 0.07126099408767579, val_acc 0.9778368794326241
trigger times: 3
end of epoch 8: val_loss 0.061741661895090116, val_acc 0.9769503546099291
trigger times: 4
end of epoch 9: val_loss 0.03982846722379685, val_acc 0.9849290780141844
trigger times: 0
saving model weights...
end of epoch 10: val_loss 0.06964235922869634, val_acc 0.9858156028368794
trigger times: 1
end of epoch 11: val_loss 0.08474864462764496, val_acc 0.9796099290780141
trigger times: 2
end of epoch 12: val_loss 0.06435257305348956, val_acc 0.9778368794326241
trigger times: 3
end of epoch 13: val_loss 0.06309599801420707, val_acc 0.9778368794326241
trigger times: 4
end of epoch 14: val_loss 0.06698121971902819, val_acc 0.9787234042553191
trigger times: 5
end of epoch 15: val_loss 0.07418500814435074, val_acc 0.976063829787234
trigger times: 6
end of epoch 16: val_loss 0.04694009046123907, val_acc 0.9804964539007093
trigger times: 7
end of epoch 17: val_loss 0.05159182464634486, val_acc 0.9831560283687943
trigger times: 8
end of epoch 18: val_loss 0.08597540428903147, val_acc 0.9769503546099291
trigger times: 9
end of epoch 19: val_loss 0.08343563666042388, val_acc 0.9778368794326241
trigger times: 10
Early stopping.
0 -273.21516197919846 -231.98610141016846
1 -184.46220114827156 -180.38100907229617
2 -177.09971049427986 -159.58559605250935
3 -173.51125621795654 -158.91948622182267
4 -153.53115648031235 -144.22340051424408
5 -127.30425855517387 -119.33378180391257
6 -121.1619105914142 -118.93014436813327
7 -112.31135188206099 -111.99728318755238
8 -73.33150190644665 -102.05729730987049
9 -64.36914812820032 -81.78273143585434
10 -74.91701347194612 -81.15486081250215
11 -50.727571873227134 -62.06616489925748
12 -41.68292471044697 -59.021462360023776
13 -31.582792673551012 -57.48973202587643
14 -34.125049371272326 -54.2864062956764
15 -29.373212904843967 -25.99016205153756
16 -3.4371409830637276 -18.600859293147124
17 15.735714314738289 -9.810796929333884
18 21.32101281126961 -2.58279350160679
19 52.3640600934159 34.523887505208855
20 65.0846962215146 38.85215532611078
21 63.70920528843999 44.83371463291592
22 96.87970802863128 64.53271247267233
23 98.49568271217868 78.39646093135971
24 118.59330196207156 85.11659264541795
25 134.06108164810576 94.60034688743727
26 122.75700337532908 97.31185243955532
27 134.64419489185093 97.75965500483397
28 126.3453887484502 98.47049183311258
29 128.97312370873988 100.53051433426002
30 136.42747239093296 102.03454348571637
31 133.3021049844101 103.89263364013634
32 133.5075844944222 104.89456244575071
33 137.68701358442195 105.33214185027923
34 134.72306480881525 107.03854266018475
35 143.75247211757232 108.39772785012178
36 138.9876060220413 109.54910495619963
37 143.57109399873298 111.56177998492792
38 147.51801792206243 111.92292565511607
39 145.79005806008354 112.02235057401518
40 144.76303637353703 112.32257133288935
41 145.51360909605864 113.2348172145928
42 149.37192631768994 113.8274283128223
43 152.40830701467348 116.41091851337076
44 157.765284671681 117.06664939486333
45 155.02472406969173 117.10824747619725
46 162.43145656245179 122.23868990266085
47 166.00739886041265 127.2098650437575
train accuracy: 0.9935787180369223
validation accuracy: 0.9778368794326241
