demos: (480, 200, 40)
demo_rewards: (480,)
maximum traj length 200
maximum traj length 200
num train_obs 46655
num train_labels 46655
num val_obs 1128
num val_labels 1128
ModuleList(
  (0): Linear(in_features=40, out_features=256, bias=True)
  (1): Linear(in_features=256, out_features=256, bias=True)
  (2): Linear(in_features=256, out_features=256, bias=True)
  (3): Linear(in_features=256, out_features=1, bias=False)
)
Training reward model from scratch...
Total number of parameters: 142336
Number of trainable paramters: 142336
device: cuda:2
end of epoch 0: val_loss 0.08925732267069142, val_acc 0.9680851063829787
trigger times: 0
saving model weights...
end of epoch 1: val_loss 0.0743475695422715, val_acc 0.973404255319149
trigger times: 0
saving model weights...
end of epoch 2: val_loss 0.12045281638321173, val_acc 0.9707446808510638
trigger times: 1
end of epoch 3: val_loss 0.054325908899003635, val_acc 0.9787234042553191
trigger times: 0
saving model weights...
end of epoch 4: val_loss 0.07421441885749118, val_acc 0.976063829787234
trigger times: 1
end of epoch 5: val_loss 0.06851141888489612, val_acc 0.976063829787234
trigger times: 2
end of epoch 6: val_loss 0.06769499948182767, val_acc 0.9796099290780141
trigger times: 3
end of epoch 7: val_loss 0.10842101797449254, val_acc 0.9725177304964538
trigger times: 4
end of epoch 8: val_loss 0.07733601612404008, val_acc 0.9769503546099291
trigger times: 5
end of epoch 9: val_loss 0.04867749543538643, val_acc 0.9849290780141844
trigger times: 0
saving model weights...
end of epoch 10: val_loss 0.09719679819369215, val_acc 0.9769503546099291
trigger times: 1
end of epoch 11: val_loss 0.09233501866838789, val_acc 0.9787234042553191
trigger times: 2
end of epoch 12: val_loss 0.1280105655643727, val_acc 0.9787234042553191
trigger times: 3
end of epoch 13: val_loss 0.09939292446122133, val_acc 0.9831560283687943
trigger times: 4
end of epoch 14: val_loss 0.06601146089767156, val_acc 0.9858156028368794
trigger times: 5
end of epoch 15: val_loss 0.09859715089244797, val_acc 0.9796099290780141
trigger times: 6
end of epoch 16: val_loss 0.16628396295674838, val_acc 0.975177304964539
trigger times: 7
end of epoch 17: val_loss 0.08090645097239413, val_acc 0.9849290780141844
trigger times: 8
end of epoch 18: val_loss 0.10095177644845595, val_acc 0.9813829787234043
trigger times: 9
end of epoch 19: val_loss 0.09626844099494636, val_acc 0.9796099290780141
trigger times: 10
Early stopping.
0 -354.07463163137436 -231.98610141016846
1 -268.8867657780647 -180.38100907229617
2 -231.2817947268486 -159.58559605250935
3 -189.42153722047806 -158.91948622182267
4 -218.5592987537384 -144.22340051424408
5 -185.80007809400558 -119.33378180391257
6 -180.72068236768246 -118.93014436813327
7 -150.25457237660885 -111.99728318755238
8 -117.20831971568987 -102.05729730987049
9 -98.6773398492951 -81.78273143585434
10 -119.85072037950158 -81.15486081250215
11 -98.88737258012407 -62.06616489925748
12 -85.08784819208086 -59.021462360023776
13 -82.62177144177258 -57.48973202587643
14 -72.49965859996155 -54.2864062956764
15 -70.6621287544258 -25.99016205153756
16 -41.91026905353647 -18.600859293147124
17 -14.069671373814344 -9.810796929333884
18 -7.250804890412837 -2.58279350160679
19 31.35740683367476 34.523887505208855
20 43.77347037685104 38.85215532611078
21 55.122053652768955 44.83371463291592
22 85.1508254869841 64.53271247267233
23 99.61058673227672 78.39646093135971
24 114.98540925706038 85.11659264541795
25 132.16005218648934 94.60034688743727
26 122.72632575564785 97.31185243955532
27 130.42783785716165 97.75965500483397
28 129.8130972981453 98.47049183311258
29 131.6365829287097 100.53051433426002
30 139.10865050600842 102.03454348571637
31 135.91753105819225 103.89263364013634
32 136.7507275386597 104.89456244575071
33 140.3753922372125 105.33214185027923
34 136.6775382622145 107.03854266018475
35 148.99219366442412 108.39772785012178
36 143.44743259891402 109.54910495619963
37 148.53357482794672 111.56177998492792
38 151.1356598867569 111.92292565511607
39 151.84113470849115 112.02235057401518
40 151.82370195467956 112.32257133288935
41 150.03202529461123 113.2348172145928
42 154.1193191879429 113.8274283128223
43 160.9348246579757 116.41091851337076
44 162.80496412015054 117.06664939486333
45 158.70711826649494 117.10824747619725
46 174.78323796286713 122.23868990266085
47 171.41361998970388 127.2098650437575
train accuracy: 0.994748687171793
validation accuracy: 0.9796099290780141
