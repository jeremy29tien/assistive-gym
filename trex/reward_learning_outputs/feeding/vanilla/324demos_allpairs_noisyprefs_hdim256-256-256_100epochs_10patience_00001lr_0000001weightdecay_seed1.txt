demos: (480, 200, 40)
demo_rewards: (480,)
maximum traj length 200
maximum traj length 200
num train_obs 52326
num train_labels 52326
num val_obs 1128
num val_labels 1128
ModuleList(
  (0): Linear(in_features=40, out_features=256, bias=True)
  (1): Linear(in_features=256, out_features=256, bias=True)
  (2): Linear(in_features=256, out_features=256, bias=True)
  (3): Linear(in_features=256, out_features=1, bias=False)
)
Training reward model from scratch...
Total number of parameters: 142336
Number of trainable paramters: 142336
device: cuda:0
end of epoch 0: val_loss 0.06664808886308139, val_acc 0.9769503546099291
trigger times: 0
saving model weights...
end of epoch 1: val_loss 0.06157166892843155, val_acc 0.974290780141844
trigger times: 0
saving model weights...
end of epoch 2: val_loss 0.05129060924898521, val_acc 0.974290780141844
trigger times: 0
saving model weights...
end of epoch 3: val_loss 0.062300829746254456, val_acc 0.9716312056737588
trigger times: 1
end of epoch 4: val_loss 0.058459707727483386, val_acc 0.9769503546099291
trigger times: 2
end of epoch 5: val_loss 0.0543551882341406, val_acc 0.976063829787234
trigger times: 3
end of epoch 6: val_loss 0.04774325872821223, val_acc 0.9787234042553191
trigger times: 0
saving model weights...
end of epoch 7: val_loss 0.04952613559459877, val_acc 0.9787234042553191
trigger times: 1
end of epoch 8: val_loss 0.05166257412893821, val_acc 0.9778368794326241
trigger times: 2
end of epoch 9: val_loss 0.058808190871294554, val_acc 0.9804964539007093
trigger times: 3
end of epoch 10: val_loss 0.06409091814990775, val_acc 0.9725177304964538
trigger times: 4
end of epoch 11: val_loss 0.04537349722769758, val_acc 0.9849290780141844
trigger times: 0
saving model weights...
end of epoch 12: val_loss 0.05108807960077182, val_acc 0.9796099290780141
trigger times: 1
end of epoch 13: val_loss 0.042777689270174224, val_acc 0.9840425531914894
trigger times: 0
saving model weights...
end of epoch 14: val_loss 0.04067187594594694, val_acc 0.9831560283687943
trigger times: 0
saving model weights...
end of epoch 15: val_loss 0.043406582117515385, val_acc 0.9831560283687943
trigger times: 1
end of epoch 16: val_loss 0.057684599902277194, val_acc 0.9778368794326241
trigger times: 2
end of epoch 17: val_loss 0.04180867534151896, val_acc 0.9849290780141844
trigger times: 3
end of epoch 18: val_loss 0.03698131814086038, val_acc 0.9831560283687943
trigger times: 0
saving model weights...
end of epoch 19: val_loss 0.038294425067776645, val_acc 0.9778368794326241
trigger times: 1
end of epoch 20: val_loss 0.049552002720544226, val_acc 0.9822695035460993
trigger times: 2
end of epoch 21: val_loss 0.04178067164750939, val_acc 0.9831560283687943
trigger times: 3
end of epoch 22: val_loss 0.04749630594878067, val_acc 0.9813829787234043
trigger times: 4
end of epoch 23: val_loss 0.054640840946723605, val_acc 0.975177304964539
trigger times: 5
end of epoch 24: val_loss 0.03776600174449485, val_acc 0.9849290780141844
trigger times: 6
end of epoch 25: val_loss 0.04902886480713116, val_acc 0.9796099290780141
trigger times: 7
end of epoch 26: val_loss 0.044770307048517255, val_acc 0.9813829787234043
trigger times: 8
end of epoch 27: val_loss 0.03972205571853198, val_acc 0.9822695035460993
trigger times: 9
end of epoch 28: val_loss 0.03450505064439192, val_acc 0.9822695035460993
trigger times: 0
saving model weights...
end of epoch 29: val_loss 0.039780588404527646, val_acc 0.9822695035460993
trigger times: 1
end of epoch 30: val_loss 0.03532266400850422, val_acc 0.9884751773049646
trigger times: 2
end of epoch 31: val_loss 0.065301435092535, val_acc 0.9804964539007093
trigger times: 3
end of epoch 32: val_loss 0.03403658994110372, val_acc 0.9849290780141844
trigger times: 0
saving model weights...
end of epoch 33: val_loss 0.03605602827340568, val_acc 0.9831560283687943
trigger times: 1
end of epoch 34: val_loss 0.041815140006525794, val_acc 0.9831560283687943
trigger times: 2
end of epoch 35: val_loss 0.052373873612038005, val_acc 0.9813829787234043
trigger times: 3
end of epoch 36: val_loss 0.03980397736691158, val_acc 0.9831560283687943
trigger times: 4
end of epoch 37: val_loss 0.03779349375418547, val_acc 0.9875886524822695
trigger times: 5
end of epoch 38: val_loss 0.04014601871955742, val_acc 0.9822695035460993
trigger times: 6
end of epoch 39: val_loss 0.03547822407156355, val_acc 0.9840425531914894
trigger times: 7
end of epoch 40: val_loss 0.032007651037419454, val_acc 0.9902482269503546
trigger times: 0
saving model weights...
end of epoch 41: val_loss 0.030250482850040797, val_acc 0.9893617021276596
trigger times: 0
saving model weights...
end of epoch 42: val_loss 0.036441286893291944, val_acc 0.9840425531914894
trigger times: 1
end of epoch 43: val_loss 0.03667111151163906, val_acc 0.9840425531914894
trigger times: 2
end of epoch 44: val_loss 0.040723401690715554, val_acc 0.9849290780141844
trigger times: 3
end of epoch 45: val_loss 0.03974918401361439, val_acc 0.9813829787234043
trigger times: 4
end of epoch 46: val_loss 0.046236921572965, val_acc 0.9831560283687943
trigger times: 5
end of epoch 47: val_loss 0.032113073375019334, val_acc 0.9884751773049646
trigger times: 6
end of epoch 48: val_loss 0.030025686107610684, val_acc 0.9867021276595744
trigger times: 0
saving model weights...
end of epoch 49: val_loss 0.038412722770408955, val_acc 0.9813829787234043
trigger times: 1
end of epoch 50: val_loss 0.04000523534958225, val_acc 0.9858156028368794
trigger times: 2
end of epoch 51: val_loss 0.030863875492129173, val_acc 0.9875886524822695
trigger times: 3
end of epoch 52: val_loss 0.04526857551386312, val_acc 0.9831560283687943
trigger times: 4
end of epoch 53: val_loss 0.032743036962838486, val_acc 0.9831560283687943
trigger times: 5
end of epoch 54: val_loss 0.035439791713093104, val_acc 0.9849290780141844
trigger times: 6
end of epoch 55: val_loss 0.025880676435163955, val_acc 0.9902482269503546
trigger times: 0
saving model weights...
end of epoch 56: val_loss 0.026952699951618503, val_acc 0.9884751773049646
trigger times: 1
end of epoch 57: val_loss 0.03355279564674541, val_acc 0.9858156028368794
trigger times: 2
end of epoch 58: val_loss 0.03917413996661487, val_acc 0.9804964539007093
trigger times: 3
end of epoch 59: val_loss 0.036881878077942305, val_acc 0.9840425531914894
trigger times: 4
end of epoch 60: val_loss 0.04634213631537645, val_acc 0.9804964539007093
trigger times: 5
end of epoch 61: val_loss 0.03307713782975802, val_acc 0.9849290780141844
trigger times: 6
end of epoch 62: val_loss 0.03369551569505278, val_acc 0.9858156028368794
trigger times: 7
end of epoch 63: val_loss 0.04493657799316623, val_acc 0.9867021276595744
trigger times: 8
end of epoch 64: val_loss 0.04870507243001093, val_acc 0.9822695035460993
trigger times: 9
end of epoch 65: val_loss 0.036191104517403434, val_acc 0.9822695035460993
trigger times: 10
Early stopping.
0 -207.35779839754105 -231.98610141016846
1 -145.02111890912056 -180.38100907229617
2 -127.78212150931358 -159.58559605250935
3 -136.72246403992176 -158.91948622182267
4 -112.50071412324905 -144.22340051424408
5 -93.08950640261173 -119.33378180391257
6 -92.95977389998734 -118.93014436813327
7 -85.09026062581688 -111.99728318755238
8 -63.535403678775765 -102.05729730987049
9 -56.36565302684903 -81.78273143585434
10 -58.38162875303533 -81.15486081250215
11 -45.377817111322656 -62.06616489925748
12 -36.270404004491866 -59.021462360023776
13 -33.386700013885275 -57.48973202587643
14 -34.22717802110128 -54.2864062956764
15 -29.633999409037642 -25.99016205153756
16 -11.290236253058538 -18.600859293147124
17 3.348639180418104 -9.810796929333884
18 6.986269786139019 -2.58279350160679
19 29.597631860291585 34.523887505208855
20 36.68065552681219 38.85215532611078
21 40.18819342297502 44.83371463291592
22 58.397484741406515 64.53271247267233
23 65.9222187512787 78.39646093135971
24 77.15641613467596 85.11659264541795
25 84.39627323485911 94.60034688743727
26 81.677189654205 97.31185243955532
27 85.55933315679431 97.75965500483397
28 84.13977689575404 98.47049183311258
29 84.6736807617126 100.53051433426002
30 88.42770564591046 102.03454348571637
31 88.90302628395148 103.89263364013634
32 88.41826101473998 104.89456244575071
33 90.59605682012625 105.33214185027923
34 88.7102161841467 107.03854266018475
35 93.06282589805778 108.39772785012178
36 93.20855948352255 109.54910495619963
37 96.15479841560591 111.56177998492792
38 96.53456916648429 111.92292565511607
39 95.89520063099917 112.02235057401518
40 95.54321529099252 112.32257133288935
41 95.85283940820955 113.2348172145928
42 98.04019519942813 113.8274283128223
43 100.12111346726306 116.41091851337076
44 102.08041318552569 117.06664939486333
45 101.35233624023385 117.10824747619725
46 107.33535667776596 122.23868990266085
47 111.48579259414691 127.2098650437575
train accuracy: 0.9858961128310973
validation accuracy: 0.9822695035460993
