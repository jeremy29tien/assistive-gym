demos: (480, 200, 32)
demo_rewards: (480,)
maximum traj length 200
maximum traj length 200
num train_obs 52326
num train_labels 52326
num val_obs 1128
num val_labels 1128
ModuleList(
  (0): Linear(in_features=32, out_features=256, bias=True)
  (1): Linear(in_features=256, out_features=256, bias=True)
  (2): Linear(in_features=256, out_features=256, bias=True)
  (3): Linear(in_features=256, out_features=1, bias=False)
)
Training reward model from scratch...
Total number of parameters: 140288
Number of trainable paramters: 140288
device: cuda:0
end of epoch 0: val_loss 0.2759632523781597, val_acc 0.8847517730496454
trigger times: 0
saving model weights...
end of epoch 1: val_loss 0.31901932070556616, val_acc 0.87677304964539
trigger times: 1
end of epoch 2: val_loss 0.27947607040141575, val_acc 0.8714539007092199
trigger times: 2
end of epoch 3: val_loss 0.29473804930695946, val_acc 0.8617021276595744
trigger times: 3
end of epoch 4: val_loss 0.29291005619868893, val_acc 0.8714539007092199
trigger times: 4
end of epoch 5: val_loss 0.31475317232036204, val_acc 0.8714539007092199
trigger times: 5
end of epoch 6: val_loss 0.2797584512520529, val_acc 0.8776595744680851
trigger times: 6
end of epoch 7: val_loss 0.3167300065380583, val_acc 0.8670212765957447
trigger times: 7
end of epoch 8: val_loss 0.28448729153824476, val_acc 0.8794326241134752
trigger times: 8
end of epoch 9: val_loss 0.35214868637347685, val_acc 0.8643617021276596
trigger times: 9
end of epoch 10: val_loss 0.3422732553673607, val_acc 0.8625886524822695
trigger times: 10
Early stopping.
0 6.061272559338249 -193.77058932274844
1 4.591108016349608 -189.65792573794374
2 5.254868319010711 -181.53450727998975
3 5.491118577250745 -180.94031503146633
4 4.897135654231533 -171.07185874229646
5 12.259333804948255 -146.8781492057455
6 11.30643838213291 -135.2361570794697
7 7.787593552609906 -132.32422579815238
8 10.809106112457812 -127.52896259979991
9 13.24726314120926 -119.75955492239184
10 14.54862581123598 -116.02779530304753
11 11.944795036950381 -113.25601936308428
12 13.295673455111682 -108.31590456875345
13 16.870133735239506 -63.684489628253
14 15.491717228200287 -52.141471551227674
15 17.835494162980467 -26.554830714509592
16 16.37814661837183 -7.0071959811727575
17 14.864779521012679 25.69124123513366
18 19.249184001237154 35.213628549995846
19 13.920133859734051 40.428355258377486
20 17.394097425276414 46.20583772082509
21 14.758158409735188 51.192000963985954
22 17.436361625790596 66.21591564279122
23 17.671817339025438 85.90004097928022
24 15.878224636428058 88.41217626317327
25 23.61525304755196 89.56728208081473
26 16.392445270437747 91.60759786486705
27 16.904383507557213 94.47894135375837
28 19.33177989628166 98.94440192500335
29 15.860872340155765 102.0062792742551
30 16.55454007256776 102.20476160553419
31 16.170990103506483 103.01364436404991
32 18.537435521604493 103.71935195099562
33 17.923852795967832 110.33860671277482
34 21.136791938450187 113.86158089834132
35 20.07942972611636 113.96536766392857
36 22.65859989495948 114.38427652291234
37 19.2217250673566 114.64275179580558
38 19.523604492656887 114.66425172742227
39 15.865765595342964 115.70154293965129
40 24.96504291333258 116.43876967111639
41 23.494566368404776 121.26452240374262
42 24.125898842699826 121.8148633500027
43 23.041694102343172 122.31117983367389
44 24.344809751491994 125.86136637734936
45 23.935562094673514 126.33642093404846
46 23.158913695719093 128.38744332488002
47 26.877295156009495 130.93804427787234
train accuracy: 0.886404464319841
validation accuracy: 0.8625886524822695
demos: (500, 200, 32)
demo_rewards: (500,)
maximum traj length 200
maximum traj length 200
num train_obs 52326
num train_labels 52326
num val_obs 1225
num val_labels 1225
ModuleList(
  (0): Linear(in_features=32, out_features=256, bias=True)
  (1): Linear(in_features=256, out_features=256, bias=True)
  (2): Linear(in_features=256, out_features=256, bias=True)
  (3): Linear(in_features=256, out_features=1, bias=False)
)
Training reward model from scratch...
Total number of parameters: 140288
Number of trainable paramters: 140288
device: cuda:1
end of epoch 0: val_loss 0.39096693478641353, val_acc 0.8359183673469388
trigger times: 0
saving model weights...
end of epoch 1: val_loss 0.40645026754224944, val_acc 0.8163265306122449
trigger times: 1
end of epoch 2: val_loss 0.4242978051842323, val_acc 0.8179591836734694
trigger times: 2
end of epoch 3: val_loss 0.38523980614758974, val_acc 0.833469387755102
trigger times: 0
saving model weights...
end of epoch 4: val_loss 0.37476888432264877, val_acc 0.830204081632653
trigger times: 0
saving model weights...
end of epoch 5: val_loss 0.43420947572507246, val_acc 0.8081632653061225
trigger times: 1
end of epoch 6: val_loss 0.46286597436542204, val_acc 0.8138775510204082
trigger times: 2
end of epoch 7: val_loss 0.5197150848940489, val_acc 0.8269387755102041
trigger times: 3
end of epoch 8: val_loss 0.41001325302642133, val_acc 0.8285714285714286
trigger times: 4
end of epoch 9: val_loss 0.39230956678369927, val_acc 0.8359183673469388
trigger times: 5
end of epoch 10: val_loss 0.4539429313421545, val_acc 0.833469387755102
trigger times: 6
end of epoch 11: val_loss 0.3636315626973211, val_acc 0.8424489795918367
trigger times: 0
saving model weights...
end of epoch 12: val_loss 0.4136680898485515, val_acc 0.8195918367346938
trigger times: 1
end of epoch 13: val_loss 0.4530888824103922, val_acc 0.8057142857142857
trigger times: 2
end of epoch 14: val_loss 0.37682246812215825, val_acc 0.8318367346938775
trigger times: 3
end of epoch 15: val_loss 0.40085071867927524, val_acc 0.8351020408163266
trigger times: 4
end of epoch 16: val_loss 0.5140586948988071, val_acc 0.8155102040816327
trigger times: 5
end of epoch 17: val_loss 0.4436483120815886, val_acc 0.830204081632653
trigger times: 6
end of epoch 18: val_loss 0.4474657833467557, val_acc 0.8351020408163266
trigger times: 7
end of epoch 19: val_loss 0.3518871504166342, val_acc 0.8408163265306122
trigger times: 0
saving model weights...
end of epoch 20: val_loss 0.5026159679843825, val_acc 0.8204081632653061
trigger times: 1
end of epoch 21: val_loss 0.43282433848712926, val_acc 0.8228571428571428
trigger times: 2
end of epoch 22: val_loss 0.4369150693177284, val_acc 0.8506122448979592
trigger times: 3
end of epoch 23: val_loss 0.45486605831540294, val_acc 0.8220408163265306
trigger times: 4
end of epoch 24: val_loss 0.48775285753330483, val_acc 0.8244897959183674
trigger times: 5
end of epoch 25: val_loss 0.4321801245173828, val_acc 0.8261224489795919
trigger times: 6
end of epoch 26: val_loss 0.4695295071832294, val_acc 0.7877551020408163
trigger times: 7
end of epoch 27: val_loss 0.4249195098117089, val_acc 0.8016326530612244
trigger times: 8
end of epoch 28: val_loss 0.460176663967383, val_acc 0.8195918367346938
trigger times: 9
end of epoch 29: val_loss 0.4063086201306538, val_acc 0.8195918367346938
trigger times: 10
Early stopping.
0 1.3588081912748748 -215.9177878701233
1 3.0175779168494046 -193.77058932274844
2 1.9759090747102164 -189.65792573794374
3 2.3722566936485237 -182.7652293135204
4 2.3839662227546796 -177.19608324005077
5 3.7401966671459377 -166.39808272925822
6 1.866779970623611 -156.23561904706384
7 5.9649113783671055 -136.9016903684411
8 8.585957748116925 -135.2361570794697
9 5.45043459783119 -132.4999980274812
10 5.918900629189011 -121.05332354775513
11 8.190370165975764 -113.25601936308428
12 11.768992563709617 -93.63303104415972
13 9.863625184836565 -83.54839050364284
14 11.126081834197976 -74.7548860746456
15 6.1303471238934435 -62.96339137499396
16 9.729848016228061 -58.66155314643179
17 12.357327871228335 -26.554830714509592
18 9.253368572011823 -19.260698919289915
19 10.223899598931894 -1.5133315871504047
20 13.664888110703032 16.189721761006762
21 10.073683383932803 21.358512279863625
22 8.762708827503957 40.428355258377486
23 13.62453191030363 50.95779374754577
24 11.40441430581268 52.74553531088168
25 13.873555035796016 65.21111912527643
26 11.29521653446136 66.21591564279122
27 12.32855515787378 76.42960210286357
28 12.646409751847386 80.74193671363145
29 11.505403105373261 82.1538390506234
30 9.5496531650424 91.60759786486705
31 9.65202645471436 94.47894135375837
32 12.252413118025288 95.38778469665249
33 11.840792214963585 99.32498886731922
34 9.40451492419379 102.20476160553419
35 10.899605806567706 102.28029269159464
36 9.099449196801288 103.01364436404991
37 11.950029683997855 104.33313818327396
38 12.271070428658277 109.72886417501778
39 11.503292791720014 110.33860671277482
40 14.203197252121754 111.55240978447834
41 11.503458730920102 111.87102467515453
42 14.127283405978233 113.49209291788252
43 15.501598929520696 114.38427652291234
44 12.864753551781178 117.71453405712296
45 14.578706388594583 121.26452240374262
46 17.27726044668816 121.8148633500027
47 15.635560125578195 122.31117983367389
48 15.004908366594464 125.86136637734936
49 14.860774810047587 130.45510520660062
train accuracy: 0.8805947330199136
validation accuracy: 0.8195918367346938
demos: (480, 200, 32)
demo_rewards: (480,)
maximum traj length 200
maximum traj length 200
num train_obs 52326
num train_labels 52326
num val_obs 1128
num val_labels 1128
ModuleList(
  (0): Linear(in_features=32, out_features=256, bias=True)
  (1): Linear(in_features=256, out_features=256, bias=True)
  (2): Linear(in_features=256, out_features=256, bias=True)
  (3): Linear(in_features=256, out_features=1, bias=False)
)
Training reward model from scratch...
Total number of parameters: 140288
Number of trainable paramters: 140288
device: cuda:0
end of epoch 0: val_loss 0.2759632523781597, val_acc 0.8847517730496454
trigger times: 0
saving model weights...
end of epoch 1: val_loss 0.31901932070556616, val_acc 0.87677304964539
trigger times: 1
end of epoch 2: val_loss 0.27947607040141575, val_acc 0.8714539007092199
trigger times: 2
end of epoch 3: val_loss 0.29473804930695946, val_acc 0.8617021276595744
trigger times: 3
end of epoch 4: val_loss 0.29291005619868893, val_acc 0.8714539007092199
trigger times: 4
end of epoch 5: val_loss 0.31475317232036204, val_acc 0.8714539007092199
trigger times: 5
end of epoch 6: val_loss 0.2797584512520529, val_acc 0.8776595744680851
trigger times: 6
end of epoch 7: val_loss 0.3167300065380583, val_acc 0.8670212765957447
trigger times: 7
end of epoch 8: val_loss 0.28448729153824476, val_acc 0.8794326241134752
trigger times: 8
end of epoch 9: val_loss 0.35214868637347685, val_acc 0.8643617021276596
trigger times: 9
end of epoch 10: val_loss 0.3422732553673607, val_acc 0.8625886524822695
trigger times: 10
Early stopping.
0 6.061272559338249 -193.77058932274844
1 4.591108016349608 -189.65792573794374
2 5.254868319010711 -181.53450727998975
3 5.491118577250745 -180.94031503146633
4 4.897135654231533 -171.07185874229646
5 12.259333804948255 -146.8781492057455
6 11.30643838213291 -135.2361570794697
7 7.787593552609906 -132.32422579815238
8 10.809106112457812 -127.52896259979991
9 13.24726314120926 -119.75955492239184
10 14.54862581123598 -116.02779530304753
11 11.944795036950381 -113.25601936308428
12 13.295673455111682 -108.31590456875345
13 16.870133735239506 -63.684489628253
14 15.491717228200287 -52.141471551227674
15 17.835494162980467 -26.554830714509592
16 16.37814661837183 -7.0071959811727575
17 14.864779521012679 25.69124123513366
18 19.249184001237154 35.213628549995846
19 13.920133859734051 40.428355258377486
20 17.394097425276414 46.20583772082509
21 14.758158409735188 51.192000963985954
22 17.436361625790596 66.21591564279122
23 17.671817339025438 85.90004097928022
24 15.878224636428058 88.41217626317327
25 23.61525304755196 89.56728208081473
26 16.392445270437747 91.60759786486705
27 16.904383507557213 94.47894135375837
28 19.33177989628166 98.94440192500335
29 15.860872340155765 102.0062792742551
30 16.55454007256776 102.20476160553419
31 16.170990103506483 103.01364436404991
32 18.537435521604493 103.71935195099562
33 17.923852795967832 110.33860671277482
34 21.136791938450187 113.86158089834132
35 20.07942972611636 113.96536766392857
36 22.65859989495948 114.38427652291234
37 19.2217250673566 114.64275179580558
38 19.523604492656887 114.66425172742227
39 15.865765595342964 115.70154293965129
40 24.96504291333258 116.43876967111639
41 23.494566368404776 121.26452240374262
42 24.125898842699826 121.8148633500027
43 23.041694102343172 122.31117983367389
44 24.344809751491994 125.86136637734936
45 23.935562094673514 126.33642093404846
46 23.158913695719093 128.38744332488002
47 26.877295156009495 130.93804427787234
train accuracy: 0.886404464319841
validation accuracy: 0.8625886524822695
demos: (500, 200, 32)
demo_rewards: (500,)
maximum traj length 200
maximum traj length 200
num train_obs 52326
num train_labels 52326
num val_obs 1225
num val_labels 1225
ModuleList(
  (0): Linear(in_features=32, out_features=256, bias=True)
  (1): Linear(in_features=256, out_features=256, bias=True)
  (2): Linear(in_features=256, out_features=256, bias=True)
  (3): Linear(in_features=256, out_features=1, bias=False)
)
Training reward model from scratch...
Total number of parameters: 140288
Number of trainable paramters: 140288
device: cuda:2
end of epoch 0: val_loss 0.39096693478641353, val_acc 0.8359183673469388
trigger times: 0
saving model weights...
end of epoch 1: val_loss 0.40645026754224944, val_acc 0.8163265306122449
trigger times: 1
end of epoch 2: val_loss 0.4242978051842323, val_acc 0.8179591836734694
trigger times: 2
end of epoch 3: val_loss 0.38523980614758974, val_acc 0.833469387755102
trigger times: 0
saving model weights...
end of epoch 4: val_loss 0.37476888432264877, val_acc 0.830204081632653
trigger times: 0
saving model weights...
end of epoch 5: val_loss 0.43420947572507246, val_acc 0.8081632653061225
trigger times: 1
end of epoch 6: val_loss 0.46286597436542204, val_acc 0.8138775510204082
trigger times: 2
end of epoch 7: val_loss 0.5197150848940489, val_acc 0.8269387755102041
trigger times: 3
end of epoch 8: val_loss 0.41001325302642133, val_acc 0.8285714285714286
trigger times: 4
end of epoch 9: val_loss 0.39230956678369927, val_acc 0.8359183673469388
trigger times: 5
end of epoch 10: val_loss 0.4539429313421545, val_acc 0.833469387755102
trigger times: 6
end of epoch 11: val_loss 0.3636315626973211, val_acc 0.8424489795918367
trigger times: 0
saving model weights...
end of epoch 12: val_loss 0.4136680898485515, val_acc 0.8195918367346938
trigger times: 1
end of epoch 13: val_loss 0.4530888824103922, val_acc 0.8057142857142857
trigger times: 2
end of epoch 14: val_loss 0.37682246812215825, val_acc 0.8318367346938775
trigger times: 3
end of epoch 15: val_loss 0.40085071867927524, val_acc 0.8351020408163266
trigger times: 4
end of epoch 16: val_loss 0.5140586948988071, val_acc 0.8155102040816327
trigger times: 5
end of epoch 17: val_loss 0.4436483120815886, val_acc 0.830204081632653
trigger times: 6
end of epoch 18: val_loss 0.4474657833467557, val_acc 0.8351020408163266
trigger times: 7
end of epoch 19: val_loss 0.3518871504166342, val_acc 0.8408163265306122
trigger times: 0
saving model weights...
end of epoch 20: val_loss 0.5026159679843825, val_acc 0.8204081632653061
trigger times: 1
end of epoch 21: val_loss 0.43282433848712926, val_acc 0.8228571428571428
trigger times: 2
end of epoch 22: val_loss 0.4369150693177284, val_acc 0.8506122448979592
trigger times: 3
end of epoch 23: val_loss 0.45486605831540294, val_acc 0.8220408163265306
trigger times: 4
end of epoch 24: val_loss 0.48775285753330483, val_acc 0.8244897959183674
trigger times: 5
end of epoch 25: val_loss 0.4321801245173828, val_acc 0.8261224489795919
trigger times: 6
end of epoch 26: val_loss 0.4695295071832294, val_acc 0.7877551020408163
trigger times: 7
end of epoch 27: val_loss 0.4249195098117089, val_acc 0.8016326530612244
trigger times: 8
end of epoch 28: val_loss 0.460176663967383, val_acc 0.8195918367346938
trigger times: 9
end of epoch 29: val_loss 0.4063086201306538, val_acc 0.8195918367346938
trigger times: 10
Early stopping.
0 1.3588081912748748 -215.9177878701233
1 3.0175779168494046 -193.77058932274844
2 1.9759090747102164 -189.65792573794374
3 2.3722566936485237 -182.7652293135204
4 2.3839662227546796 -177.19608324005077
5 3.7401966671459377 -166.39808272925822
6 1.866779970623611 -156.23561904706384
7 5.9649113783671055 -136.9016903684411
8 8.585957748116925 -135.2361570794697
9 5.45043459783119 -132.4999980274812
10 5.918900629189011 -121.05332354775513
11 8.190370165975764 -113.25601936308428
12 11.768992563709617 -93.63303104415972
13 9.863625184836565 -83.54839050364284
14 11.126081834197976 -74.7548860746456
15 6.1303471238934435 -62.96339137499396
16 9.729848016228061 -58.66155314643179
17 12.357327871228335 -26.554830714509592
18 9.253368572011823 -19.260698919289915
19 10.223899598931894 -1.5133315871504047
20 13.664888110703032 16.189721761006762
21 10.073683383932803 21.358512279863625
22 8.762708827503957 40.428355258377486
23 13.62453191030363 50.95779374754577
24 11.40441430581268 52.74553531088168
25 13.873555035796016 65.21111912527643
26 11.29521653446136 66.21591564279122
27 12.32855515787378 76.42960210286357
28 12.646409751847386 80.74193671363145
29 11.505403105373261 82.1538390506234
30 9.5496531650424 91.60759786486705
31 9.65202645471436 94.47894135375837
32 12.252413118025288 95.38778469665249
33 11.840792214963585 99.32498886731922
34 9.40451492419379 102.20476160553419
35 10.899605806567706 102.28029269159464
36 9.099449196801288 103.01364436404991
37 11.950029683997855 104.33313818327396
38 12.271070428658277 109.72886417501778
39 11.503292791720014 110.33860671277482
40 14.203197252121754 111.55240978447834
41 11.503458730920102 111.87102467515453
42 14.127283405978233 113.49209291788252
43 15.501598929520696 114.38427652291234
44 12.864753551781178 117.71453405712296
45 14.578706388594583 121.26452240374262
46 17.27726044668816 121.8148633500027
47 15.635560125578195 122.31117983367389
48 15.004908366594464 125.86136637734936
49 14.860774810047587 130.45510520660062
train accuracy: 0.8805947330199136
validation accuracy: 0.8195918367346938
demos: (520, 200, 32)
demo_rewards: (520,)
maximum traj length 200
maximum traj length 200
num train_obs 52326
num train_labels 52326
num val_obs 1326
num val_labels 1326
ModuleList(
  (0): Linear(in_features=32, out_features=256, bias=True)
  (1): Linear(in_features=256, out_features=256, bias=True)
  (2): Linear(in_features=256, out_features=256, bias=True)
  (3): Linear(in_features=256, out_features=1, bias=False)
)
Training reward model from scratch...
Total number of parameters: 140288
Number of trainable paramters: 140288
device: cuda:1
end of epoch 0: val_loss 0.33616550503825915, val_acc 0.8778280542986425
trigger times: 0
saving model weights...
end of epoch 1: val_loss 0.4124894804421237, val_acc 0.8182503770739065
trigger times: 1
end of epoch 2: val_loss 0.3587965000718008, val_acc 0.8469079939668175
trigger times: 2
end of epoch 3: val_loss 0.4339707654412105, val_acc 0.8438914027149321
trigger times: 3
end of epoch 4: val_loss 0.3712813246297804, val_acc 0.8619909502262444
trigger times: 4
end of epoch 5: val_loss 0.3517204132588608, val_acc 0.8717948717948718
trigger times: 5
end of epoch 6: val_loss 0.37473180272943485, val_acc 0.8431372549019608
trigger times: 6
end of epoch 7: val_loss 0.37922569642514337, val_acc 0.8725490196078431
trigger times: 7
end of epoch 8: val_loss 0.3864479670404624, val_acc 0.8634992458521871
trigger times: 8
end of epoch 9: val_loss 0.39843311262168685, val_acc 0.8536953242835595
trigger times: 9
end of epoch 10: val_loss 0.4157198645963505, val_acc 0.8355957767722474
trigger times: 10
Early stopping.
0 -35.16391745954752 -209.0523138369167
1 -30.58674193173647 -188.0211902974503
2 -30.470919638872147 -181.53450727998975
3 -27.75501487031579 -175.78382138582643
4 -26.119776468724012 -163.66483751290164
5 -21.37733379751444 -145.21452256945796
6 -15.764142394065857 -121.05332354775513
7 -17.4761749394238 -116.02779530304753
8 -16.550387089140713 -106.61264278156179
9 -21.375068321824074 -102.61096960201738
10 -14.593739733099937 -85.08317721801633
11 -13.596158359199762 -83.54839050364284
12 -15.460309425368905 -79.97107993883422
13 -17.458616729825735 -75.04365672708533
14 -15.802683372050524 -71.88194877193882
15 -14.328743308782578 -60.32902713650449
16 -17.0374566456303 -25.690221770027268
17 -15.828244917094707 -20.635708086354146
18 -14.22291342355311 11.612289242987064
19 -12.185119461151771 16.189721761006762
20 -13.157682247459888 29.931003861327106
21 -15.848281813785434 40.428355258377486
22 -14.842554725240916 46.20583772082509
23 -6.974995281954762 50.95779374754577
24 -14.443915278185159 58.760634987774274
25 -12.095224878750741 76.42960210286357
26 -15.207433353178203 80.48392305495419
27 -12.504513751715422 86.67905792357188
28 -16.355419661849737 93.48032634416985
29 -13.653323283419013 94.47894135375837
30 -11.961612042039633 95.38778469665249
31 -14.583185473456979 97.55210792127215
32 -14.495764750987291 102.0062792742551
33 -14.34016896598041 102.74578030549429
34 -14.481116075068712 102.88046080019838
35 -15.300807966850698 103.01364436404991
36 -12.584980055689812 103.25847199969756
37 -13.021998619893566 104.33313818327396
38 -12.334686884656549 109.83835639851611
39 -12.751304481062107 113.49209291788252
40 -11.549149438156746 113.86158089834132
41 -11.941726768389344 113.96536766392857
42 -12.341839571250603 114.38427652291234
43 -12.772723557427526 114.80695571228861
44 -10.281650643795729 117.27388896583807
45 -9.529234105721116 119.9944732564883
46 -9.518167704343796 121.17365052906995
47 -8.573385956231505 121.26452240374262
48 -9.788303053937852 121.8148633500027
49 -10.787419763859361 125.17634239385316
50 -10.106560657033697 126.39803550662174
51 -8.773413930088282 130.45510520660062
train accuracy: 0.884990253411306
validation accuracy: 0.8355957767722474
demos: (540, 200, 32)
demo_rewards: (540,)
maximum traj length 200
maximum traj length 200
num train_obs 52326
num train_labels 52326
num val_obs 1431
num val_labels 1431
ModuleList(
  (0): Linear(in_features=32, out_features=256, bias=True)
  (1): Linear(in_features=256, out_features=256, bias=True)
  (2): Linear(in_features=256, out_features=256, bias=True)
  (3): Linear(in_features=256, out_features=1, bias=False)
)
Training reward model from scratch...
Total number of parameters: 140288
Number of trainable paramters: 140288
device: cuda:3
end of epoch 0: val_loss 0.319122555373466, val_acc 0.8588399720475192
trigger times: 0
saving model weights...
end of epoch 1: val_loss 0.24237565051730642, val_acc 0.8916841369671559
trigger times: 0
saving model weights...
end of epoch 2: val_loss 0.292002747801617, val_acc 0.870020964360587
trigger times: 1
end of epoch 3: val_loss 0.30562387333523827, val_acc 0.8756114605171209
trigger times: 2
end of epoch 4: val_loss 0.28086124250192096, val_acc 0.870020964360587
trigger times: 3
end of epoch 5: val_loss 0.2807996388164681, val_acc 0.8853948287910552
trigger times: 4
end of epoch 6: val_loss 0.2934628583235031, val_acc 0.8658280922431866
trigger times: 5
end of epoch 7: val_loss 0.31939647485295813, val_acc 0.859538784067086
trigger times: 6
end of epoch 8: val_loss 0.2689517363511424, val_acc 0.8923829489867225
trigger times: 7
end of epoch 9: val_loss 0.36454260973952984, val_acc 0.8609364081062194
trigger times: 8
end of epoch 10: val_loss 0.4069132744699617, val_acc 0.8259958071278826
trigger times: 9
end of epoch 11: val_loss 0.2985091200429937, val_acc 0.8742138364779874
trigger times: 10
Early stopping.
0 5.7006118294084445 -215.9177878701233
1 1.853225403581746 -209.0523138369167
2 2.3305046874447726 -198.46439451395057
3 3.301998194423504 -171.73538080057904
4 4.741635390440933 -170.27401399351893
5 3.399409815086983 -166.08151575346506
6 2.9667290662200685 -156.23561904706384
7 6.397115153959021 -153.84889359885997
8 6.229676327202469 -151.03182509904744
9 3.800744790234603 -127.35015292881329
10 3.3510310365090845 -122.64265056439109
11 4.264207555426765 -121.62283979231374
12 12.975052271096501 -121.05332354775513
13 11.867759475950152 -114.93257529936977
14 9.439941407428705 -108.31590456875345
15 11.205877896165475 -106.61264278156179
16 7.263168988720281 -106.34887562579361
17 6.801867381902412 -96.76895908022341
18 12.220382939791307 -95.90965889467061
19 10.105723228072748 -77.66430866119553
20 13.82279134192504 -69.43095741885254
21 11.880566780106165 -67.82678910062958
22 12.294168863765663 -65.46886682985541
23 14.753616491274443 -40.18888097237036
24 14.274455264618155 -26.554830714509592
25 12.25626357307192 -1.5133315871504047
26 12.931774011463858 9.9385357692998
27 16.104888830333948 31.292646621686625
28 13.316437822999433 38.01283008215399
29 13.104346819454804 46.20583772082509
30 17.12420970131643 50.95779374754577
31 14.73294716887176 72.466227519198
32 14.801243911264464 82.1538390506234
33 12.851549151004292 84.60194958244833
34 14.940295754233375 85.90004097928022
35 14.29918396717403 86.34494544170542
36 12.4710063200273 94.17959357033311
37 15.383826899458654 95.38778469665249
38 15.242007003864273 100.17952611313399
39 14.355518264463171 101.16803939094815
40 13.267466096323915 103.01364436404991
41 15.731074944720604 103.48199115320371
42 14.969694253522903 109.72886417501778
43 14.537512182956561 110.0667525543097
44 16.44806023640558 113.86158089834132
45 16.26022388623096 113.96536766392857
46 16.46581622364465 114.38427652291234
47 17.70055690105073 114.44473746763674
48 15.77706891298294 114.64275179580558
49 15.664115634281188 116.79577177737987
50 17.03284102145699 117.71453405712296
51 18.482821309473366 121.8148633500027
52 17.509226659080014 123.06717338614516
53 16.03540505748242 125.17634239385316
train accuracy: 0.8957497228911058
validation accuracy: 0.8742138364779874
demos: (560, 200, 32)
demo_rewards: (560,)
maximum traj length 200
maximum traj length 200
num train_obs 52326
num train_labels 52326
num val_obs 1540
num val_labels 1540
ModuleList(
  (0): Linear(in_features=32, out_features=256, bias=True)
  (1): Linear(in_features=256, out_features=256, bias=True)
  (2): Linear(in_features=256, out_features=256, bias=True)
  (3): Linear(in_features=256, out_features=1, bias=False)
)
Training reward model from scratch...
Total number of parameters: 140288
Number of trainable paramters: 140288
device: cuda:1
end of epoch 0: val_loss 0.27997210519080196, val_acc 0.8896103896103896
trigger times: 0
saving model weights...
end of epoch 1: val_loss 0.3266939342761491, val_acc 0.8668831168831169
trigger times: 1
end of epoch 2: val_loss 0.2526372348399748, val_acc 0.8850649350649351
trigger times: 0
saving model weights...
end of epoch 3: val_loss 0.2656040729469141, val_acc 0.8792207792207792
trigger times: 1
end of epoch 4: val_loss 0.2615778849408127, val_acc 0.8876623376623377
trigger times: 2
end of epoch 5: val_loss 0.2841947397461428, val_acc 0.8824675324675325
trigger times: 3
end of epoch 6: val_loss 0.375042832968438, val_acc 0.8577922077922078
trigger times: 4
end of epoch 7: val_loss 0.2937604680467324, val_acc 0.8792207792207792
trigger times: 5
end of epoch 8: val_loss 0.2497097849139076, val_acc 0.8896103896103896
trigger times: 0
saving model weights...
end of epoch 9: val_loss 0.2832223994386212, val_acc 0.8857142857142857
trigger times: 1
end of epoch 10: val_loss 0.2908604586382467, val_acc 0.8837662337662338
trigger times: 2
end of epoch 11: val_loss 0.4183926259183888, val_acc 0.8415584415584415
trigger times: 3
end of epoch 12: val_loss 0.28314035683407746, val_acc 0.8766233766233766
trigger times: 4
end of epoch 13: val_loss 0.2473507246511299, val_acc 0.8863636363636364
trigger times: 0
saving model weights...
end of epoch 14: val_loss 0.3236550114010601, val_acc 0.874025974025974
trigger times: 1
end of epoch 15: val_loss 0.24582669821904654, val_acc 0.8844155844155844
trigger times: 0
saving model weights...
end of epoch 16: val_loss 0.2299324182049723, val_acc 0.8948051948051948
trigger times: 0
saving model weights...
end of epoch 17: val_loss 0.25310345380722793, val_acc 0.8863636363636364
trigger times: 1
end of epoch 18: val_loss 0.28959614674507195, val_acc 0.8746753246753247
trigger times: 2
end of epoch 19: val_loss 0.27344970772378097, val_acc 0.888961038961039
trigger times: 3
end of epoch 20: val_loss 0.2845421642352302, val_acc 0.8863636363636364
trigger times: 4
end of epoch 21: val_loss 0.25764354627207786, val_acc 0.8922077922077922
trigger times: 5
end of epoch 22: val_loss 0.2664966303412335, val_acc 0.8792207792207792
trigger times: 6
end of epoch 23: val_loss 0.2806421674982886, val_acc 0.8772727272727273
trigger times: 7
end of epoch 24: val_loss 0.26076696302061136, val_acc 0.8941558441558441
trigger times: 8
end of epoch 25: val_loss 0.2739733516543868, val_acc 0.8772727272727273
trigger times: 9
end of epoch 26: val_loss 0.2710318705119472, val_acc 0.8779220779220779
trigger times: 10
Early stopping.
0 4.507983703180798 -215.9177878701233
1 3.935364176053554 -187.3810298801045
2 3.5268264235928655 -179.96596086312886
3 4.4616481815464795 -170.27401399351893
4 2.3140235114842653 -162.65073958817794
5 6.340133735910058 -141.12462246021656
6 8.996080621145666 -132.38470480860462
7 5.527651215903461 -132.32422579815238
8 7.423710375558585 -127.35015292881329
9 6.56032207980752 -124.0045955742604
10 8.509577163495123 -120.53146571724781
11 10.373675079084933 -117.56064723209383
12 7.911761164665222 -116.03766899018919
13 5.4550471170805395 -115.94914632705371
14 8.879626838024706 -109.65811822591519
15 9.173931546043605 -108.31590456875345
16 6.1602384014986455 -107.91848650346893
17 7.611113942693919 -106.34887562579361
18 7.500308682676405 -97.4152535751459
19 9.641739785205573 -97.38983155484487
20 8.537403657566756 -93.94216077405083
21 8.035134177654982 -79.2141871082159
22 7.855836077593267 -74.34257435108044
23 11.65612981421873 -73.44850659688827
24 11.787251485046 -71.88194877193882
25 9.574118260294199 -71.35272703551989
26 10.601185468491167 -64.59517229125954
27 10.437626041471958 -57.05551066263755
28 9.13933048164472 -35.86254173038183
29 11.205116116907448 -16.36038367979373
30 11.885410921182483 11.612289242987064
31 11.717391243204474 15.578356723059361
32 12.40837147179991 31.292646621686625
33 10.280370893888175 38.01283008215399
34 12.513040761463344 82.1538390506234
35 10.890406660269946 87.7203754226118
36 10.671340798493475 91.60759786486705
37 11.891225981526077 93.17220181871483
38 14.298073551151901 97.31123430564293
39 13.929575173649937 98.94440192500335
40 11.623229733668268 100.17952611313399
41 13.009849045891315 102.88046080019838
42 12.012496523559093 106.46955912103628
43 12.899176685139537 109.78275288448633
44 15.188735053408891 113.54556399786723
45 14.722431994508952 113.86158089834132
46 14.598573637660593 114.38427652291234
47 14.429647368844599 114.44473746763674
48 13.271463537123054 114.64275179580558
49 10.752726343460381 115.70154293965129
50 15.854583139996976 116.43876967111639
51 16.208526422735304 119.9944732564883
52 15.81600614078343 121.26452240374262
53 16.587598152458668 121.8148633500027
54 13.601609017234296 123.42126221211687
55 15.055498789530247 124.618280620502
train accuracy: 0.8981003707525895
validation accuracy: 0.8779220779220779
