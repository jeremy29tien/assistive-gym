demos: (480, 200, 32)
demo_rewards: (480,)
maximum traj length 200
maximum traj length 200
num train_obs 52326
num train_labels 52326
num val_obs 1128
num val_labels 1128
ModuleList(
  (0): Linear(in_features=32, out_features=256, bias=True)
  (1): Linear(in_features=256, out_features=256, bias=True)
  (2): Linear(in_features=256, out_features=256, bias=True)
  (3): Linear(in_features=256, out_features=1, bias=False)
)
Training reward model from scratch...
Total number of parameters: 140288
Number of trainable paramters: 140288
device: cuda:1
end of epoch 0: val_loss 0.3059464836004421, val_acc 0.875
trigger times: 0
saving model weights...
end of epoch 1: val_loss 0.30689673618840413, val_acc 0.8643617021276596
trigger times: 1
end of epoch 2: val_loss 0.3137384112260754, val_acc 0.8652482269503546
trigger times: 2
end of epoch 3: val_loss 0.28772594119555667, val_acc 0.8608156028368794
trigger times: 0
saving model weights...
end of epoch 4: val_loss 0.30462423276768563, val_acc 0.8563829787234043
trigger times: 1
end of epoch 5: val_loss 1.21304309679955, val_acc 0.75177304964539
trigger times: 2
end of epoch 6: val_loss 0.3647826347961045, val_acc 0.8342198581560284
trigger times: 3
end of epoch 7: val_loss 0.30596784611996375, val_acc 0.8537234042553191
trigger times: 4
end of epoch 8: val_loss 0.40309540501038416, val_acc 0.8554964539007093
trigger times: 5
end of epoch 9: val_loss 0.3007939812200813, val_acc 0.8554964539007093
trigger times: 6
end of epoch 10: val_loss 0.35217394438830524, val_acc 0.8386524822695035
trigger times: 7
end of epoch 11: val_loss 0.42461015032514027, val_acc 0.8067375886524822
trigger times: 8
end of epoch 12: val_loss 0.5397332780532894, val_acc 0.775709219858156
trigger times: 9
end of epoch 13: val_loss 0.379571215419863, val_acc 0.8315602836879432
trigger times: 10
Early stopping.
0 -28.547567486763 -176.02327356618886
1 -26.921330139040947 -171.73538080057904
2 -32.15139275044203 -162.12021763693463
3 -22.332151506096125 -151.03182509904744
4 -23.873572077602148 -144.9053011827279
5 -21.064198788255453 -135.2361570794697
6 -19.775696251541376 -130.60907588284448
7 -18.144947255030274 -123.08440479922548
8 -19.951297838240862 -109.26967476004833
9 -23.05155099928379 -97.75429321743087
10 -16.634164134040475 -93.63303104415972
11 -14.686295121908188 -71.68281387511338
12 -14.719672294333577 -71.51650811905506
13 -17.15147888287902 -67.25891012483117
14 -15.051389761269093 -64.59517229125954
15 -20.33181127719581 -29.04983757741715
16 -14.673190599307418 -26.554830714509592
17 -17.273117134347558 7.066338713494528
18 -14.629027880728245 9.9385357692998
19 -14.399144358932972 21.358512279863625
20 -13.680811379104853 36.38260726753759
21 -13.230941228568554 51.192000963985954
22 -14.151667321100831 58.67680633739908
23 -13.134711598977447 74.36839302338853
24 -15.524598801508546 79.93047048250351
25 -15.10726236179471 89.19536109182386
26 -18.39582630060613 91.60759786486705
27 -14.707856681197882 93.17220181871483
28 -14.487747255712748 94.22803327213148
29 -11.912609184160829 96.79908925678686
30 -13.56284400075674 97.31123430564293
31 -14.270975248888135 101.37202708023295
32 -14.611350797116756 101.55104413527681
33 -14.54565929248929 102.74578030549429
34 -14.841561015695333 106.02351298384437
35 -12.984451020136476 106.45096995781903
36 -12.528309840708971 108.06711384653553
37 -13.858960043638945 109.02633758684364
38 -14.378086183220148 109.51702889237426
39 -15.267356110736728 110.37533862221531
40 -12.719848094508052 110.43094239093074
41 -12.197436705231667 110.59269304108648
42 -13.359527895227075 111.26442060476346
43 -14.328550189733505 111.55240978447834
44 -11.791082818061113 120.93165361575389
45 -11.535138674080372 125.17634239385316
46 -7.3779662027955055 129.08221841696613
47 -9.336100777611136 130.45510520660062
train accuracy: 0.8878951190612697
validation accuracy: 0.8315602836879432
demos: (500, 200, 32)
demo_rewards: (500,)
maximum traj length 200
maximum traj length 200
num train_obs 52326
num train_labels 52326
num val_obs 1225
num val_labels 1225
ModuleList(
  (0): Linear(in_features=32, out_features=256, bias=True)
  (1): Linear(in_features=256, out_features=256, bias=True)
  (2): Linear(in_features=256, out_features=256, bias=True)
  (3): Linear(in_features=256, out_features=1, bias=False)
)
Training reward model from scratch...
Total number of parameters: 140288
Number of trainable paramters: 140288
device: cuda:2
end of epoch 0: val_loss 0.4017140076337435, val_acc 0.7893877551020408
trigger times: 0
saving model weights...
end of epoch 1: val_loss 0.448925576621278, val_acc 0.7828571428571428
trigger times: 1
end of epoch 2: val_loss 0.4151942467453058, val_acc 0.8367346938775511
trigger times: 2
end of epoch 3: val_loss 0.33558704979891685, val_acc 0.8448979591836735
trigger times: 0
saving model weights...
end of epoch 4: val_loss 0.3596813209393674, val_acc 0.8424489795918367
trigger times: 1
end of epoch 5: val_loss 0.3323823067506995, val_acc 0.8497959183673469
trigger times: 0
saving model weights...
end of epoch 6: val_loss 0.3440088206046749, val_acc 0.8383673469387755
trigger times: 1
end of epoch 7: val_loss 0.37017967212230984, val_acc 0.8293877551020408
trigger times: 2
end of epoch 8: val_loss 0.39708421060453886, val_acc 0.8359183673469388
trigger times: 3
end of epoch 9: val_loss 0.3499262651051275, val_acc 0.846530612244898
trigger times: 4
end of epoch 10: val_loss 0.5566222637877234, val_acc 0.7942857142857143
trigger times: 5
end of epoch 11: val_loss 0.38502187185284675, val_acc 0.8244897959183674
trigger times: 6
end of epoch 12: val_loss 0.30748257756593833, val_acc 0.846530612244898
trigger times: 0
saving model weights...
end of epoch 13: val_loss 0.3716110717176259, val_acc 0.8285714285714286
trigger times: 1
end of epoch 14: val_loss 0.351402787429169, val_acc 0.8212244897959183
trigger times: 2
end of epoch 15: val_loss 0.302604399855341, val_acc 0.8538775510204082
trigger times: 0
saving model weights...
end of epoch 16: val_loss 0.3282644823782093, val_acc 0.8448979591836735
trigger times: 1
end of epoch 17: val_loss 0.32441771547795556, val_acc 0.846530612244898
trigger times: 2
end of epoch 18: val_loss 0.35565014473896533, val_acc 0.8351020408163266
trigger times: 3
end of epoch 19: val_loss 0.3410881062091661, val_acc 0.8269387755102041
trigger times: 4
end of epoch 20: val_loss 0.33762064122599983, val_acc 0.8440816326530612
trigger times: 5
end of epoch 21: val_loss 0.720891809776875, val_acc 0.7297959183673469
trigger times: 6
end of epoch 22: val_loss 0.36462825594718756, val_acc 0.8220408163265306
trigger times: 7
end of epoch 23: val_loss 0.33959035147569316, val_acc 0.8318367346938775
trigger times: 8
end of epoch 24: val_loss 0.33836728666966104, val_acc 0.856326530612245
trigger times: 9
end of epoch 25: val_loss 0.3374510328812322, val_acc 0.8497959183673469
trigger times: 10
Early stopping.
0 -2.0970357446931303 -220.94363941938857
1 -0.5522481994703412 -202.5149138997368
2 6.326754610054195 -168.43007377260267
3 5.503447389230132 -163.18847100689678
4 9.926799439359456 -159.37437700843304
5 10.507833586074412 -141.59020190812006
6 10.433121256530285 -139.8598026529788
7 10.859430086798966 -135.2361570794697
8 11.354323418810964 -130.60907588284448
9 10.517313511110842 -126.24611896152201
10 7.826067851856351 -124.0045955742604
11 13.769420978613198 -92.47165833788436
12 12.203755598398857 -75.04365672708533
13 14.787865135702305 -73.44850659688827
14 13.054245124105364 -67.25891012483117
15 15.885051134042442 -62.35581204175748
16 13.886014951393008 -58.66155314643179
17 12.494480568915606 -21.866164696575467
18 15.88523132679984 -1.5133315871504047
19 15.238914865069091 -1.499346687638555
20 17.91491832397878 16.189721761006762
21 15.146250650752336 21.358512279863625
22 16.117502986919135 51.192000963985954
23 16.81877585593611 58.760634987774274
24 14.515161603223532 66.71193243213483
25 17.374275598675013 74.10202095135847
26 15.901211784221232 79.93047048250351
27 15.663371852599084 80.48392305495419
28 16.260013761930168 82.1538390506234
29 16.1396551723592 85.90004097928022
30 13.693390736822039 89.11303835091482
31 14.334279238246381 93.48032634416985
32 15.256568004842848 94.22803327213148
33 20.26510148961097 96.79908925678686
34 17.60778673645109 97.31123430564293
35 16.628084145486355 100.67397449441083
36 16.530243707820773 101.37202708023295
37 16.609858038835227 101.55104413527681
38 16.05619366420433 102.74578030549429
39 16.57059890497476 104.33313818327396
40 18.1070973649621 106.45096995781903
41 15.476006434299052 106.71043949985365
42 17.50133292656392 106.99096041080111
43 17.426168034784496 109.72886417501778
44 15.92445938102901 110.37533862221531
45 18.128452663309872 111.26442060476346
46 18.52341261319816 114.38427652291234
47 17.64835188165307 114.64275179580558
48 22.683510311879218 129.08221841696613
49 20.680961882695556 129.28378585959993
train accuracy: 0.8952337270190728
validation accuracy: 0.8497959183673469
demos: (520, 200, 32)
demo_rewards: (520,)
maximum traj length 200
maximum traj length 200
num train_obs 52326
num train_labels 52326
num val_obs 1326
num val_labels 1326
ModuleList(
  (0): Linear(in_features=32, out_features=256, bias=True)
  (1): Linear(in_features=256, out_features=256, bias=True)
  (2): Linear(in_features=256, out_features=256, bias=True)
  (3): Linear(in_features=256, out_features=1, bias=False)
)
Training reward model from scratch...
Total number of parameters: 140288
Number of trainable paramters: 140288
device: cuda:0
end of epoch 0: val_loss 0.30697555629939727, val_acc 0.8627450980392157
trigger times: 0
saving model weights...
end of epoch 1: val_loss 0.39033660853818924, val_acc 0.834841628959276
trigger times: 1
end of epoch 2: val_loss 0.34150582745000235, val_acc 0.832579185520362
trigger times: 2
end of epoch 3: val_loss 0.33472826228225255, val_acc 0.8423831070889894
trigger times: 3
end of epoch 4: val_loss 0.3327197269591847, val_acc 0.8431372549019608
trigger times: 4
end of epoch 5: val_loss 0.3116181727614267, val_acc 0.8559577677224736
trigger times: 5
end of epoch 6: val_loss 0.418212577790554, val_acc 0.8378582202111614
trigger times: 6
end of epoch 7: val_loss 0.30916741598720066, val_acc 0.8552036199095022
trigger times: 7
end of epoch 8: val_loss 0.33931044337353944, val_acc 0.8461538461538461
trigger times: 8
end of epoch 9: val_loss 0.3605672592389971, val_acc 0.8461538461538461
trigger times: 9
end of epoch 10: val_loss 0.3152833839662693, val_acc 0.8529411764705882
trigger times: 10
Early stopping.
0 -34.17674495279789 -233.39052435935884
1 -18.521892242133617 -187.3810298801045
2 -27.46742982789874 -174.7728735710907
3 -15.064189683645964 -171.05558932195746
4 -16.235660649836063 -166.39808272925822
5 -20.488070905208588 -162.12021763693463
6 -19.12795015797019 -157.8694620479787
7 -12.019292932003736 -146.8781492057455
8 -14.643080297857523 -141.9431791637346
9 -12.10641213413328 -135.2361570794697
10 -17.368699193000793 -132.32422579815238
11 -11.74748595431447 -106.34887562579361
12 -14.160321325995028 -97.75429321743087
13 -9.308842307887971 -84.82931859673268
14 -8.262694532051682 -81.40156491068564
15 -9.726085435599089 -74.7548860746456
16 -9.983202517032623 -67.74773304489165
17 -9.011425929144025 -63.12953812377558
18 -8.732739517465234 -27.163007141656234
19 -11.443269313313067 -21.866164696575467
20 -8.365530604496598 -21.125938826482816
21 -9.026423200033605 -20.26340482048243
22 -8.405432398431003 21.358512279863625
23 -6.915438668802381 59.17479313249983
24 -7.946399540640414 64.65376957054497
25 -7.290905602276325 74.36839302338853
26 -8.375122714787722 82.1538390506234
27 -10.079339590854943 83.75426276407146
28 -9.32732678949833 89.11303835091482
29 -8.43102018814534 94.76241717705837
30 -6.087852390483022 96.79908925678686
31 -7.071829452179372 101.37202708023295
32 -8.070483741350472 102.99533879005212
33 -7.67715114261955 103.56706221635987
34 -8.601026973687112 103.71083627769976
35 -6.446829424239695 106.45096995781903
36 -8.32696642074734 106.71043949985365
37 -6.6130873607471585 108.06711384653553
38 -7.509469600394368 108.98656220301545
39 -7.121999515220523 109.61609834854033
40 -7.560157013125718 109.72886417501778
41 -7.693737634457648 109.83835639851611
42 -8.317889080382884 110.37533862221531
43 -6.7845102567225695 111.26442060476346
44 -7.6422279588878155 111.55240978447834
45 -5.981148456223309 113.54556399786723
46 -6.74010588042438 113.6079710956805
47 -7.457030187360942 114.66425172742227
48 -7.523566181771457 114.7831290214751
49 -5.2893929071724415 125.71615511762498
50 -4.476136316545308 129.08221841696613
51 -5.4789205975830555 130.45510520660062
train accuracy: 0.8959026105568934
validation accuracy: 0.8529411764705882
demos: (540, 200, 32)
demo_rewards: (540,)
maximum traj length 200
maximum traj length 200
num train_obs 52326
num train_labels 52326
num val_obs 1431
num val_labels 1431
ModuleList(
  (0): Linear(in_features=32, out_features=256, bias=True)
  (1): Linear(in_features=256, out_features=256, bias=True)
  (2): Linear(in_features=256, out_features=256, bias=True)
  (3): Linear(in_features=256, out_features=1, bias=False)
)
Training reward model from scratch...
Total number of parameters: 140288
Number of trainable paramters: 140288
device: cuda:3
end of epoch 0: val_loss 0.2825801588930503, val_acc 0.8749126484975541
trigger times: 0
saving model weights...
end of epoch 1: val_loss 0.3188540477589432, val_acc 0.8714185883997205
trigger times: 1
end of epoch 2: val_loss 0.298805653606672, val_acc 0.8721174004192872
trigger times: 2
end of epoch 3: val_loss 0.2985684594224576, val_acc 0.8630328441649197
trigger times: 3
end of epoch 4: val_loss 0.27300348992893264, val_acc 0.8763102725366876
trigger times: 0
saving model weights...
end of epoch 5: val_loss 0.3546492513116864, val_acc 0.8497554157931516
trigger times: 1
end of epoch 6: val_loss 0.30712462357749887, val_acc 0.8679245283018868
trigger times: 2
end of epoch 7: val_loss 0.2978495682326568, val_acc 0.8770090845562544
trigger times: 3
end of epoch 8: val_loss 0.31586991156920863, val_acc 0.8679245283018868
trigger times: 4
end of epoch 9: val_loss 0.3094211602345075, val_acc 0.8644304682040531
trigger times: 5
end of epoch 10: val_loss 0.2913122638079474, val_acc 0.8819007686932215
trigger times: 6
end of epoch 11: val_loss 0.2933175408861707, val_acc 0.8707197763801537
trigger times: 7
end of epoch 12: val_loss 0.3241313029571462, val_acc 0.8707197763801537
trigger times: 8
end of epoch 13: val_loss 0.30188233301123457, val_acc 0.8581411600279525
trigger times: 9
end of epoch 14: val_loss 0.34265981848085675, val_acc 0.8665269042627534
trigger times: 10
Early stopping.
0 9.809920235420577 -199.04068934105942
1 9.933687707060017 -198.62548151512715
2 10.648563233204186 -187.3810298801045
3 11.660771682159975 -182.7652293135204
4 13.245352856814861 -158.98604846130755
5 12.222300490364432 -157.58076401159747
6 12.833373085333733 -156.8354163242861
7 14.473428592085838 -153.84889359885997
8 16.241011974401772 -151.03182509904744
9 15.105219148099422 -136.9016903684411
10 16.92381682433188 -135.2361570794697
11 12.866028688848019 -132.32422579815238
12 16.50866707600653 -126.24611896152201
13 16.884443237097003 -123.08440479922548
14 19.18451460264623 -117.56064723209383
15 14.192846497520804 -112.7349225355363
16 16.66854365170002 -112.5340343753957
17 20.90750604495406 -92.47165833788436
18 20.684591693338007 -87.12595597627949
19 20.194345893338323 -83.05652638750908
20 22.256279348395765 -82.06170790121502
21 18.960955689661205 -78.17493251279159
22 22.80141937918961 -71.51650811905506
23 18.423536108341068 -71.30942871215316
24 19.888335486873984 -63.12953812377558
25 20.620114692486823 -55.691908261159085
26 21.921977222897112 9.9385357692998
27 20.95079238852486 38.01283008215399
28 23.085778693668544 51.192000963985954
29 24.288092559203506 74.10202095135847
30 21.2818440390256 74.77278251853146
31 21.59309269860387 80.74193671363145
32 20.43635320290923 86.97513535448299
33 20.490007660351694 89.11303835091482
34 24.02280326001346 89.2284220839693
35 20.883915756829083 92.98206675203036
36 29.42157019628212 96.79908925678686
37 24.66293545300141 99.34558404579464
38 22.214316153898835 99.85173738001097
39 22.921300754882395 101.55104413527681
40 23.26704555284232 102.74578030549429
41 23.154120044317096 102.88046080019838
42 22.86153330653906 102.99533879005212
43 22.96662870515138 106.02351298384437
44 25.987086810171604 106.45096995781903
45 26.35562054440379 108.06711384653553
46 22.60257390514016 108.98656220301545
47 25.814646771759726 109.61609834854033
48 23.486242132261395 109.83835639851611
49 26.889360891655087 111.26442060476346
50 20.09824337484315 113.7695856377133
51 26.929648322984576 115.18026432441671
52 28.420143466442823 125.71615511762498
53 26.531994942575693 126.25468464473899
train accuracy: 0.9075411841149715
validation accuracy: 0.8665269042627534
demos: (560, 200, 32)
demo_rewards: (560,)
maximum traj length 200
maximum traj length 200
num train_obs 52326
num train_labels 52326
num val_obs 1540
num val_labels 1540
ModuleList(
  (0): Linear(in_features=32, out_features=256, bias=True)
  (1): Linear(in_features=256, out_features=256, bias=True)
  (2): Linear(in_features=256, out_features=256, bias=True)
  (3): Linear(in_features=256, out_features=1, bias=False)
)
Training reward model from scratch...
Total number of parameters: 140288
Number of trainable paramters: 140288
device: cuda:1
end of epoch 0: val_loss 0.3819892476293231, val_acc 0.8448051948051948
trigger times: 0
saving model weights...
end of epoch 1: val_loss 0.3541427299174695, val_acc 0.8532467532467533
trigger times: 0
saving model weights...
end of epoch 2: val_loss 0.34368295447631503, val_acc 0.8525974025974026
trigger times: 0
saving model weights...
end of epoch 3: val_loss 0.35743825021017334, val_acc 0.8538961038961039
trigger times: 1
end of epoch 4: val_loss 0.3083895052301607, val_acc 0.8597402597402597
trigger times: 0
saving model weights...
end of epoch 5: val_loss 0.5820736794783167, val_acc 0.8441558441558441
trigger times: 1
end of epoch 6: val_loss 0.4830126137706794, val_acc 0.824025974025974
trigger times: 2
end of epoch 7: val_loss 0.3580547131356109, val_acc 0.8487012987012987
trigger times: 3
end of epoch 8: val_loss 0.37828870206077186, val_acc 0.8311688311688312
trigger times: 4
end of epoch 9: val_loss 0.4557399528389344, val_acc 0.8357142857142857
trigger times: 5
end of epoch 10: val_loss 0.32145589260881285, val_acc 0.8668831168831169
trigger times: 6
end of epoch 11: val_loss 0.4994524819933617, val_acc 0.8272727272727273
trigger times: 7
end of epoch 12: val_loss 0.36779390535161344, val_acc 0.8512987012987013
trigger times: 8
end of epoch 13: val_loss 0.3729863784977675, val_acc 0.8571428571428571
trigger times: 9
end of epoch 14: val_loss 0.38632565831566557, val_acc 0.8376623376623377
trigger times: 10
Early stopping.
0 5.894080451359514 -238.6878600498492
1 6.3816310302372585 -227.77288902195497
2 6.504684347074544 -226.40696217683256
3 9.470003647729754 -199.04068934105942
4 17.65363996475935 -179.96596086312886
5 20.08032289147377 -169.72756641465017
6 17.91585074365139 -162.12021763693463
7 21.361393593251705 -156.23561904706384
8 19.7046035528183 -145.2677371393297
9 25.76259259134531 -141.9431791637346
10 22.161102443933487 -126.24611896152201
11 21.00651003420353 -112.07323177973771
12 22.504912227392197 -97.75429321743087
13 22.14576307311654 -91.35273754274259
14 25.480918284505606 -88.94899174825389
15 25.172277808189392 -83.05652638750908
16 26.54534525424242 -76.64970632397707
17 24.474409818649292 -75.3326203441267
18 27.338991470634937 -74.7548860746456
19 22.144615718862042 -71.30942871215316
20 27.43126881867647 -62.35581204175748
21 28.2968687787652 -40.18888097237036
22 27.646818906068802 -33.43344103627959
23 23.739134665578604 -27.163007141656234
24 27.197202153503895 -26.554830714509592
25 28.05696264654398 16.189721761006762
26 27.398835979402065 66.21591564279122
27 26.78094471246004 79.93047048250351
28 26.651285969710443 84.60194958244833
29 28.882533200085163 86.34494544170542
30 28.196227978914976 94.22803327213148
31 27.015728153288364 94.76241717705837
32 32.21482752158772 96.79908925678686
33 25.450010803611804 98.9107936738028
34 28.872953810263425 99.34558404579464
35 28.607695288956165 100.67397449441083
36 26.308774476870894 102.99533879005212
37 29.229288578033447 103.25847199969756
38 27.833654587622732 105.39484207290671
39 29.865932626649737 106.99096041080111
40 28.91471628844738 108.19351028466765
41 29.87544341571629 108.21752728269145
42 28.119244336674456 108.98656220301545
43 28.18424878269434 109.02633758684364
44 29.94551597069949 109.61609834854033
45 27.37715332955122 110.0667525543097
46 29.10334850102663 111.20504336739191
47 30.29173604771495 111.26442060476346
48 30.885070013348013 113.54556399786723
49 26.347434744238853 113.7695856377133
50 30.918231412768364 115.18026432441671
51 25.938887983560562 115.70154293965129
52 28.297630794346333 116.79577177737987
53 30.836724665539805 119.9944732564883
54 30.56757709546946 129.08221841696613
55 31.65396261587739 129.28378585959993
train accuracy: 0.8943546229407943
validation accuracy: 0.8376623376623377
