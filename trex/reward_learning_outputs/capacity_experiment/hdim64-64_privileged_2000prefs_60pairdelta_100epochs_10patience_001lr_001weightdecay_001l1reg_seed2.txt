demo lengths 200
demos: (120, 200, 3)
demo_rewards: (120,)
[-191.10004521 -189.05007017 -187.50220085 -180.24009179 -171.96137924
 -169.38170168 -167.87631268 -164.27567046 -163.76742237 -156.07868959
 -155.22804552 -145.29002069 -142.8665728  -142.75441848 -136.98962801
 -132.4813577  -130.98347157 -118.24362226 -117.38411415 -116.97382686
 -115.06704102 -112.47832646 -103.24187681  -99.7422753   -98.18526662
  -88.94674758  -85.88346862  -79.38307722  -79.25112655  -73.50697856
  -72.69803192  -71.37326168  -68.27187815  -65.42298163  -65.35816021
  -49.31867416  -17.32544162   -4.37451128   -0.4258659     9.10814675
   17.73263018   40.64550157   41.11774839   48.64917674   52.5026004
   52.54502853   59.52827492   63.45606317   66.31570759   67.13050508
   72.16624272   79.16074532   84.19837606   89.30707154   90.26988507
   90.28646232   90.32667007   91.18021498   92.38187518   92.67153902
   93.69474939   93.8611286    95.24073533   95.36301018   96.09581961
   97.90553231   98.07644231   98.35872828   98.5733471    98.77895391
   99.10163704   99.47183808  101.36707045  102.70820969  103.61971442
  104.00039884  104.94014609  105.28448326  105.60678193  106.95774051
  107.03525723  107.05410486  107.36477417  107.72369032  107.78006758
  107.99397436  108.08910889  108.09776529  108.24033507  109.15712102
  109.71287331  110.25063891  110.45880856  110.48639228  111.92877272
  112.2946742   112.73910566  112.98274531  113.8461648   114.8461224
  115.08707834  115.41025719  115.56466246  115.87882503  116.51927592
  116.69939038  117.18809855  117.29357602  117.43241924  119.84073496
  122.74776107  124.10172315  124.42382576  124.4817957   125.25908938
  125.30457668  125.43458549  129.13346806  129.67718524  131.40806577]
maximum traj length 200
num training_obs 1800
num training_labels 1800
num val_obs 200
num val_labels 200
ModuleList(
  (0): Linear(in_features=3, out_features=64, bias=True)
  (1): Linear(in_features=64, out_features=64, bias=True)
  (2): Linear(in_features=64, out_features=1, bias=False)
)
device: cuda:0
end of epoch 0: val_loss 0.004563416931245179, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-7.8438e-06,  1.4257e-04,  7.6402e-04],
        [-4.9111e-04, -1.4786e-03,  1.0680e-03],
        [ 2.5405e-03, -6.8361e-04, -4.9577e-04],
        [ 8.4866e-04,  8.7087e-04, -2.3610e-04],
        [ 1.4452e-03, -1.3516e-03,  7.7665e-04],
        [-4.1584e-04, -4.5468e-04,  4.3228e-04],
        [-5.3020e-05,  1.8354e-04, -4.7595e-04],
        [-5.9773e-04, -8.5183e-04,  1.3385e-03],
        [-9.3584e-04,  6.7107e-04,  1.1873e-03],
        [-1.2863e-03, -2.5109e-04, -2.5497e-03],
        [ 1.3186e-03, -9.2799e-04, -1.9733e-03],
        [-1.6337e-03,  1.1604e-03, -6.2109e-04],
        [-2.2247e-04,  6.2324e-04,  1.0677e-03],
        [ 1.0433e-04, -3.9210e-04, -1.0865e-03],
        [-1.0327e-03,  5.2822e-04, -1.8817e-03],
        [-8.8914e-04,  6.3701e-04, -4.9199e-04],
        [ 7.7129e-04, -1.8609e-03,  1.8015e-03],
        [-6.4185e-04, -8.8585e-04,  1.1641e-04],
        [ 4.3914e-04, -3.8418e-03, -1.0988e-03],
        [ 2.0540e-04,  2.2116e-04, -2.1379e-04],
        [-9.4110e-04,  8.4784e-04, -1.0864e-03],
        [ 2.2792e-04, -7.4502e-04, -1.1573e-03],
        [-3.3133e-04, -4.1960e-04,  7.1485e-04],
        [ 2.6084e-04,  1.4709e-04, -1.6343e-03],
        [ 1.0832e-04, -9.7870e-05, -6.7099e-04],
        [ 3.5940e-04, -9.0395e-04,  8.8255e-05],
        [-1.0985e-04, -1.6810e-03,  2.3040e-03],
        [ 3.7129e-04, -1.5619e-04, -2.1122e-03],
        [-4.5122e-04, -1.4011e-03, -1.2658e-03],
        [-5.9134e-04,  1.4437e-03,  8.1528e-04],
        [ 7.5811e-04, -1.7501e-03,  4.7159e-04],
        [-5.3191e-04, -6.9239e-04, -9.9608e-07],
        [ 5.3147e-04,  7.3424e-04, -6.4968e-04],
        [ 9.6566e-04, -2.8244e-03, -1.3357e-03],
        [-1.4853e-04, -5.9104e-04,  4.9519e-04],
        [ 9.6440e-05,  6.0523e-04,  2.0602e-03],
        [-6.5206e-04,  1.1124e-03,  5.5806e-04],
        [ 1.5365e-04,  1.6961e-03, -2.4081e-04],
        [ 1.2282e-03, -2.0685e-03, -1.3591e-03],
        [ 1.4984e-03, -1.0263e-03, -6.2011e-04],
        [ 1.6631e-04, -8.8518e-05, -1.7329e-05],
        [-2.0831e-03,  5.6197e-04,  1.1542e-03],
        [-1.2028e-03, -2.1855e-03,  6.2338e-04],
        [ 1.2650e-03, -1.5696e-03, -6.5190e-04],
        [ 1.3991e-03, -1.1008e-04, -2.1438e-03],
        [-1.3533e-03, -8.5072e-04,  3.1646e-04],
        [ 2.4581e-04,  3.4033e-04,  8.6795e-04],
        [-1.5308e-03,  4.8631e-04,  5.6891e-04],
        [-2.7411e-03, -7.0476e-04,  9.4098e-04],
        [ 1.2619e-03,  1.3207e-03, -1.1779e-03],
        [-6.9694e-04, -7.0821e-04, -6.7276e-04],
        [-9.4197e-04,  8.6454e-05, -4.8216e-04],
        [-4.1797e-01,  6.1280e-01, -1.3076e-01],
        [ 6.2496e-04,  7.5665e-04, -5.8632e-04],
        [-3.5451e-04, -1.3965e-03,  7.0183e-04],
        [ 8.1047e-04,  3.1120e-04,  5.2278e-04],
        [ 3.0004e-05,  6.2154e-04, -2.6397e-03],
        [-7.7765e-04, -1.6500e-03, -7.4257e-04],
        [-2.1203e-04,  5.1408e-04, -2.8788e-04],
        [-8.7921e-04, -1.6133e-03, -1.2647e-03],
        [ 6.5284e-04, -1.5665e-04, -1.3260e-03],
        [ 1.4711e-03, -2.3909e-04, -9.5790e-04],
        [ 8.6387e-04, -2.6580e-03,  7.6830e-04],
        [ 1.3834e-04, -6.1869e-04, -7.2479e-04]], device='cuda:0')), ('fcs.0.bias', tensor([ 1.1032e-04,  4.5931e-05,  2.9907e-04, -2.2725e-03, -2.1067e-04,
        -2.0848e-03,  1.8182e-03,  2.1395e-04, -3.4520e-03, -6.7753e-04,
        -3.8745e-04, -1.4016e-03, -8.6969e-05, -8.4448e-04,  7.5262e-04,
        -6.1354e-04,  4.5830e-04, -4.4959e-04,  2.0240e-03, -1.3193e-04,
        -4.0444e-04,  1.2921e-03,  1.9153e-03,  1.5244e-03, -4.7470e-04,
        -1.3856e-03, -9.7111e-04, -1.3123e-03, -8.3793e-04, -1.2805e-03,
        -1.0727e-03, -8.1300e-04,  1.8198e-03, -1.0499e-03, -1.6230e-03,
        -1.0185e-03,  2.7821e-04, -2.2245e-03,  9.0685e-04,  1.0411e-04,
        -9.0392e-04, -1.4957e-03, -1.7112e-03,  1.0428e-03, -1.4377e-03,
        -1.5400e-03, -6.0259e-05, -1.6489e-03, -9.6478e-04,  7.6225e-04,
        -1.7193e-03, -1.7162e-03,  2.4214e-01, -9.7529e-04,  7.1519e-07,
        -1.8493e-04,  5.0468e-04,  1.1953e-03, -1.8981e-03,  1.5209e-03,
        -1.8227e-03,  2.7848e-03, -6.0550e-04, -7.0926e-04], device='cuda:0')), ('fcs.1.weight', tensor([[ 2.6480e-04, -5.9360e-04,  1.6395e-03,  ...,  1.3043e-03,
          2.5713e-03, -1.1519e-03],
        [ 9.5770e-05,  3.4827e-04,  1.3039e-03,  ...,  1.3039e-03,
         -1.3042e-03, -1.5413e-04],
        [-7.8535e-05, -3.0920e-04, -1.3041e-03,  ...,  4.9699e-04,
          1.9540e-03,  2.3186e-03],
        ...,
        [ 3.5789e-04, -1.2574e-03, -1.9644e-03,  ..., -1.2621e-03,
          5.1346e-05, -1.5778e-04],
        [ 4.6051e-04,  1.3113e-03,  2.2783e-04,  ..., -2.4670e-03,
         -3.1457e-03, -1.3048e-03],
        [ 7.2530e-04, -2.1285e-03, -2.2205e-03,  ...,  1.4388e-03,
         -1.7607e-03,  7.3973e-04]], device='cuda:0')), ('fcs.1.bias', tensor([ 6.9747e-04, -1.7290e-04,  1.8351e-03,  3.4171e-04, -6.0837e-04,
        -1.0546e-03, -1.1235e-03, -9.1236e-04,  4.7576e-04, -1.3948e-04,
        -5.9867e-04, -7.5841e-04, -1.2144e-03, -3.2766e-04,  2.9334e-04,
        -9.9185e-05,  1.1959e-03, -1.5503e-07, -6.4793e-04,  7.7066e-04,
         3.1993e-03, -1.1924e-05,  1.8307e-03,  1.0727e-03, -2.3628e-03,
        -7.8715e-04, -3.2275e-04,  8.4096e-04, -3.0051e-04,  2.1230e-03,
         2.0069e-03, -1.1150e-03, -5.1225e-04, -9.9595e-04,  9.9672e-04,
        -1.0410e-03, -9.0349e-04, -1.4456e-03,  4.7071e-04,  1.3702e-03,
         1.2035e-04,  9.9164e-04, -2.8700e-06, -3.7547e-04,  1.1938e-05,
         1.1478e-03, -2.2242e-04,  6.1445e-04,  1.2723e-03, -7.2140e-04,
        -5.5484e-05, -1.7153e-03,  1.4890e-03, -1.5215e-03, -6.4081e-04,
        -1.3612e-03, -1.3045e-03,  2.2607e-03, -4.8243e-04,  1.5757e-03,
        -6.7942e-04, -1.5509e-04, -6.0414e-04, -1.2738e-04], device='cuda:0')), ('fcs.2.weight', tensor([[ 5.6432e-06,  3.6285e-04, -4.0297e-04, -4.8306e-04,  4.7280e-05,
         -3.4546e-04,  5.6316e-04,  1.1245e-03,  3.5341e-05,  3.0721e-05,
          2.2957e-03,  1.3916e-03,  9.2037e-04, -4.2741e-04, -8.6293e-05,
          1.1128e-03,  1.7301e-04, -7.7997e-04, -5.6556e-04, -2.2130e-04,
         -1.6256e-03, -5.8284e-04,  1.1248e-04, -7.2317e-04,  9.3495e-04,
         -1.3914e-04,  9.4205e-04,  2.6705e-04,  2.4064e-04, -8.0556e-05,
         -1.9397e-04,  5.8609e-04, -5.7533e-05, -2.5286e-03, -2.4143e-04,
          4.6393e-05, -2.5835e-03, -6.9585e-05,  3.3701e-04,  5.6804e-04,
         -1.9248e-04, -9.5591e-04,  1.5973e-03, -2.6386e-04, -4.7030e-04,
          2.6064e-03,  5.0773e-05, -3.2832e-04, -1.1804e-03, -2.9490e-05,
         -9.1055e-04,  3.3365e-04, -4.1901e-04,  1.5983e-03, -4.6198e-04,
          2.3038e-03, -4.9050e-04,  1.3591e-03, -4.3470e-04, -4.7875e-04,
         -1.6237e-04, -3.0555e-04,  1.2152e-03,  9.3354e-01]], device='cuda:0'))])
end of epoch 1: val_loss 0.0055066177760913606, val_acc 1.0
trigger times: 1
end of epoch 2: val_loss 0.009479787676485963, val_acc 0.995
trigger times: 2
end of epoch 3: val_loss 0.008263352838286053, val_acc 0.995
trigger times: 3
end of epoch 4: val_loss 0.009922286281559138, val_acc 1.0
trigger times: 4
end of epoch 5: val_loss 0.01088858324799329, val_acc 0.995
trigger times: 5
end of epoch 6: val_loss 0.009111748168928919, val_acc 1.0
trigger times: 6
end of epoch 7: val_loss 0.006978816063537749, val_acc 0.995
trigger times: 7
end of epoch 8: val_loss 0.007990250757404916, val_acc 0.995
trigger times: 8
end of epoch 9: val_loss 0.00888313024786516, val_acc 0.995
trigger times: 9
end of epoch 10: val_loss 0.0055486016048836365, val_acc 1.0
trigger times: 10
Early stopping.
0 6.224407722309479 -191.10004520678868
1 6.539979301261155 -189.05007017278314
2 6.053119284050695 -187.50220085194994
3 8.83191905250078 -180.24009179391223
4 10.738630639683834 -171.9613792356186
5 11.336486549193069 -169.3817016847894
6 11.544682834477499 -167.87631268052303
7 6.976000530939018 -164.27567046290412
8 8.813475852664396 -163.76742236654098
9 14.543410750754447 -156.0786895876365
10 12.170915141533442 -155.22804551507866
11 12.210639499266108 -145.29002069283715
12 11.715078593148974 -142.86657280197298
13 18.39193791210255 -142.75441848091938
14 17.28186885704963 -136.98962801176134
15 12.939656294543965 -132.4813576990395
16 19.276820860665794 -130.98347157271724
17 14.200150687247515 -118.2436222554584
18 22.3471168028791 -117.38411415155902
19 14.562586256910777 -116.97382686219106
20 20.67377377444518 -115.06704102317899
21 24.95192751914874 -112.47832645551227
22 17.63958464562893 -103.24187681049156
23 25.8555144588272 -99.7422752992134
24 29.15957323089242 -98.18526661663928
25 26.124327265191823 -88.94674758091466
26 29.268468376937562 -85.88346861832474
27 31.44952591136098 -79.38307722218848
28 30.096518171951175 -79.25112655387144
29 24.154747377662716 -73.50697855948762
30 25.280274108052254 -72.69803191552006
31 29.503387650438526 -71.37326168319514
32 27.277321748435497 -68.27187815304366
33 28.285790894180536 -65.42298162776466
34 29.778587482869625 -65.35816021006309
35 31.023887388408184 -49.3186741604369
36 22.33512747194618 -17.325441617065966
37 31.674827647966595 -4.374511275254108
38 30.816373884064888 -0.4258658969524013
39 27.961833093315363 9.108146753357724
40 28.774207685142756 17.732630180500013
41 35.57262208978318 40.64550156746333
42 35.14728215665127 41.11774838972275
43 31.286867987550977 48.64917674484657
44 33.87352616339922 52.50260039838799
45 34.02528964355588 52.54502852695255
46 34.57421127829093 59.52827491841281
47 35.080873479135334 63.45606316769021
48 36.27814027102431 66.31570758515764
49 29.918315246140082 67.13050507695384
50 37.854374542832375 72.16624272108386
51 29.418413430452347 79.16074531670823
52 31.54169062525034 84.19837606184075
53 31.52901814877987 89.30707154325768
54 31.498609744012356 90.2698850730257
55 32.21154648438096 90.28646231697512
56 35.86509957164526 90.32667007477052
57 37.76804459095001 91.18021498086692
58 36.62472505494952 92.38187517969644
59 31.737423084676266 92.67153902025292
60 31.941223688423634 93.69474938898811
61 36.737711761146784 93.86112859581364
62 32.592187605798244 95.24073532592021
63 32.555988386273384 95.3630101766082
64 32.915731474757195 96.09581961281374
65 34.0240668207407 97.90553231413178
66 33.19382306933403 98.07644230926206
67 33.53880485147238 98.35872828331676
68 32.60656900703907 98.57334710000995
69 33.275991559028625 98.77895390936838
70 32.991756334900856 99.10163703819775
71 33.36151543259621 99.47183807834362
72 33.498346239328384 101.36707045382526
73 33.85458233207464 102.70820969163083
74 33.56625684350729 103.61971441966246
75 34.39281639456749 104.00039883786899
76 34.431710720062256 104.94014608739957
77 33.74968744814396 105.28448326377394
78 34.83879931271076 105.60678192821229
79 35.678686790168285 106.95774051225432
80 34.53226996213198 107.03525723063939
81 35.09072748571634 107.05410485829283
82 36.05100453644991 107.36477417456501
83 35.90742590278387 107.72369032284489
84 34.324677132070065 107.78006757763964
85 34.65968392044306 107.99397435655325
86 35.35894425213337 108.08910889221833
87 34.706203751266 108.09776529440465
88 35.817120887339115 108.24033506535473
89 35.701859600842 109.15712102315346
90 35.38970312476158 109.71287331230647
91 35.54654632508755 110.25063890779474
92 35.70589737594128 110.45880856467717
93 36.29259976744652 110.48639228144049
94 35.92431249469519 111.92877271779909
95 35.83003284782171 112.29467419620224
96 36.07973854243755 112.73910566375015
97 36.26760973781347 112.98274531176438
98 36.48298431187868 113.84616479719523
99 37.84331767261028 114.84612239587612
100 36.00808294117451 115.08707834021696
101 37.62592230737209 115.41025719446112
102 37.27935203909874 115.5646624637931
103 37.51071202009916 115.87882502857741
104 36.51642211526632 116.51927592390606
105 36.32064714282751 116.69939038222442
106 37.33740771561861 117.18809854794453
107 37.17699045687914 117.29357601720739
108 37.82528178393841 117.43241923864416
109 37.13056392967701 119.84073495876005
110 38.38998484611511 122.74776106687673
111 38.27269107848406 124.10172315382671
112 39.03705297410488 124.42382576156477
113 38.40535926818848 124.48179570258212
114 38.47071893513203 125.2590893824027
115 38.609908640384674 125.30457667780085
116 38.62160222232342 125.43458549438884
117 40.161875218153 129.13346806288703
118 40.06243151426315 129.67718524437547
119 40.780515387654305 131.40806576766226
train accuracy: 1.0
validation accuracy: 1.0
