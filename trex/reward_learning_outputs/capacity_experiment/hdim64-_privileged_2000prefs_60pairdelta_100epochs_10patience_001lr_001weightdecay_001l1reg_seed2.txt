demo lengths 200
demos: (120, 200, 3)
demo_rewards: (120,)
[-191.10004521 -189.05007017 -187.50220085 -180.24009179 -171.96137924
 -169.38170168 -167.87631268 -164.27567046 -163.76742237 -156.07868959
 -155.22804552 -145.29002069 -142.8665728  -142.75441848 -136.98962801
 -132.4813577  -130.98347157 -118.24362226 -117.38411415 -116.97382686
 -115.06704102 -112.47832646 -103.24187681  -99.7422753   -98.18526662
  -88.94674758  -85.88346862  -79.38307722  -79.25112655  -73.50697856
  -72.69803192  -71.37326168  -68.27187815  -65.42298163  -65.35816021
  -49.31867416  -17.32544162   -4.37451128   -0.4258659     9.10814675
   17.73263018   40.64550157   41.11774839   48.64917674   52.5026004
   52.54502853   59.52827492   63.45606317   66.31570759   67.13050508
   72.16624272   79.16074532   84.19837606   89.30707154   90.26988507
   90.28646232   90.32667007   91.18021498   92.38187518   92.67153902
   93.69474939   93.8611286    95.24073533   95.36301018   96.09581961
   97.90553231   98.07644231   98.35872828   98.5733471    98.77895391
   99.10163704   99.47183808  101.36707045  102.70820969  103.61971442
  104.00039884  104.94014609  105.28448326  105.60678193  106.95774051
  107.03525723  107.05410486  107.36477417  107.72369032  107.78006758
  107.99397436  108.08910889  108.09776529  108.24033507  109.15712102
  109.71287331  110.25063891  110.45880856  110.48639228  111.92877272
  112.2946742   112.73910566  112.98274531  113.8461648   114.8461224
  115.08707834  115.41025719  115.56466246  115.87882503  116.51927592
  116.69939038  117.18809855  117.29357602  117.43241924  119.84073496
  122.74776107  124.10172315  124.42382576  124.4817957   125.25908938
  125.30457668  125.43458549  129.13346806  129.67718524  131.40806577]
maximum traj length 200
num training_obs 1800
num training_labels 1800
num val_obs 200
num val_labels 200
ModuleList(
  (0): Linear(in_features=3, out_features=64, bias=True)
  (1): Linear(in_features=64, out_features=1, bias=False)
)
device: cuda:0
end of epoch 0: val_loss 0.004659701621846714, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 2.7332e-03, -2.2565e-03,  8.6402e-04],
        [ 1.0600e-03, -5.9156e-04, -7.8579e-04],
        [ 4.9882e-04,  4.8757e-04, -1.0311e-03],
        [-1.1326e-04,  7.2439e-04,  2.6700e-03],
        [-4.5045e-04, -4.8609e-04, -6.1422e-04],
        [-9.4038e-04, -4.7193e-05, -9.1577e-04],
        [-6.2140e-05,  6.2644e-04,  1.2101e-03],
        [ 3.6685e-05,  2.7736e-04, -1.1550e-03],
        [-5.9522e-04,  1.3145e-04, -8.4787e-04],
        [ 1.6824e-03,  8.3602e-04, -1.0466e-03],
        [ 5.6086e-04, -1.9245e-03,  2.0030e-03],
        [-3.7467e-04, -2.1796e-03,  2.4522e-04],
        [-4.1749e-04,  1.4873e-03, -5.3207e-04],
        [-3.0172e-04, -6.2084e-04,  1.2313e-03],
        [ 1.8142e-03,  1.1932e-03, -4.5841e-04],
        [-1.2047e-03, -8.6260e-06,  5.1121e-04],
        [ 4.2192e-04,  1.4932e-03, -1.6903e-03],
        [ 1.4314e-03, -7.5268e-05,  5.2718e-04],
        [ 1.2794e-03, -1.8302e-04,  4.4482e-04],
        [ 5.5713e-04,  3.9585e-04, -3.7194e-04],
        [ 1.7703e-03, -1.0715e-03, -1.0859e-03],
        [-6.1910e-04, -1.5776e-03,  2.0642e-03],
        [-5.8001e-04,  1.9888e-03,  2.3138e-03],
        [-6.4219e-04,  7.8033e-04,  5.3146e-05],
        [-3.0937e-04, -1.9269e-03, -7.9208e-04],
        [-2.0659e-03,  1.1148e-03,  1.1440e-03],
        [-1.4428e-03,  2.3390e-04,  3.2088e-04],
        [-3.5320e-04,  9.1064e-04, -1.3331e-03],
        [-1.4916e-03, -8.0273e-04, -2.4144e-03],
        [-1.9658e-03, -6.5425e-05, -1.9230e-03],
        [ 9.7237e-04, -1.2504e-03,  1.7025e-04],
        [ 9.7778e-04,  1.2917e-03, -1.3836e-03],
        [-1.0979e-03, -3.4762e-04, -2.1999e-03],
        [ 1.3669e-03,  2.1621e-04, -5.5138e-04],
        [ 1.4390e-03, -1.8162e-04, -1.0804e-03],
        [-9.0777e-04,  4.5437e-04,  1.2608e-03],
        [ 3.8959e-04, -2.0697e-04,  2.0858e-03],
        [ 2.2685e-03, -6.2793e-04, -1.0504e-03],
        [-1.5015e-04, -2.9785e-03,  9.1792e-04],
        [ 1.6392e-04, -8.7141e-04,  3.5930e-04],
        [ 1.2107e-03,  8.3261e-04,  1.0823e-03],
        [-9.4598e-05,  1.5673e-03, -2.2682e-03],
        [-1.0710e-03, -8.2242e-04,  4.4080e-04],
        [-1.9840e-04,  3.6398e-04,  1.5487e-03],
        [-2.3105e-04,  4.8875e-04,  1.2220e-03],
        [ 8.3487e-05,  1.8098e-04,  2.5580e-03],
        [ 8.6961e-04, -3.3172e-03,  6.7126e-04],
        [ 7.6638e-04, -6.9351e-04,  4.4199e-03],
        [-3.8749e-04, -1.6934e-03,  1.4601e-04],
        [-3.8753e-04, -7.0703e-04, -1.1732e-03],
        [ 1.1266e-03,  8.1076e-04,  9.2034e-04],
        [-1.7624e-03,  1.3650e-04, -2.7732e-04],
        [-2.0620e-03,  3.1104e-03,  4.9838e-05],
        [-1.9773e-04,  1.2542e-03, -1.4243e-03],
        [-7.1640e-04, -1.8454e-03,  2.5821e-03],
        [-2.7661e-04, -1.1424e-03,  4.1111e-04],
        [-5.4179e-04, -2.4686e-03,  3.2799e-05],
        [ 1.9614e-03,  2.2122e-03,  5.3378e-04],
        [ 1.4562e-03, -1.9574e-03, -3.0691e-04],
        [-3.0371e-01,  6.9088e-01, -8.9721e-02],
        [ 1.0082e-03,  7.5749e-04,  8.3032e-04],
        [ 1.1692e-03,  3.3040e-04, -3.5680e-04],
        [-4.3278e-04,  8.7752e-04,  2.4563e-03],
        [-1.3856e-04, -2.3145e-03, -1.8424e-03]], device='cuda:0')), ('fcs.0.bias', tensor([ 1.0698e-03,  1.0506e-04,  1.8976e-04,  6.4927e-04, -7.9298e-04,
         8.6757e-04, -2.5581e-03,  7.4591e-04,  1.0489e-03,  3.9874e-04,
        -2.2080e-03,  1.0819e-03,  1.2837e-04, -5.5711e-04,  3.5071e-04,
         7.4598e-04, -9.5142e-04,  5.4052e-04,  6.6946e-04,  2.4746e-04,
        -5.6397e-04, -7.1819e-04,  1.0803e-03, -6.2095e-04, -1.2480e-03,
         1.1499e-03, -1.4464e-03,  1.2935e-03, -1.0382e-03,  5.6387e-04,
        -8.0464e-05,  9.3276e-04, -7.0388e-04,  7.5760e-04,  1.0420e-04,
         7.3634e-04,  2.8705e-04,  5.2722e-04, -5.3690e-05,  5.2022e-04,
        -5.1783e-05,  4.3144e-05, -3.8317e-04, -9.6453e-04,  1.5942e-03,
         1.4922e-03,  7.3358e-04,  2.1498e-04,  1.7054e-03, -7.0699e-04,
        -8.7866e-04, -1.3141e-03,  6.3748e-04,  1.5347e-04, -4.3265e-04,
         1.1436e-03, -3.8850e-04,  6.0533e-04,  1.0812e-04,  2.4261e-01,
         3.6266e-04, -8.2304e-04, -8.8169e-04, -5.2145e-04], device='cuda:0')), ('fcs.1.weight', tensor([[ 1.4178e-04,  1.1685e-04, -3.6543e-04,  2.0178e-03, -1.6261e-04,
          1.3866e-03, -2.3927e-04, -1.0084e-03,  1.6278e-03, -2.3668e-03,
         -1.0231e-03, -4.1212e-04, -3.3418e-04, -3.8625e-04,  4.9131e-04,
         -1.6604e-03, -1.2182e-03, -9.8628e-04,  1.9651e-03, -5.8817e-05,
         -2.8950e-04,  3.8468e-04, -7.3224e-04,  4.0253e-04,  3.3341e-04,
         -1.1871e-03,  1.3950e-04,  6.2104e-04,  3.4819e-05, -6.7080e-04,
         -1.0258e-04,  1.9261e-04,  1.4154e-03, -6.9012e-04, -5.8882e-06,
         -1.1473e-04,  1.0280e-04, -2.5387e-04,  5.3144e-04,  2.1320e-04,
         -1.9160e-04, -1.0620e-04, -5.9321e-04,  6.2064e-06, -9.7664e-04,
          1.3253e-03,  1.9235e-04,  4.2786e-04, -9.6065e-04,  5.9898e-05,
         -2.0914e-03, -1.8132e-06, -9.5247e-05,  5.6013e-05, -5.8037e-04,
          7.9184e-05,  1.6309e-03, -6.8357e-04, -7.4783e-04,  8.7713e-01,
          1.8038e-04,  7.3060e-04, -1.3392e-03,  3.8840e-04]], device='cuda:0'))])
end of epoch 1: val_loss 0.0059523241516730606, val_acc 1.0
trigger times: 1
end of epoch 2: val_loss 0.007388333138056069, val_acc 1.0
trigger times: 2
end of epoch 3: val_loss 0.00837595810804018, val_acc 1.0
trigger times: 3
end of epoch 4: val_loss 0.010424398501791892, val_acc 1.0
trigger times: 4
end of epoch 5: val_loss 0.004980042033405958, val_acc 1.0
trigger times: 5
end of epoch 6: val_loss 0.008135945459790364, val_acc 1.0
trigger times: 6
end of epoch 7: val_loss 0.00941019541695013, val_acc 1.0
trigger times: 7
end of epoch 8: val_loss 0.00916543664436567, val_acc 1.0
trigger times: 8
end of epoch 9: val_loss 0.010255644694924513, val_acc 1.0
trigger times: 9
end of epoch 10: val_loss 0.007341373141831475, val_acc 1.0
trigger times: 10
Early stopping.
0 3.2211648815657554 -191.10004520678868
1 3.7749194167454334 -189.05007017278314
2 3.541450038115727 -187.50220085194994
3 5.636227467635308 -180.24009179391223
4 6.984768561891997 -171.9613792356186
5 7.4519054987631534 -169.3817016847894
6 7.544379753153407 -167.87631268052303
7 4.205057784630299 -164.27567046290412
8 5.655060975646705 -163.76742236654098
9 10.401440032757819 -156.0786895876365
10 8.045668176440586 -155.22804551507866
11 8.056203458923846 -145.29002069283715
12 7.628466062402367 -142.86657280197298
13 13.445694151625503 -142.75441848091938
14 12.380957323875009 -136.98962801176134
15 8.676165638957173 -132.4813576990395
16 14.251260652191377 -130.98347157271724
17 9.693982942961156 -118.2436222554584
18 16.818021047860384 -117.38411415155902
19 10.165678151271095 -116.97382686219106
20 15.299182745191501 -115.06704102317899
21 19.048237127091852 -112.47832645551227
22 12.605448875576258 -103.24187681049156
23 19.68200977339893 -99.7422752992134
24 22.86387126147747 -98.18526661663928
25 20.041237328201532 -88.94674758091466
26 22.738614939153194 -85.88346861832474
27 24.61248053237796 -79.38307722218848
28 23.403787940740585 -79.25112655387144
29 18.272565141291125 -73.50697855948762
30 19.073424067348242 -72.69803191552006
31 23.11919936351478 -71.37326168319514
32 20.8272873647511 -68.27187815304366
33 21.68096099421382 -65.42298162776466
34 22.944697327911854 -65.35816021006309
35 23.935554888099432 -49.3186741604369
36 17.111182402819395 -17.325441617065966
37 25.18603440374136 -4.374511275254108
38 24.39959157258272 -0.4258658969524013
39 21.810978915542364 9.108146753357724
40 22.742205610498786 17.732630180500013
41 28.499899107962847 40.64550156746333
42 28.18459453433752 41.11774838972275
43 24.939730608835816 48.64917674484657
44 26.932247411459684 52.50260039838799
45 27.304216269403696 52.54502852695255
46 27.757061675190926 59.52827491841281
47 28.19780522212386 63.45606316769021
48 29.12732701934874 66.31570758515764
49 23.84030655398965 67.13050507695384
50 30.54566838592291 72.16624272108386
51 23.511508528143167 79.16074531670823
52 25.308908116072416 84.19837606184075
53 25.29818159714341 89.30707154325768
54 25.272460881620646 90.2698850730257
55 25.875962682068348 90.28646231697512
56 28.91521653160453 90.32667007477052
57 30.52613504603505 91.18021498086692
58 29.558263767510653 92.38187517969644
59 25.47459662333131 92.67153902025292
60 25.647126354277134 93.69474938898811
61 29.65395152568817 93.86112859581364
62 26.198177501559258 95.24073532592021
63 26.16753765195608 95.3630101766082
64 26.472013242542744 96.09581961281374
65 27.41028979793191 97.90553231413178
66 26.707456801086664 98.07644230926206
67 26.999512787908316 98.35872828331676
68 26.21037330850959 98.57334710000995
69 26.777046162635088 98.77895390936838
70 26.536435391753912 99.10163703819775
71 26.849402587860823 99.47183807834362
72 26.96527749672532 101.36707045382526
73 27.266811184585094 102.70820969163083
74 27.022714015096426 103.61971441966246
75 27.722458008676767 104.00039883786899
76 27.75537772849202 104.94014608739957
77 27.177994307130575 105.28448326377394
78 28.09999668225646 105.60678192821229
79 28.81098696961999 106.95774051225432
80 27.840496364980936 107.03525723063939
81 28.31323739886284 107.05410485829283
82 29.12616975605488 107.36477417456501
83 29.00459737330675 107.72369032284489
84 27.66475210338831 107.78006757763964
85 27.948354672640562 107.99397435655325
86 28.540297370404005 108.08910889221833
87 27.987727962434292 108.09776529440465
88 28.9281685911119 108.24033506535473
89 28.83058552443981 109.15712102315346
90 28.566347688436508 109.71287331230647
91 28.699090290814638 110.25063890779474
92 28.834017410874367 110.45880856467717
93 29.330659173429012 110.48639228144049
94 29.018896259367466 111.92877271779909
95 28.9390761628747 112.29467419620224
96 29.150471657514572 112.73910566375015
97 29.309539556503296 112.98274531176438
98 29.4918515086174 113.84616479719523
99 30.643388405442238 114.84612239587612
100 29.089808326214552 115.08707834021696
101 30.459408551454544 115.41025719446112
102 30.165976516902447 115.5646624637931
103 30.36186907812953 115.87882502857741
104 29.52015295624733 116.51927592390606
105 29.35439184308052 116.69939038222442
106 30.215144239366055 117.18809854794453
107 30.07933411002159 117.29357601720739
108 30.628147907555103 117.43241923864416
109 30.0400223210454 119.84073495876005
110 31.106184642761946 122.74776106687673
111 31.006920475512743 124.10172315382671
112 31.653962839394808 124.42382576156477
113 31.119191613048315 124.48179570258212
114 31.174539163708687 125.2590893824027
115 31.292359679937363 125.30457667780085
116 31.302253033965826 125.43458549438884
117 32.606186490505934 129.13346806288703
118 32.521995559334755 129.67718524437547
119 33.129882495850325 131.40806576766226
train accuracy: 1.0
validation accuracy: 1.0
