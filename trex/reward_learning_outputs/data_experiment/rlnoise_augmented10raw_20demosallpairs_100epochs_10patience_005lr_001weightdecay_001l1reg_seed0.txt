demo lengths 200
demos: (120, 200, 13)
demo_rewards: (120,)
[-191.10004521 -189.05007017 -187.50220085 -180.24009179 -171.96137924
 -169.38170168 -167.87631268 -164.27567046 -163.76742237 -156.07868959
 -155.22804552 -145.29002069 -142.8665728  -142.75441848 -136.98962801
 -132.4813577  -130.98347157 -118.24362226 -117.38411415 -116.97382686
 -115.06704102 -112.47832646 -103.24187681  -99.7422753   -98.18526662
  -88.94674758  -85.88346862  -79.38307722  -79.25112655  -73.50697856
  -72.69803192  -71.37326168  -68.27187815  -65.42298163  -65.35816021
  -49.31867416  -17.32544162   -4.37451128   -0.4258659     9.10814675
   17.73263018   40.64550157   41.11774839   48.64917674   52.5026004
   52.54502853   59.52827492   63.45606317   66.31570759   67.13050508
   72.16624272   79.16074532   84.19837606   89.30707154   90.26988507
   90.28646232   90.32667007   91.18021498   92.38187518   92.67153902
   93.69474939   93.8611286    95.24073533   95.36301018   96.09581961
   97.90553231   98.07644231   98.35872828   98.5733471    98.77895391
   99.10163704   99.47183808  101.36707045  102.70820969  103.61971442
  104.00039884  104.94014609  105.28448326  105.60678193  106.95774051
  107.03525723  107.05410486  107.36477417  107.72369032  107.78006758
  107.99397436  108.08910889  108.09776529  108.24033507  109.15712102
  109.71287331  110.25063891  110.45880856  110.48639228  111.92877272
  112.2946742   112.73910566  112.98274531  113.8461648   114.8461224
  115.08707834  115.41025719  115.56466246  115.87882503  116.51927592
  116.69939038  117.18809855  117.29357602  117.43241924  119.84073496
  122.74776107  124.10172315  124.42382576  124.4817957   125.25908938
  125.30457668  125.43458549  129.13346806  129.67718524  131.40806577]
maximum traj length 200
num training_obs 171
num training_labels 171
num val_obs 19
num val_labels 19
ModuleList(
  (0): Linear(in_features=13, out_features=1, bias=False)
)
Total number of parameters: 13
Number of trainable paramters: 13
device: cuda:0
end of epoch 0: val_loss 5.465200596289109, val_acc 0.5789473684210527
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-1.1558e-01,  1.4314e-03, -1.4062e-01,  3.3507e-02, -4.5894e-01,
         -3.1315e-02, -9.6588e-02,  7.1376e-03,  5.4803e-02,  4.3541e-01,
         -2.4695e-01,  1.4537e+00, -8.7523e-01]], device='cuda:0'))])
end of epoch 1: val_loss 0.8127619582453343, val_acc 0.8421052631578947
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-0.3137,  0.1654,  0.1908,  0.2271, -0.1047,  0.1166, -0.4156, -0.3834,
          0.1016,  0.5366, -0.5538,  2.3989, -1.5587]], device='cuda:0'))])
end of epoch 2: val_loss 0.4624104393564937, val_acc 0.8947368421052632
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[-0.1143,  0.2223,  0.3860,  0.2458, -0.2781,  0.0746, -0.3681, -0.0436,
         -0.0847,  1.1808, -0.7602,  2.9120, -2.3215]], device='cuda:0'))])
end of epoch 3: val_loss 7.67690708762721, val_acc 0.7368421052631579
trigger times: 1
end of epoch 4: val_loss 1.9653525853921707, val_acc 0.7894736842105263
trigger times: 2
end of epoch 5: val_loss 0.3786393878451331, val_acc 0.8947368421052632
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 0.2368,  0.1191,  0.1597,  0.1654, -0.2425,  0.1076, -0.2931, -0.2619,
         -0.0067,  1.6510, -1.1526,  4.6787, -2.6164]], device='cuda:0'))])
end of epoch 6: val_loss 0.2211841909500336, val_acc 0.9473684210526315
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 0.5134,  0.2790, -0.4158,  0.6664, -0.3429, -0.0677, -0.5706, -0.5247,
         -0.4446,  1.4871, -1.1673,  4.8707, -2.9683]], device='cuda:0'))])
end of epoch 7: val_loss 0.1831816938614745, val_acc 0.8947368421052632
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 0.4091,  0.2090,  0.0317,  0.3923, -0.2534,  0.1590, -0.2861, -0.4336,
         -0.4148,  1.5791, -1.3057,  4.6805, -2.8681]], device='cuda:0'))])
end of epoch 8: val_loss 0.8125789323266154, val_acc 0.8947368421052632
trigger times: 1
end of epoch 9: val_loss 0.2345970575902102, val_acc 0.9473684210526315
trigger times: 2
end of epoch 10: val_loss 0.020933953509578367, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 0.0927, -0.0380,  0.2395,  0.1682, -0.2611,  0.1454, -0.2805, -0.5126,
         -0.5465,  1.5867, -1.0636,  3.7079, -2.1399]], device='cuda:0'))])
end of epoch 11: val_loss 1.739600049818747, val_acc 0.7894736842105263
trigger times: 1
end of epoch 12: val_loss 0.7086005846289672, val_acc 0.7894736842105263
trigger times: 2
end of epoch 13: val_loss 2.4373518247838977, val_acc 0.7894736842105263
trigger times: 3
end of epoch 14: val_loss 0.9506524172831246, val_acc 0.8421052631578947
trigger times: 4
end of epoch 15: val_loss 1.8159208499744481, val_acc 0.7894736842105263
trigger times: 5
end of epoch 16: val_loss 1.946359772431211, val_acc 0.8421052631578947
trigger times: 6
end of epoch 17: val_loss 0.3234733718099482, val_acc 0.9473684210526315
trigger times: 7
end of epoch 18: val_loss 0.6018965856022487, val_acc 0.8947368421052632
trigger times: 8
end of epoch 19: val_loss 0.009863177524828279, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 0.5240,  0.1220, -0.4569,  0.3903, -0.7038,  0.4166, -0.4187, -0.6952,
         -0.9212,  2.2841, -1.9432,  5.3233, -3.1111]], device='cuda:0'))])
end of epoch 20: val_loss 2.008907173807978, val_acc 0.8421052631578947
trigger times: 1
end of epoch 21: val_loss 0.5118430524859191, val_acc 0.8947368421052632
trigger times: 2
end of epoch 22: val_loss 0.19651210559077836, val_acc 0.9473684210526315
trigger times: 3
end of epoch 23: val_loss 0.0026641210799910275, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 3.7452e-01, -3.7632e-03, -6.9672e-02,  7.0745e-01, -7.0980e-01,
          4.8536e-01, -9.2178e-01, -4.1424e-01, -7.1905e-01,  2.0630e+00,
         -2.1883e+00,  4.3583e+00, -2.5685e+00]], device='cuda:0'))])
end of epoch 24: val_loss 0.3647851463592602, val_acc 0.8947368421052632
trigger times: 1
end of epoch 25: val_loss 1.5049492182614272, val_acc 0.8421052631578947
trigger times: 2
end of epoch 26: val_loss 1.9522021318735663, val_acc 0.8421052631578947
trigger times: 3
end of epoch 27: val_loss 1.910028035643336, val_acc 0.8421052631578947
trigger times: 4
end of epoch 28: val_loss 3.8663474749368655e-05, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 0.0219,  0.0924,  0.0293,  0.2644, -0.6091,  0.3922, -0.4262, -1.6065,
         -1.0340,  1.8876, -2.1296,  5.2096, -3.3397]], device='cuda:0'))])
end of epoch 29: val_loss 0.1500671186398613, val_acc 0.9473684210526315
trigger times: 1
end of epoch 30: val_loss 0.0041020245070686355, val_acc 1.0
trigger times: 2
end of epoch 31: val_loss 0.4319438306908679, val_acc 0.8421052631578947
trigger times: 3
end of epoch 32: val_loss 0.137655614178105, val_acc 0.9473684210526315
trigger times: 4
end of epoch 33: val_loss 1.3730686432360215, val_acc 0.8947368421052632
trigger times: 5
end of epoch 34: val_loss 2.4475377092256068, val_acc 0.7894736842105263
trigger times: 6
end of epoch 35: val_loss 1.8485422410303638, val_acc 0.7894736842105263
trigger times: 7
end of epoch 36: val_loss 12.172964347036261, val_acc 0.7368421052631579
trigger times: 8
end of epoch 37: val_loss 1.8162684691561992, val_acc 0.8421052631578947
trigger times: 9
end of epoch 38: val_loss 0.08679492183420703, val_acc 0.9473684210526315
trigger times: 10
Early stopping.
0 -296.1359704732895 -191.10004520678868
1 -135.53830474615097 -167.87631268052303
2 -190.75061166286469 -142.75441848091938
3 -114.9117391705513 -116.97382686219106
4 -34.21883933991194 -88.94674758091466
5 -69.51785907149315 -71.37326168319514
6 -10.117982000112534 -0.4258658969524013
7 6.584427420049906 52.50260039838799
8 4.690887521952391 72.16624272108386
9 30.947120148688555 90.32667007477052
10 16.33274133503437 95.3630101766082
11 22.928906939923763 98.77895390936838
12 26.90702675282955 104.00039883786899
13 31.814707972109318 107.05410485829283
14 33.38029356300831 108.24033506535473
15 25.558340571820736 111.92877271779909
16 38.348505817353725 115.08707834021696
17 48.519944213330746 117.18809854794453
18 47.85453559458256 124.48179570258212
19 37.18787403032184 131.40806576766226
train accuracy: 0.9239766081871345
validation accuracy: 0.9473684210526315
