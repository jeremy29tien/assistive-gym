demo lengths 200
demos: (20, 200, 13)
demo_rewards: (20,)
[-164.60939173 -110.4021119   -90.34107021  -83.54538651  -77.71993871
  -70.18614344  -64.50817745  -50.24769537  -48.34145065  -38.70229081
   -8.71818574   20.55458422   94.64456082   97.77206132  101.87890933
  116.73865694  121.19361924  124.02158228  127.42190046  127.79372169]
maximum traj length 200
num training_obs 171
num training_labels 171
num val_obs 19
num val_labels 19
ModuleList(
  (0): Linear(in_features=13, out_features=1, bias=False)
)
Total number of parameters: 13
Number of trainable paramters: 13
device: cuda:0
end of epoch 0: val_loss 0.0007322643459095963, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 0.0865, -0.0983, -0.2484,  0.3113,  0.1992, -0.0832, -0.1250, -0.2134,
         -0.0860,  0.0116, -0.4536,  1.7949, -1.0880]], device='cuda:0'))])
end of epoch 1: val_loss 0.02002675635244606, val_acc 1.0
trigger times: 1
end of epoch 2: val_loss 0.0038039921338215783, val_acc 1.0
trigger times: 2
end of epoch 3: val_loss 0.04092559751159803, val_acc 0.9473684210526315
trigger times: 3
end of epoch 4: val_loss 0.00618774515102042, val_acc 1.0
trigger times: 4
end of epoch 5: val_loss 3.751382510735742e-05, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 0.2499, -0.0077, -0.0701,  0.0923,  0.1116, -0.4838, -0.2382, -0.4319,
         -0.4854, -0.3667, -1.4322,  4.0332, -1.8906]], device='cuda:0'))])
end of epoch 6: val_loss 1.1275246906945138, val_acc 0.8947368421052632
trigger times: 1
end of epoch 7: val_loss 0.0002874440915069212, val_acc 1.0
trigger times: 2
end of epoch 8: val_loss 0.5940621148996271, val_acc 0.9473684210526315
trigger times: 3
end of epoch 9: val_loss 0.00016661419600064905, val_acc 1.0
trigger times: 4
end of epoch 10: val_loss 9.787626619359606e-07, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 0.4439,  0.0511, -0.0322,  0.2588,  0.1810, -0.6582, -0.2116, -0.4731,
         -0.4794, -0.3067, -2.0396,  5.3240, -1.3817]], device='cuda:0'))])
end of epoch 11: val_loss 0.1149172657320665, val_acc 0.9473684210526315
trigger times: 1
end of epoch 12: val_loss 6.393889136808484e-05, val_acc 1.0
trigger times: 2
end of epoch 13: val_loss 3.1118979677557945e-06, val_acc 1.0
trigger times: 3
end of epoch 14: val_loss 0.047488664325914885, val_acc 0.9473684210526315
trigger times: 4
end of epoch 15: val_loss 1.2548344772623846e-08, val_acc 1.0
trigger times: 0
saving model weights...
Weights: OrderedDict([('fcs.0.weight', tensor([[ 0.5861,  0.0270, -0.2517,  0.5633,  0.3102, -0.9406, -0.4117, -0.6862,
         -0.6522, -0.2687, -2.2542,  6.2882, -1.4392]], device='cuda:0'))])
end of epoch 16: val_loss 0.3237418124544284, val_acc 0.9473684210526315
trigger times: 1
end of epoch 17: val_loss 0.005297170265629048, val_acc 1.0
trigger times: 2
end of epoch 18: val_loss 7.529002375935977e-08, val_acc 1.0
trigger times: 3
end of epoch 19: val_loss 0.0007547722443153983, val_acc 1.0
trigger times: 4
end of epoch 20: val_loss 5.194795544651386e-06, val_acc 1.0
trigger times: 5
end of epoch 21: val_loss 3.166309493520346e-05, val_acc 1.0
trigger times: 6
end of epoch 22: val_loss 0.001469660807680085, val_acc 1.0
trigger times: 7
end of epoch 23: val_loss 0.7333184853778221, val_acc 0.9473684210526315
trigger times: 8
end of epoch 24: val_loss 0.16803367509610803, val_acc 0.9473684210526315
trigger times: 9
end of epoch 25: val_loss 1.2293186871039372, val_acc 0.8947368421052632
trigger times: 10
Early stopping.
0 -158.17117154598236 -164.60939172667727
1 -45.4145425260067 -110.40211189959727
2 -15.891339227557182 -90.3410702099161
3 39.37324273586273 -83.54538650927852
4 31.143768906593323 -77.71993870914932
5 32.596628308296204 -70.18614343970475
6 42.318118661642075 -64.50817744738329
7 72.03521776199341 -50.24769537498815
8 67.37225458025932 -48.34145065013472
9 56.07703012228012 -38.702290812442186
10 53.04061394929886 -8.718185737683392
11 107.43786969780922 20.554584219954464
12 91.17485627532005 94.64456081709041
13 97.10690854489803 97.77206131759269
14 77.05633470416069 101.87890933152616
15 111.42783454060555 116.73865693628218
16 120.37192678451538 121.19361924060846
17 122.80699273943901 124.02158228281696
18 95.39438362419605 127.42190046347255
19 133.70176547765732 127.79372168925553
train accuracy: 0.9064327485380117
validation accuracy: 0.8947368421052632
